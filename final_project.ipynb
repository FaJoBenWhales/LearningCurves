{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Learning Curves of Convolutional Neural Network on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tools as t\n",
    "import models as m\n",
    "import hyperband as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling configuration data\n",
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n"
     ]
    }
   ],
   "source": [
    "configs,lcs,Y = t.load_data(scale_configs = True)\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    Testing models (mlp, lstm, multi_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "177/177 [==============================] - 2s 14ms/step - loss: 0.0554 - val_loss: 0.0263\n",
      "Epoch 2/10\n",
      "177/177 [==============================] - 0s 445us/step - loss: 0.0363 - val_loss: 0.0250\n",
      "Epoch 3/10\n",
      "177/177 [==============================] - 0s 446us/step - loss: 0.0353 - val_loss: 0.0234\n",
      "Epoch 4/10\n",
      "177/177 [==============================] - 0s 534us/step - loss: 0.0330 - val_loss: 0.0229\n",
      "Epoch 5/10\n",
      "177/177 [==============================] - 0s 443us/step - loss: 0.0305 - val_loss: 0.0252\n",
      "Epoch 6/10\n",
      "177/177 [==============================] - 0s 596us/step - loss: 0.0287 - val_loss: 0.0227\n",
      "Epoch 7/10\n",
      "177/177 [==============================] - 0s 431us/step - loss: 0.0260 - val_loss: 0.0192\n",
      "Epoch 8/10\n",
      "177/177 [==============================] - 0s 483us/step - loss: 0.0247 - val_loss: 0.0183\n",
      "Epoch 9/10\n",
      "177/177 [==============================] - 0s 683us/step - loss: 0.0224 - val_loss: 0.0185\n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 0s 450us/step - loss: 0.0219 - val_loss: 0.0176\n",
      "mse train: 0.02026, mse validation 0.01757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.020264899801071712, 0.017568055259537099)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20}\n",
    "model = m.mlp(cfg)\n",
    "m.train_mlp(model, configs, Y, cfg, split=177, epochs=10)\n",
    "m.eval_mlp(model, configs, Y, split=177, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train on finalstep considering 10 epochs, eval during training with 10 epochs\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 6s 708ms/step - loss: 0.2487 - mean_squared_error: 0.2487 - val_loss: 0.1858 - val_mean_squared_error: 0.1858\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.1104 - mean_squared_error: 0.1104 - val_loss: 0.1012 - val_mean_squared_error: 0.1012\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0705 - mean_squared_error: 0.0705 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "mse train: 0.07338, mse validation 0.05441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.073382757786209549, 0.054412963820766672)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(10,10), split=150, \n",
    "             batch_size=20, epochs=3, mode='finalstep', verbose=1)\n",
    "m.eval_lstm_direct(model, [configs,lcs], Y, steps=10, split=150, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train on finalstep with random nr. of epochs, eval during training with 10 epochs\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - 7s 825ms/step - loss: 0.3111 - mean_squared_error: 0.3111 - val_loss: 0.2062 - val_mean_squared_error: 0.2062\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.1179 - mean_squared_error: 0.1179 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0788 - mean_squared_error: 0.0788 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "mse train: 0.05126, mse validation 0.03871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.051258760669721667, 0.03870874210144807)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same with training on random lenghts\n",
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(0,10), split=150, batch_size=20, \n",
    "             epochs=3, mode='finalstep', verbose=1)\n",
    "m.eval_lstm_direct(model, [configs,lcs], Y, steps=10, split=150, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 527ms/step - loss: 0.2842 - mean_squared_error: 0.2842 - val_loss: 0.1273 - val_mean_squared_error: 0.1273\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 0.0610 - mean_squared_error: 0.0610 - val_loss: 0.0715 - val_mean_squared_error: 0.0715\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 8.6942e-04 - val_mean_squared_error: 8.6942e-04\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.6067e-04 - val_mean_squared_error: 8.6067e-04\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 8.0088e-04 - mean_squared_error: 8.0088e-04 - val_loss: 5.3051e-04 - val_mean_squared_error: 5.3051e-04\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 6.5383e-04 - mean_squared_error: 6.5383e-04 - val_loss: 4.8940e-04 - val_mean_squared_error: 4.8940e-04\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 5.9794e-04 - mean_squared_error: 5.9794e-04 - val_loss: 4.1794e-04 - val_mean_squared_error: 4.1794e-04\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 4.8789e-04 - mean_squared_error: 4.8789e-04 - val_loss: 4.4278e-04 - val_mean_squared_error: 4.4278e-04\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 4.7472e-04 - mean_squared_error: 4.7472e-04 - val_loss: 4.8829e-04 - val_mean_squared_error: 4.8829e-04\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 4.7378e-04 - mean_squared_error: 4.7378e-04 - val_loss: 4.6291e-04 - val_mean_squared_error: 4.6291e-04\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 4.5659e-04 - mean_squared_error: 4.5659e-04 - val_loss: 4.7734e-04 - val_mean_squared_error: 4.7734e-04\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 4.7181e-04 - mean_squared_error: 4.7181e-04 - val_loss: 5.0012e-04 - val_mean_squared_error: 5.0012e-04\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 4.7167e-04 - mean_squared_error: 4.7167e-04 - val_loss: 5.0414e-04 - val_mean_squared_error: 5.0414e-04\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 4.9762e-04 - mean_squared_error: 4.9762e-04 - val_loss: 5.1562e-04 - val_mean_squared_error: 5.1562e-04\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 5.0700e-04 - mean_squared_error: 5.0700e-04 - val_loss: 5.6090e-04 - val_mean_squared_error: 5.6090e-04\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 6.1550e-04 - mean_squared_error: 6.1550e-04 - val_loss: 5.7167e-04 - val_mean_squared_error: 5.7167e-04\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 7.3531e-04 - mean_squared_error: 7.3531e-04 - val_loss: 8.5170e-04 - val_mean_squared_error: 8.5170e-04\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 8.7663e-04 - val_mean_squared_error: 8.7663e-04\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.7629e-04 - val_mean_squared_error: 7.7629e-04\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 3.5146e-04 - val_mean_squared_error: 3.5146e-04\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 5.8703e-04 - mean_squared_error: 5.8703e-04 - val_loss: 5.1905e-04 - val_mean_squared_error: 5.1905e-04\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 6.5990e-04 - mean_squared_error: 6.5990e-04 - val_loss: 6.0620e-04 - val_mean_squared_error: 6.0620e-04\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 6.2369e-04 - mean_squared_error: 6.2369e-04 - val_loss: 5.1306e-04 - val_mean_squared_error: 5.1306e-04\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 5.4402e-04 - mean_squared_error: 5.4402e-04 - val_loss: 5.0181e-04 - val_mean_squared_error: 5.0181e-04\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 5.4179e-04 - mean_squared_error: 5.4179e-04 - val_loss: 5.0539e-04 - val_mean_squared_error: 5.0539e-04\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 5.5562e-04 - mean_squared_error: 5.5562e-04 - val_loss: 5.0386e-04 - val_mean_squared_error: 5.0386e-04\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 5.4436e-04 - mean_squared_error: 5.4436e-04 - val_loss: 5.1037e-04 - val_mean_squared_error: 5.1037e-04\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 125ms/step - loss: 5.5181e-04 - mean_squared_error: 5.5181e-04 - val_loss: 5.2507e-04 - val_mean_squared_error: 5.2507e-04\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 5.6531e-04 - mean_squared_error: 5.6531e-04 - val_loss: 5.2816e-04 - val_mean_squared_error: 5.2816e-04\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 5.7088e-04 - mean_squared_error: 5.7088e-04 - val_loss: 5.3062e-04 - val_mean_squared_error: 5.3062e-04\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 5.8097e-04 - mean_squared_error: 5.8097e-04 - val_loss: 5.2733e-04 - val_mean_squared_error: 5.2733e-04\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 5.8217e-04 - mean_squared_error: 5.8217e-04 - val_loss: 5.3640e-04 - val_mean_squared_error: 5.3640e-04\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 6.1269e-04 - mean_squared_error: 6.1269e-04 - val_loss: 5.2189e-04 - val_mean_squared_error: 5.2189e-04\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 6.1096e-04 - mean_squared_error: 6.1096e-04 - val_loss: 5.7000e-04 - val_mean_squared_error: 5.7000e-04\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 7.2944e-04 - mean_squared_error: 7.2944e-04 - val_loss: 5.4656e-04 - val_mean_squared_error: 5.4656e-04\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 8.0794e-04 - mean_squared_error: 8.0794e-04 - val_loss: 7.6281e-04 - val_mean_squared_error: 7.6281e-04\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 8.4114e-04 - val_mean_squared_error: 8.4114e-04\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 9.5205e-04 - val_mean_squared_error: 9.5205e-04\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 7.7647e-04 - val_mean_squared_error: 7.7647e-04\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 8.4677e-04 - mean_squared_error: 8.4677e-04 - val_loss: 7.4963e-04 - val_mean_squared_error: 7.4963e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 7.4931e-04 - mean_squared_error: 7.4931e-04 - val_loss: 5.9438e-04 - val_mean_squared_error: 5.9438e-04\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 6.7311e-04 - mean_squared_error: 6.7311e-04 - val_loss: 4.7425e-04 - val_mean_squared_error: 4.7425e-04\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 6.5365e-04 - mean_squared_error: 6.5365e-04 - val_loss: 4.5641e-04 - val_mean_squared_error: 4.5641e-04\n",
      "mse train: 0.06521, mse validation 0.02669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.065214293491303491, 0.026686737793762665)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(10,10), split=180, batch_size=20, \n",
    "             epochs=50, mode='nextstep', verbose=1)\n",
    "m.eval_lstm_stepwise(model, [configs,lcs], Y, steps=10, split=180, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train considering 20 epochs, eval during training with 20 epochs\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 6s 616ms/step - loss: 0.3187 - mean_squared_error: 0.3187 - val_loss: 0.1667 - val_mean_squared_error: 0.1667\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.0876 - mean_squared_error: 0.0876 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 139ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 2s 171ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 2s 198ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 8.5395e-04 - val_mean_squared_error: 8.5395e-04\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 132ms/step - loss: 7.7500e-04 - mean_squared_error: 7.7500e-04 - val_loss: 4.8302e-04 - val_mean_squared_error: 4.8302e-04\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 6.5339e-04 - mean_squared_error: 6.5339e-04 - val_loss: 7.3556e-04 - val_mean_squared_error: 7.3556e-04\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 4.7104e-04 - mean_squared_error: 4.7104e-04 - val_loss: 5.0899e-04 - val_mean_squared_error: 5.0899e-04\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 2s 206ms/step - loss: 4.3912e-04 - mean_squared_error: 4.3912e-04 - val_loss: 5.1421e-04 - val_mean_squared_error: 5.1421e-04\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 4.4952e-04 - mean_squared_error: 4.4952e-04 - val_loss: 4.1170e-04 - val_mean_squared_error: 4.1170e-04\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 4.4389e-04 - mean_squared_error: 4.4389e-04 - val_loss: 3.6920e-04 - val_mean_squared_error: 3.6920e-04\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 160ms/step - loss: 3.9739e-04 - mean_squared_error: 3.9739e-04 - val_loss: 3.9454e-04 - val_mean_squared_error: 3.9454e-04\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 3.6438e-04 - mean_squared_error: 3.6438e-04 - val_loss: 4.1874e-04 - val_mean_squared_error: 4.1874e-04\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 3.7776e-04 - mean_squared_error: 3.7776e-04 - val_loss: 4.4277e-04 - val_mean_squared_error: 4.4277e-04\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 3.9011e-04 - mean_squared_error: 3.9011e-04 - val_loss: 4.5991e-04 - val_mean_squared_error: 4.5991e-04\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 3.9392e-04 - mean_squared_error: 3.9392e-04 - val_loss: 4.8633e-04 - val_mean_squared_error: 4.8633e-04\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 4.0337e-04 - mean_squared_error: 4.0337e-04 - val_loss: 5.2011e-04 - val_mean_squared_error: 5.2011e-04\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 118ms/step - loss: 4.1083e-04 - mean_squared_error: 4.1083e-04 - val_loss: 5.4903e-04 - val_mean_squared_error: 5.4903e-04\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 4.1645e-04 - mean_squared_error: 4.1645e-04 - val_loss: 5.8611e-04 - val_mean_squared_error: 5.8611e-04\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 4.2205e-04 - mean_squared_error: 4.2205e-04 - val_loss: 6.2044e-04 - val_mean_squared_error: 6.2044e-04\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 129ms/step - loss: 4.2445e-04 - mean_squared_error: 4.2445e-04 - val_loss: 6.4510e-04 - val_mean_squared_error: 6.4510e-04\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 2s 192ms/step - loss: 4.2634e-04 - mean_squared_error: 4.2634e-04 - val_loss: 6.5912e-04 - val_mean_squared_error: 6.5912e-04\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 4.2768e-04 - mean_squared_error: 4.2768e-04 - val_loss: 6.5945e-04 - val_mean_squared_error: 6.5945e-04\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 130ms/step - loss: 4.2838e-04 - mean_squared_error: 4.2838e-04 - val_loss: 6.4277e-04 - val_mean_squared_error: 6.4277e-04\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 4.3042e-04 - mean_squared_error: 4.3042e-04 - val_loss: 6.1855e-04 - val_mean_squared_error: 6.1855e-04\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 4.3192e-04 - mean_squared_error: 4.3192e-04 - val_loss: 5.8745e-04 - val_mean_squared_error: 5.8745e-04\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 4.3334e-04 - mean_squared_error: 4.3334e-04 - val_loss: 5.6487e-04 - val_mean_squared_error: 5.6487e-04\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 4.3174e-04 - mean_squared_error: 4.3174e-04 - val_loss: 5.4573e-04 - val_mean_squared_error: 5.4573e-04\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 4.2783e-04 - mean_squared_error: 4.2783e-04 - val_loss: 5.4693e-04 - val_mean_squared_error: 5.4693e-04\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 4.2134e-04 - mean_squared_error: 4.2134e-04 - val_loss: 5.4281e-04 - val_mean_squared_error: 5.4281e-04\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 4.1351e-04 - mean_squared_error: 4.1351e-04 - val_loss: 5.6364e-04 - val_mean_squared_error: 5.6364e-04\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 2s 169ms/step - loss: 4.0610e-04 - mean_squared_error: 4.0610e-04 - val_loss: 5.4848e-04 - val_mean_squared_error: 5.4848e-04\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 3.9829e-04 - mean_squared_error: 3.9829e-04 - val_loss: 5.8068e-04 - val_mean_squared_error: 5.8068e-04\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 111ms/step - loss: 3.9303e-04 - mean_squared_error: 3.9303e-04 - val_loss: 5.2665e-04 - val_mean_squared_error: 5.2665e-04\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 3.8678e-04 - mean_squared_error: 3.8678e-04 - val_loss: 5.9208e-04 - val_mean_squared_error: 5.9208e-04\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 3.8725e-04 - mean_squared_error: 3.8725e-04 - val_loss: 4.8470e-04 - val_mean_squared_error: 4.8470e-04\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 3.8458e-04 - mean_squared_error: 3.8458e-04 - val_loss: 6.2418e-04 - val_mean_squared_error: 6.2418e-04\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 3.9485e-04 - mean_squared_error: 3.9485e-04 - val_loss: 4.4557e-04 - val_mean_squared_error: 4.4557e-04\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 3.9114e-04 - mean_squared_error: 3.9114e-04 - val_loss: 6.6658e-04 - val_mean_squared_error: 6.6658e-04\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 4.0717e-04 - mean_squared_error: 4.0717e-04 - val_loss: 4.1475e-04 - val_mean_squared_error: 4.1475e-04\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 3.9160e-04 - mean_squared_error: 3.9160e-04 - val_loss: 6.6236e-04 - val_mean_squared_error: 6.6236e-04\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 4.0314e-04 - mean_squared_error: 4.0314e-04 - val_loss: 3.8992e-04 - val_mean_squared_error: 3.8992e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 3.8044e-04 - mean_squared_error: 3.8044e-04 - val_loss: 5.9433e-04 - val_mean_squared_error: 5.9433e-04\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 3.8620e-04 - mean_squared_error: 3.8620e-04 - val_loss: 3.8484e-04 - val_mean_squared_error: 3.8484e-04\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 3.7075e-04 - mean_squared_error: 3.7075e-04 - val_loss: 5.0869e-04 - val_mean_squared_error: 5.0869e-04\n",
      "mse train: 0.07631, mse validation 0.03996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.076310423364451249, 0.039959337114572585)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(20,20), split=180, batch_size=20, \n",
    "             epochs=50, mode='nextstep', verbose=1)\n",
    "m.eval_lstm_stepwise(model, [configs,lcs], Y, steps=20, split=180, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 510ms/step - loss: 0.2543 - mean_squared_error: 0.2543 - val_loss: 0.0632 - val_mean_squared_error: 0.0632\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 1s 59ms/step - loss: 0.0601 - mean_squared_error: 0.0601 - val_loss: 0.0636 - val_mean_squared_error: 0.0636\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 1s 66ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 1s 67ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.4203e-04 - val_mean_squared_error: 9.4203e-04\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 1s 72ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.7494e-04 - val_mean_squared_error: 9.7494e-04\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 1s 75ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 1s 82ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.9589e-04 - val_mean_squared_error: 9.9589e-04\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.8937e-04 - val_mean_squared_error: 7.8937e-04\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 9.7421e-04 - mean_squared_error: 9.7421e-04 - val_loss: 7.6363e-04 - val_mean_squared_error: 7.6363e-04\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 1s 83ms/step - loss: 9.1752e-04 - mean_squared_error: 9.1752e-04 - val_loss: 6.7368e-04 - val_mean_squared_error: 6.7368e-04\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 8.6539e-04 - mean_squared_error: 8.6539e-04 - val_loss: 6.6338e-04 - val_mean_squared_error: 6.6338e-04\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 9.6177e-04 - mean_squared_error: 9.6177e-04 - val_loss: 7.0253e-04 - val_mean_squared_error: 7.0253e-04\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.1121e-04 - val_mean_squared_error: 8.1121e-04\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 1s 70ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 8.2198e-04 - val_mean_squared_error: 8.2198e-04\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 1s 71ms/step - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 8.2502e-04 - val_mean_squared_error: 8.2502e-04\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 1s 81ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 6.6508e-04 - val_mean_squared_error: 6.6508e-04\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 7.6501e-04 - val_mean_squared_error: 7.6501e-04\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 7.4475e-04 - mean_squared_error: 7.4475e-04 - val_loss: 8.0915e-04 - val_mean_squared_error: 8.0915e-04\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 7.8624e-04 - mean_squared_error: 7.8624e-04 - val_loss: 6.1501e-04 - val_mean_squared_error: 6.1501e-04\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 1s 76ms/step - loss: 6.5213e-04 - mean_squared_error: 6.5213e-04 - val_loss: 5.7252e-04 - val_mean_squared_error: 5.7252e-04\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 1s 74ms/step - loss: 6.2322e-04 - mean_squared_error: 6.2322e-04 - val_loss: 5.3362e-04 - val_mean_squared_error: 5.3362e-04\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 6.2554e-04 - mean_squared_error: 6.2554e-04 - val_loss: 5.4672e-04 - val_mean_squared_error: 5.4672e-04\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 6.5832e-04 - mean_squared_error: 6.5832e-04 - val_loss: 5.5547e-04 - val_mean_squared_error: 5.5547e-04\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 7.0015e-04 - mean_squared_error: 7.0015e-04 - val_loss: 6.4986e-04 - val_mean_squared_error: 6.4986e-04\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 1s 80ms/step - loss: 7.6763e-04 - mean_squared_error: 7.6763e-04 - val_loss: 6.2912e-04 - val_mean_squared_error: 6.2912e-04\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 8.4450e-04 - mean_squared_error: 8.4450e-04 - val_loss: 8.5492e-04 - val_mean_squared_error: 8.5492e-04\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 9.5290e-04 - mean_squared_error: 9.5290e-04 - val_loss: 7.2314e-04 - val_mean_squared_error: 7.2314e-04\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 1s 79ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 1s 78ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.3492e-04 - val_mean_squared_error: 7.3492e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.2414e-04 - val_mean_squared_error: 8.2414e-04\n",
      "mse train: 7.22660, mse validation 7.20777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.2265960036872281, 7.2077733345183974)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(5,5), split=180, batch_size=20, \n",
    "             epochs=50, mode='nextstep', verbose=1)\n",
    "m.eval_lstm_stepwise(model, [configs,lcs], Y, steps=5, split=180, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train with random nr. of epochs, eval during training with 10 epochs\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.2961 - mean_squared_error: 0.2961 - val_loss: 0.0789 - val_mean_squared_error: 0.0789\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.0863 - mean_squared_error: 0.0863 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 2s 190ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 2s 244ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 2s 283ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "mse train: 0.92659, mse validation 0.73805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.92658545341745213, 0.73805311720421751)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m.multi_lstm()\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(0,10), split=150, batch_size=20, \n",
    "             epochs=10, mode='nextstep', verbose=1)\n",
    "m.eval_lstm_stepwise(model, [configs,lcs], Y, steps=10, split=150, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on new epoch 5 true value for curve no. 13 (example) 0.297987927284\n",
      "train on new epoch 6 true value for curve no. 13 (example) 0.276659959129\n",
      "train on new epoch 7 true value for curve no. 13 (example) 0.275050303766\n",
      "train on new epoch 8 true value for curve no. 13 (example) 0.288933598569\n",
      "train on new epoch 9 true value for curve no. 13 (example) 0.275251509888\n",
      "train on new epoch 10 true value for curve no. 13 (example) 0.311066399728\n",
      "train on new epoch 11 true value for curve no. 13 (example) 0.257645875216\n",
      "train on new epoch 12 true value for curve no. 13 (example) 0.26348088256\n",
      "train on new epoch 13 true value for curve no. 13 (example) 0.282394366605\n",
      "train on new epoch 14 true value for curve no. 13 (example) 0.245372237904\n",
      "train on new epoch 15 true value for curve no. 13 (example) 0.252716300743\n",
      "train on new epoch 16 true value for curve no. 13 (example) 0.246177060263\n",
      "train on new epoch 17 true value for curve no. 13 (example) 0.235714284437\n",
      "train on new epoch 18 true value for curve no. 13 (example) 0.264486921685\n",
      "train on new epoch 19 true value for curve no. 13 (example) 0.253319919109\n",
      "train on new epoch 20 true value for curve no. 13 (example) 0.230482899717\n",
      "train on new epoch 21 true value for curve no. 13 (example) 0.227062367967\n",
      "train on new epoch 22 true value for curve no. 13 (example) 0.232796779701\n",
      "train on new epoch 23 true value for curve no. 13 (example) 0.227364180343\n",
      "train on new epoch 24 true value for curve no. 13 (example) 0.229476860591\n",
      "train on new epoch 25 true value for curve no. 13 (example) 0.229577464717\n",
      "train on new epoch 26 true value for curve no. 13 (example) 0.248390346766\n",
      "train on new epoch 27 true value for curve no. 13 (example) 0.242354122656\n",
      "train on new epoch 28 true value for curve no. 13 (example) 0.243561365775\n",
      "train on new epoch 29 true value for curve no. 13 (example) 0.22173038125\n",
      "train on new epoch 30 true value for curve no. 13 (example) 0.215492953147\n",
      "train on new epoch 31 true value for curve no. 13 (example) 0.219617709517\n",
      "train on new epoch 32 true value for curve no. 13 (example) 0.235211265939\n",
      "train on new epoch 33 true value for curve no. 13 (example) 0.230382293463\n",
      "train on new epoch 34 true value for curve no. 13 (example) 0.227565382208\n",
      "train on new epoch 35 true value for curve no. 13 (example) 0.224044261234\n",
      "train on new epoch 36 true value for curve no. 13 (example) 0.331790747387\n",
      "train on new epoch 37 true value for curve no. 13 (example) 0.246981897524\n",
      "train on new epoch 38 true value for curve no. 13 (example) 0.214084506035\n",
      "train on new epoch 39 true value for curve no. 13 (example) 0.214084501777\n",
      "train on new epoch 40 true value for curve no. 13 (example) 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 10 prediction / true value for lc number 13 0.277989 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.2915 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.276354 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.292358 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.274371 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.290001 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.274371 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.287972 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.274371 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.287972 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.274371 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.284571 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.274371 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.281017 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.274371 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.272158 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.269471 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.269471 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.269471 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.269471 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.269471 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.269471 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.269471 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.269471 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.269471 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.269471 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.269471 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.269471 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.269471 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.269471 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.51741443  0.4540801   0.42677908  0.39405802  0.37759711  0.36866406\n",
      "  0.35782395  0.34698384  0.33524039  0.32951922  0.32249322  0.32148951\n",
      "  0.31506574  0.31356018  0.30683529  0.31135201  0.30442638  0.30312155\n",
      "  0.29308442  0.29298404  0.29338553  0.29388738  0.2857573   0.28977216\n",
      "  0.28073873  0.2899729   0.28214393  0.27792833  0.27863094  0.27381311\n",
      "  0.27270902  0.27903242  0.2728094   0.27009937  0.27050085  0.26809194\n",
      "  0.26538191  0.26558265  0.27120345  0.26708823]\n",
      "step nr. 10 prediction / true value for lc number 13 0.343269 / 0.322493222025\n",
      "step nr. 11 prediction / true value for lc number 13 0.345114 / 0.321489512185\n",
      "step nr. 12 prediction / true value for lc number 13 0.345114 / 0.315065743747\n",
      "step nr. 13 prediction / true value for lc number 13 0.339905 / 0.313560176043\n",
      "step nr. 14 prediction / true value for lc number 13 0.346333 / 0.306835287883\n",
      "step nr. 15 prediction / true value for lc number 13 0.346333 / 0.311352006447\n",
      "step nr. 16 prediction / true value for lc number 13 0.345114 / 0.304426380146\n",
      "step nr. 17 prediction / true value for lc number 13 0.346333 / 0.303121549848\n",
      "step nr. 18 prediction / true value for lc number 13 0.346333 / 0.293084416125\n",
      "step nr. 19 prediction / true value for lc number 13 0.346333 / 0.292984041167\n",
      "step nr. 20 prediction / true value for lc number 13 0.346333 / 0.293385528488\n",
      "step nr. 21 prediction / true value for lc number 13 0.346333 / 0.2938873812\n",
      "step nr. 22 prediction / true value for lc number 13 0.346333 / 0.285757301766\n",
      "step nr. 23 prediction / true value for lc number 13 0.346333 / 0.289772155108\n",
      "step nr. 24 prediction / true value for lc number 13 0.346333 / 0.280738732697\n",
      "step nr. 25 prediction / true value for lc number 13 0.346333 / 0.289972896929\n",
      "step nr. 26 prediction / true value for lc number 13 0.346333 / 0.282143932802\n",
      "step nr. 27 prediction / true value for lc number 13 0.346333 / 0.277928333959\n",
      "step nr. 28 prediction / true value for lc number 13 0.346333 / 0.278630935116\n",
      "step nr. 29 prediction / true value for lc number 13 0.346333 / 0.273813112282\n",
      "step nr. 30 prediction / true value for lc number 13 0.346333 / 0.272709022334\n",
      "step nr. 31 prediction / true value for lc number 13 0.346333 / 0.279032418757\n",
      "step nr. 32 prediction / true value for lc number 13 0.346333 / 0.272809395084\n",
      "step nr. 33 prediction / true value for lc number 13 0.346333 / 0.270099369096\n",
      "step nr. 34 prediction / true value for lc number 13 0.346333 / 0.270500852738\n",
      "step nr. 35 prediction / true value for lc number 13 0.346333 / 0.26809193985\n",
      "step nr. 36 prediction / true value for lc number 13 0.346333 / 0.26538191239\n",
      "step nr. 37 prediction / true value for lc number 13 0.346333 / 0.265582654211\n",
      "step nr. 38 prediction / true value for lc number 13 0.346333 / 0.271203452422\n",
      "step nr. 39 prediction / true value for lc number 13 0.346333 / 0.26708822633\n",
      "mse train: 0.08315, mse validation 0.05617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.083146945607023348, 0.056170584855359744)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = {'maxdepth': 10, 'lr': 0.08119864140758115, 'gamma': 0.007833441242813044, \n",
    "       'cols_bt': 0.9376450587145334, 'n_estimators': 1000, 'subsample': 0.7946631901813815}\n",
    "model = m.xgb_next(cfg)\n",
    "m.train_xgb_next(model, [configs,lcs], split = 200)\n",
    "m.eval_xgb_stepwise(model, [configs,lcs], Y, 10, split=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    evaluating models with cross validation (ridge, XGB, mlp, lstm, multi_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 0 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'alpha': 1.0}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.02977] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03703]\n",
      " [ 0.02671]\n",
      " [ 0.02556]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.02747] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02433]\n",
      " [ 0.02864]\n",
      " [ 0.02943]]\n",
      "mse over all validation data 0.0297968665436\n",
      "set format\n",
      "path plots/ridge regression_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b489b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b2812e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg={'alpha':1.0}\n",
    "res_ridge = m.eval_cv('ridge', configs, Y, cfg=cfg, splits = 3)\n",
    "t.scatter_plot(Y, res_ridge['y_preds'][0], 'ridge regression')\n",
    "t.box_plot(Y, (5,5), [res_ridge], ['ridge'], 'comparison models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 0 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'gamma': 0.007833441242813044, 'lr': 0.08119864140758115, 'subsample': 0.7946631901813815, 'cols_bt': 0.9376450587145334, 'maxdepth': 10, 'n_estimators': 1000}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00677] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01027]\n",
      " [ 0.00327]\n",
      " [ 0.00675]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00056] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00051]\n",
      " [ 0.00057]\n",
      " [ 0.00059]]\n",
      "mse over all validation data 0.0067790880535\n",
      "set format\n",
      "path plots/xgb_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9ac01e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9ac01898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = {'maxdepth': 10, 'lr': 0.08119864140758115, 'gamma': 0.007833441242813044, 'cols_bt': 0.9376450587145334, \n",
    "       'n_estimators': 1000, 'subsample': 0.7946631901813815}\n",
    "#cfg = {'maxdepth': 4, 'lr': 0.07120217610550672, 'gamma': 0.03393596760993278, 'cols_bt': 0.823494199726015, 'n_estimators': 107, 'subsample': 0.7288741544938715}\n",
    "res_xgb = m.eval_cv('xgb', configs, Y, cfg=cfg, splits = 3)\n",
    "t.scatter_plot(Y, res_xgb, 'xgb')\n",
    "t.box_plot_single(Y, (5,5), [res_ridge, res_xgb], ['ridge','xgb'], 'comparison models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 500 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 20, 'lr': 0.2213474827989724}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00596] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00632]\n",
      " [ 0.00574]\n",
      " [ 0.00583]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00075] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00016]\n",
      " [ 0.00158]\n",
      " [ 0.00051]]\n",
      "mse over all validation data 0.00596572134582\n"
     ]
    }
   ],
   "source": [
    "# evaluate mlp via cross validation\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_500 = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=500, splits = 3, earlystop=False) \n",
    "t.pickle_to_file(res_mlp_500, 'res_mlp_500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9a061b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9a061390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_mlp_500=t.pickle_from_file('res_mlp_500')\n",
    "t.scatter_plot(Y, res_mlp_500, 'mlp')\n",
    "t.box_plot_single(Y, (5,5), [res_ridge, res_xgb, res_mlp_500], ['ridge','xgb','mlp_500epo'], \n",
    "           'predicting final point directly from config')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'lr': 0.2213474827989724, 'batch_size': 20}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04875, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04875 to 0.04613, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.04671, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04613 to 0.04593, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04593 to 0.04239, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.04353, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04239 to 0.03963, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03963 to 0.03916, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03916 to 0.03686, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03686 to 0.03644, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03644 to 0.03381, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03381 to 0.03142, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03142 to 0.02962, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02962 to 0.02731, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02731 to 0.02713, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02713 to 0.02316, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02316 to 0.02113, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02113 to 0.01929, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01929 to 0.01806, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.01816, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01806 to 0.01620, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01620 to 0.01465, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.01648, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01465 to 0.01372, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01372 to 0.01237, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01237 to 0.01145, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.01291, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01145 to 0.01099, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01099 to 0.01085, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01085 to 0.01084, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01084 to 0.01035, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01035 to 0.01001, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01001 to 0.00926, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00951, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.01041, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00926 to 0.00920, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00920 to 0.00903, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00974, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00903 to 0.00875, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00875 to 0.00830, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00920, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00888, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00878, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00830 to 0.00817, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00824, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.01040, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00817 to 0.00784, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00784 to 0.00784, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00784 to 0.00768, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00955, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00768 to 0.00762, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00762 to 0.00752, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.00926, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00752 to 0.00749, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00898, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00887, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00749 to 0.00747, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00747 to 0.00738, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00915, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00738 to 0.00736, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00736 to 0.00734, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00893, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00922, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00884, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00874, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00849, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00915, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00777, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00765, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00857, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00897, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00909, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00898, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00859, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00952, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00779, did not improve\n",
      "Epoch 00174: early stopping\n",
      "Using epoch 00099 with val_loss: 0.00734\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03013, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03013 to 0.02939, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02939 to 0.02794, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02794 to 0.02712, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02712 to 0.02585, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.02667, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02585 to 0.02313, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02313 to 0.02203, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02203 to 0.02114, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02114 to 0.01806, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01806 to 0.01684, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01684 to 0.01593, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01593 to 0.01527, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01527 to 0.01433, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01433 to 0.01349, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01349 to 0.01253, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01253 to 0.01133, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01133 to 0.01071, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01190, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01071 to 0.00961, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00961 to 0.00952, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00952 to 0.00885, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00885 to 0.00858, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00858 to 0.00837, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00837 to 0.00825, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00840, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00825 to 0.00765, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00914, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00765 to 0.00717, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00717 to 0.00715, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00873, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00715 to 0.00706, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00706 to 0.00704, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00916, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00704 to 0.00674, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00674 to 0.00666, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00982, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00666 to 0.00660, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00660 to 0.00648, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00892, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00850, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00879, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00648 to 0.00648, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00648 to 0.00624, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00736, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00624 to 0.00615, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00615 to 0.00611, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00611 to 0.00603, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00603 to 0.00585, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00585 to 0.00585, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00585 to 0.00577, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00577 to 0.00573, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00573 to 0.00567, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00567 to 0.00564, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00564 to 0.00563, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00563 to 0.00557, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00557 to 0.00543, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00543 to 0.00540, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00540 to 0.00538, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00538 to 0.00524, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00524 to 0.00511, storing weights.\n",
      "\n",
      "Epoch 00253: val_loss is 0.00523, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00511 to 0.00510, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00533, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00267: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.00510 to 0.00499, storing weights.\n",
      "\n",
      "Epoch 00307: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00523, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00505, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.00499 to 0.00490, storing weights.\n",
      "\n",
      "Epoch 00376: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00504, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00498, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00503, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00511, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00430: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00523, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.00506, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.00511, did not improve\n",
      "Epoch 00450: early stopping\n",
      "Using epoch 00375 with val_loss: 0.00490\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02666, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02666 to 0.02495, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02495 to 0.02461, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02461 to 0.02340, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02340 to 0.02236, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02236 to 0.02154, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02154 to 0.02006, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02006 to 0.01987, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01987 to 0.01797, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01797 to 0.01709, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.02040, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01709 to 0.01677, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01677 to 0.01617, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01617 to 0.01609, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01609 to 0.01306, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.01326, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01306 to 0.01131, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01131 to 0.01061, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01061 to 0.00972, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00972 to 0.00965, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00976, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00965 to 0.00957, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00957 to 0.00863, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00863 to 0.00850, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00850 to 0.00837, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.01393, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00864, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00837 to 0.00753, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00753 to 0.00745, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00745 to 0.00717, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00717 to 0.00704, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00899, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00704 to 0.00699, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00966, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.01020, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00699 to 0.00683, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00683 to 0.00671, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00671 to 0.00655, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00655 to 0.00649, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00864, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00649 to 0.00641, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00641 to 0.00636, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00968, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00859, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00636 to 0.00592, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00592 to 0.00591, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00591 to 0.00558, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00850, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00866, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00558 to 0.00520, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00542, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00520 to 0.00509, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00509 to 0.00483, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00489, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00859, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00505, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00483 to 0.00481, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00497, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00494, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00498, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00506, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00504, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00284: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00497, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00914, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00496, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00575, did not improve\n",
      "Epoch 00301: early stopping\n",
      "Using epoch 00226 with val_loss: 0.00481\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00568] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00734]\n",
      " [ 0.0049 ]\n",
      " [ 0.00481]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00178] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00275]\n",
      " [ 0.0011 ]\n",
      " [ 0.00149]]\n",
      "mse over all validation data 0.00568764191678\n",
      "path plots/mlp with earlystop_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdead45c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mlp via cross validation\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_es = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True)\n",
    "t.scatter_plot(Y, res_mlp_es['y_preds'][0], 'mlp with earlystop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'lr': 0.2213474827989724, 'batch_size': 20}\n",
      "evaluating with early stopping\n",
      "create mlp using Dropout\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05210, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05210 to 0.04729, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04729 to 0.04595, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04595 to 0.04564, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.04595, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04564 to 0.04303, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04303 to 0.04162, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04162 to 0.04005, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.04128, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04005 to 0.03847, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03847 to 0.03559, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.03796, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03559 to 0.03239, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03239 to 0.03183, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03183 to 0.03084, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.03152, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03084 to 0.02923, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02923 to 0.02588, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02588 to 0.02551, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02551 to 0.02517, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02517 to 0.02293, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.02314, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02293 to 0.02196, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02196 to 0.01942, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.02016, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.02048, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01942 to 0.01746, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01746 to 0.01571, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.01838, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01571 to 0.01484, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01484 to 0.01462, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01462 to 0.01306, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01306 to 0.01224, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.01324, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.01243, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.01518, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.01592, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01224 to 0.01151, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01151 to 0.01075, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.01147, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.01217, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01075 to 0.00998, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00998 to 0.00956, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.01163, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00956 to 0.00872, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00883, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00962, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.01052, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.01028, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.01088, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00905, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.01033, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.01013, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00872 to 0.00868, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00887, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00947, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.01487, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00882, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00868 to 0.00828, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00828 to 0.00820, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00874, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00921, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00884, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.01017, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00892, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00886, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00916, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00832, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00960, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00883, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00937, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00937, did not improve\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00820 to 0.00814, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00945, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00866, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00945, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00887, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00814 to 0.00810, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00974, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00949, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00993, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00886, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00859, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00902, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.01336, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00865, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00810 to 0.00809, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00809 to 0.00807, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.00886, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01028, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00923, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00904, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00908, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00142: val_loss is 0.01008, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.01029, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.01020, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00954, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00866, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00875, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00913, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00807 to 0.00774, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00998, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00972, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00984, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00774 to 0.00772, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01005, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00862, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01041, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00879, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00827, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00978, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00926, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00927, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00952, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00893, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00894, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00949, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00852, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00993, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00894, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00881, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00940, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00856, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00929, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01002, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00874, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00815, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.01002, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00985, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00841, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00964, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00910, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00984, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00976, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00858, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00850, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00814, did not improve\n",
      "Epoch 00247: early stopping\n",
      "Using epoch 00172 with val_loss: 0.00772\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03060, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03060 to 0.02954, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.03105, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02954 to 0.02854, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02854 to 0.02739, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02739 to 0.02692, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02692 to 0.02546, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02546 to 0.02425, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02425 to 0.02319, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02319 to 0.02285, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02285 to 0.02072, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02072 to 0.02070, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02070 to 0.01925, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01925 to 0.01842, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01842 to 0.01755, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01755 to 0.01681, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01681 to 0.01644, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01644 to 0.01513, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01513 to 0.01503, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01503 to 0.01415, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01415 to 0.01366, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01366 to 0.01277, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01277 to 0.01275, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.01330, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01275 to 0.01130, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.01134, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01130 to 0.01013, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.01018, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01013 to 0.00999, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00999 to 0.00913, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.00971, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00913 to 0.00887, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00887 to 0.00865, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00865 to 0.00797, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00827, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00797 to 0.00791, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00976, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_loss is 0.00923, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00791 to 0.00775, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00775 to 0.00760, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00991, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00760 to 0.00753, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00753 to 0.00716, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00716 to 0.00695, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00981, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00695 to 0.00682, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00682 to 0.00662, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00895, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00870, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00662 to 0.00662, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00662 to 0.00644, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss is 0.00931, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00985, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00644 to 0.00643, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00643 to 0.00641, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00641 to 0.00618, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00618 to 0.00596, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.01009, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00920, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00596 to 0.00562, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00847, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00864, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00909, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00862, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00843, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00663, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00196: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00562 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00832, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00551 to 0.00548, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.00548 to 0.00547, storing weights.\n",
      "\n",
      "Epoch 00308: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.00547 to 0.00531, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00824, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.00531 to 0.00521, storing weights.\n",
      "\n",
      "Epoch 00349: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00617, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00358: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.00521 to 0.00519, storing weights.\n",
      "\n",
      "Epoch 00365: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.00519 to 0.00514, storing weights.\n",
      "\n",
      "Epoch 00371: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.00514 to 0.00513, storing weights.\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.00513 to 0.00507, storing weights.\n",
      "\n",
      "Epoch 00376: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.00507 to 0.00505, storing weights.\n",
      "\n",
      "Epoch 00381: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.00505 to 0.00496, storing weights.\n",
      "\n",
      "Epoch 00385: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00514, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00871, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.00596, did not improve\n",
      "Epoch 00459: early stopping\n",
      "Using epoch 00384 with val_loss: 0.00496\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02605, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.02800, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02605 to 0.02551, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02551 to 0.02437, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.02468, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02437 to 0.02290, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02290 to 0.02215, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.02314, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02215 to 0.02166, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02166 to 0.01976, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.02044, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01976 to 0.01814, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01814 to 0.01801, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01801 to 0.01641, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01641 to 0.01554, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01554 to 0.01522, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01522 to 0.01459, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01459 to 0.01412, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01464, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01412 to 0.01227, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01227 to 0.01158, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01158 to 0.01144, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01144 to 0.01096, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01096 to 0.01054, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01054 to 0.01028, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01028 to 0.00971, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.01026, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00971 to 0.00908, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00908 to 0.00848, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00848 to 0.00846, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00896, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00846 to 0.00794, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00921, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00794 to 0.00728, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00728 to 0.00703, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00917, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00703 to 0.00701, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00701 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00667 to 0.00624, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00624 to 0.00617, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.01017, did not improve\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00617 to 0.00607, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00931, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00788, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00944, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00607 to 0.00557, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00557 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00550 to 0.00547, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00547 to 0.00535, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00535 to 0.00510, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00920, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00974, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00951, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00917, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00883, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00719, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00201: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00899, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00715, did not improve\n",
      "Epoch 00210: early stopping\n",
      "Using epoch 00135 with val_loss: 0.00510\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00593] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00772]\n",
      " [ 0.00496]\n",
      " [ 0.0051 ]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00288] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00284]\n",
      " [ 0.00188]\n",
      " [ 0.00391]]\n",
      "mse over all validation data 0.00593283374683\n",
      "path plots/mlp with dropout_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdb578dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mlp via cross validation\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_do = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, dropout=True)\n",
    "t.scatter_plot(Y, res_mlp_do['y_preds'][0], 'mlp with dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
      "evaluating with early stopping\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08864, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08864 to 0.08346, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08346 to 0.08315, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08315 to 0.08297, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08297 to 0.08224, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.08275, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08224 to 0.08080, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08080 to 0.07997, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.07997 to 0.07986, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.07986 to 0.07833, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07833 to 0.07699, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.07699 to 0.07684, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.07746, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07684 to 0.07499, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.07499 to 0.07344, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07344 to 0.07308, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.07369, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07308 to 0.07151, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07151 to 0.07005, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07005 to 0.06938, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06938 to 0.06800, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06800 to 0.06731, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.06731 to 0.06621, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06621 to 0.06579, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06579 to 0.06382, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06382 to 0.06318, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06318 to 0.06239, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06239 to 0.06127, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06127 to 0.05935, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05935 to 0.05868, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05868 to 0.05776, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05776 to 0.05675, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.05688, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.05675 to 0.05451, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05451 to 0.05346, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.05346 to 0.05270, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05270 to 0.05242, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.05242 to 0.05061, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05061 to 0.05011, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.05011 to 0.04980, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04980 to 0.04824, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04824 to 0.04803, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04803 to 0.04677, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.04677 to 0.04634, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.04636, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.04634 to 0.04484, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.04484 to 0.04446, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.04446 to 0.04443, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.04443 to 0.04340, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.04340 to 0.04323, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.04323 to 0.04235, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.04243, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.04235 to 0.04103, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.04103 to 0.04074, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.04074 to 0.04061, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.04061 to 0.03990, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.04047, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.03990 to 0.03911, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.03926, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.03971, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.03911 to 0.03883, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.03883 to 0.03833, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.03833 to 0.03817, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03817 to 0.03759, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.03896, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.03759 to 0.03723, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.03723 to 0.03653, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.03653 to 0.03606, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.03662, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.03606 to 0.03561, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03561 to 0.03507, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.03507 to 0.03499, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.03499 to 0.03474, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.03474 to 0.03436, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.03436 to 0.03411, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.03445, did not improve\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.03411 to 0.03390, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.03390 to 0.03372, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.03372 to 0.03323, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.03323 to 0.03312, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.03312 to 0.03302, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.03302 to 0.03256, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.03256 to 0.03241, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.03241 to 0.03239, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.03239 to 0.03217, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.03217 to 0.03208, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.03208 to 0.03191, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.03191 to 0.03134, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.03140, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.03187, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.03134 to 0.03104, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.03104 to 0.03073, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.03073 to 0.03026, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.03078, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.03026 to 0.03005, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.03005 to 0.02981, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02981 to 0.02953, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.02994, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.03015, did not improve\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02953 to 0.02925, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.02947, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.02949, did not improve\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02925 to 0.02889, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.02911, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.02890, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02889 to 0.02819, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.02837, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.02862, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.02840, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02819 to 0.02775, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02775 to 0.02736, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.02736 to 0.02726, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss is 0.02763, did not improve\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.02726 to 0.02725, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02725 to 0.02693, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02693 to 0.02643, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00118: val_loss is 0.02690, did not improve\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.02643 to 0.02623, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02623 to 0.02600, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02600 to 0.02585, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02585 to 0.02573, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.02627, did not improve\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02573 to 0.02564, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss is 0.02578, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.02581, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.02620, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.02564 to 0.02512, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss is 0.02527, did not improve\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.02512 to 0.02486, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss is 0.02489, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02486 to 0.02460, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.02461, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.02460 to 0.02421, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss is 0.02426, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.02427, did not improve\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.02421 to 0.02395, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02395 to 0.02379, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.02379 to 0.02358, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02358 to 0.02344, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss is 0.02350, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.02416, did not improve\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.02344 to 0.02325, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss is 0.02375, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.02325, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.02325 to 0.02292, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss is 0.02299, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.02292 to 0.02277, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.02303, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.02293, did not improve\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.02277 to 0.02270, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.02270 to 0.02239, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.02239 to 0.02233, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.02233 to 0.02203, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss is 0.02214, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.02206, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.02283, did not improve\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.02203 to 0.02178, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.02178 to 0.02176, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.02176 to 0.02149, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss is 0.02158, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.02180, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.02155, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.02149 to 0.02104, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.02104 to 0.02096, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.02134, did not improve\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.02096 to 0.02076, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.02106, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.02078, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.02078, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.02098, did not improve\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.02076 to 0.02045, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.02045 to 0.02021, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss is 0.02079, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.02027, did not improve\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.02021 to 0.02004, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.02004 to 0.01991, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.01991 to 0.01981, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.01981 to 0.01979, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss is 0.01998, did not improve\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.01979 to 0.01975, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01975 to 0.01944, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.01944 to 0.01935, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.01935 to 0.01929, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss is 0.01940, did not improve\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.01929 to 0.01918, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.01918 to 0.01905, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss is 0.01948, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01913, did not improve\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.01905 to 0.01889, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.01889 to 0.01880, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.01880 to 0.01866, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss is 0.01908, did not improve\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.01866 to 0.01852, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.01852 to 0.01846, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss is 0.01848, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01851, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.01846 to 0.01825, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.01825 to 0.01819, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss is 0.01843, did not improve\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.01819 to 0.01803, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.01803 to 0.01795, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.01795 to 0.01788, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.01788 to 0.01785, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.01785 to 0.01783, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.01783 to 0.01763, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.01763 to 0.01751, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss is 0.01782, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01791, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01860, did not improve\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.01751 to 0.01737, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.01737 to 0.01732, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss is 0.01751, did not improve\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.01732 to 0.01723, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.01723 to 0.01712, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.01712 to 0.01711, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss is 0.01718, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.01711 to 0.01710, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss is 0.01740, did not improve\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.01710 to 0.01688, storing weights.\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.01688 to 0.01669, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss is 0.01670, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01736, did not improve\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.01669 to 0.01667, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.01667 to 0.01661, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.01661 to 0.01647, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss is 0.01762, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01679, did not improve\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.01647 to 0.01640, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.01640 to 0.01625, storing weights.\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.01625 to 0.01618, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.01618 to 0.01612, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss is 0.01684, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.01613, did not improve\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.01612 to 0.01591, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss is 0.01616, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01593, did not improve\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.01591 to 0.01581, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss is 0.01627, did not improve\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.01581 to 0.01578, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss is 0.01600, did not improve\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.01578 to 0.01567, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.01567 to 0.01559, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.01559 to 0.01555, storing weights.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.01555 to 0.01543, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.01543 to 0.01538, storing weights.\n",
      "\n",
      "Epoch 00247: val_loss is 0.01552, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00248: val_loss improved from 0.01538 to 0.01534, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss is 0.01574, did not improve\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.01534 to 0.01521, storing weights.\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.01521 to 0.01513, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss is 0.01641, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01517, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.01513 to 0.01501, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss is 0.01526, did not improve\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.01501 to 0.01499, storing weights.\n",
      "\n",
      "Epoch 00257: val_loss is 0.01512, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01521, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01619, did not improve\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.01499 to 0.01490, storing weights.\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.01490 to 0.01487, storing weights.\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.01487 to 0.01475, storing weights.\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.01475 to 0.01463, storing weights.\n",
      "\n",
      "Epoch 00264: val_loss is 0.01480, did not improve\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.01463 to 0.01452, storing weights.\n",
      "\n",
      "Epoch 00266: val_loss is 0.01494, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01488, did not improve\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.01452 to 0.01449, storing weights.\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.01449 to 0.01439, storing weights.\n",
      "\n",
      "Epoch 00270: val_loss is 0.01467, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.01439 to 0.01426, storing weights.\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.01426 to 0.01423, storing weights.\n",
      "\n",
      "Epoch 00274: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01450, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01453, did not improve\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.01423 to 0.01413, storing weights.\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.01413 to 0.01410, storing weights.\n",
      "\n",
      "Epoch 00279: val_loss is 0.01438, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01425, did not improve\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.01410 to 0.01401, storing weights.\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.01401 to 0.01393, storing weights.\n",
      "\n",
      "Epoch 00283: val_loss is 0.01408, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01393, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01426, did not improve\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.01393 to 0.01389, storing weights.\n",
      "\n",
      "Epoch 00287: val_loss is 0.01429, did not improve\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.01389 to 0.01385, storing weights.\n",
      "\n",
      "Epoch 00289: val_loss is 0.01401, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.01387, did not improve\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.01385 to 0.01362, storing weights.\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.01362 to 0.01358, storing weights.\n",
      "\n",
      "Epoch 00293: val_loss is 0.01362, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01373, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01360, did not improve\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.01358 to 0.01351, storing weights.\n",
      "\n",
      "Epoch 00297: val_loss is 0.01420, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01394, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01434, did not improve\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.01351 to 0.01339, storing weights.\n",
      "\n",
      "Epoch 00301: val_loss is 0.01352, did not improve\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.01339 to 0.01338, storing weights.\n",
      "\n",
      "Epoch 00303: val_loss is 0.01342, did not improve\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.01338 to 0.01321, storing weights.\n",
      "\n",
      "Epoch 00305: val_loss is 0.01478, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01345, did not improve\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.01321 to 0.01318, storing weights.\n",
      "\n",
      "Epoch 00308: val_loss is 0.01347, did not improve\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.01318 to 0.01317, storing weights.\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.01317 to 0.01312, storing weights.\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.01312 to 0.01304, storing weights.\n",
      "\n",
      "Epoch 00312: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.01387, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.01333, did not improve\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.01304 to 0.01299, storing weights.\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.01299 to 0.01297, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.01297 to 0.01285, storing weights.\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.01285 to 0.01278, storing weights.\n",
      "\n",
      "Epoch 00322: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.01278 to 0.01277, storing weights.\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.01277 to 0.01275, storing weights.\n",
      "\n",
      "Epoch 00325: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01289, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01354, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.01275 to 0.01264, storing weights.\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.01264 to 0.01258, storing weights.\n",
      "\n",
      "Epoch 00332: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01274, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.01262, did not improve\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.01258 to 0.01255, storing weights.\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.01255 to 0.01250, storing weights.\n",
      "\n",
      "Epoch 00337: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.01250 to 0.01249, storing weights.\n",
      "\n",
      "Epoch 00339: val_loss is 0.01251, did not improve\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.01249 to 0.01243, storing weights.\n",
      "\n",
      "Epoch 00341: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.01243 to 0.01235, storing weights.\n",
      "\n",
      "Epoch 00343: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.01235 to 0.01233, storing weights.\n",
      "\n",
      "Epoch 00345: val_loss is 0.01254, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01257, did not improve\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.01233 to 0.01231, storing weights.\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.01231 to 0.01224, storing weights.\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.01224 to 0.01222, storing weights.\n",
      "\n",
      "Epoch 00350: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.01222 to 0.01218, storing weights.\n",
      "\n",
      "Epoch 00352: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.01218 to 0.01211, storing weights.\n",
      "\n",
      "Epoch 00355: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.01211 to 0.01207, storing weights.\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.01207 to 0.01204, storing weights.\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.01204 to 0.01202, storing weights.\n",
      "\n",
      "Epoch 00361: val_loss is 0.01205, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.01202 to 0.01199, storing weights.\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.01199 to 0.01198, storing weights.\n",
      "\n",
      "Epoch 00365: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01210, did not improve\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.01198 to 0.01195, storing weights.\n",
      "\n",
      "Epoch 00368: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01272, did not improve\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.01195 to 0.01193, storing weights.\n",
      "\n",
      "Epoch 00371: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.01193 to 0.01185, storing weights.\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.01185 to 0.01185, storing weights.\n",
      "\n",
      "Epoch 00375: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.01185 to 0.01185, storing weights.\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.01185 to 0.01179, storing weights.\n",
      "\n",
      "Epoch 00383: val_loss is 0.01193, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00384: val_loss improved from 0.01179 to 0.01165, storing weights.\n",
      "\n",
      "Epoch 00385: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.01165 to 0.01163, storing weights.\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.01163 to 0.01161, storing weights.\n",
      "\n",
      "Epoch 00390: val_loss is 0.01216, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.01161 to 0.01154, storing weights.\n",
      "\n",
      "Epoch 00396: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01221, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01321, did not improve\n",
      "\n",
      "Epoch 00402: val_loss improved from 0.01154 to 0.01147, storing weights.\n",
      "\n",
      "Epoch 00403: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01223, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.01147 to 0.01137, storing weights.\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.01137 to 0.01132, storing weights.\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.01132 to 0.01128, storing weights.\n",
      "\n",
      "Epoch 00413: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01257, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.01128 to 0.01128, storing weights.\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.01128 to 0.01125, storing weights.\n",
      "\n",
      "Epoch 00421: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01131, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.01125 to 0.01122, storing weights.\n",
      "\n",
      "Epoch 00425: val_loss improved from 0.01122 to 0.01121, storing weights.\n",
      "\n",
      "Epoch 00426: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.01121 to 0.01116, storing weights.\n",
      "\n",
      "Epoch 00430: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.01116 to 0.01110, storing weights.\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.01110 to 0.01105, storing weights.\n",
      "\n",
      "Epoch 00437: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.01203, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.01105 to 0.01101, storing weights.\n",
      "\n",
      "Epoch 00448: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.01329, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00456: val_loss improved from 0.01101 to 0.01097, storing weights.\n",
      "\n",
      "Epoch 00457: val_loss is 0.01110, did not improve\n",
      "\n",
      "Epoch 00458: val_loss improved from 0.01097 to 0.01093, storing weights.\n",
      "\n",
      "Epoch 00459: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.01093 to 0.01093, storing weights.\n",
      "\n",
      "Epoch 00465: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.01171, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.01093 to 0.01088, storing weights.\n",
      "\n",
      "Epoch 00474: val_loss improved from 0.01088 to 0.01084, storing weights.\n",
      "\n",
      "Epoch 00475: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00479: val_loss improved from 0.01084 to 0.01080, storing weights.\n",
      "\n",
      "Epoch 00480: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00483: val_loss improved from 0.01080 to 0.01076, storing weights.\n",
      "\n",
      "Epoch 00484: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00491: val_loss improved from 0.01076 to 0.01075, storing weights.\n",
      "\n",
      "Epoch 00492: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.01086, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.01084, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.01075 to 0.01073, storing weights.\n",
      "\n",
      "Epoch 00498: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00501: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.01073 to 0.01069, storing weights.\n",
      "\n",
      "Epoch 00504: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.01115, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00514: val_loss improved from 0.01069 to 0.01062, storing weights.\n",
      "\n",
      "Epoch 00515: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00519: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00520: val_loss improved from 0.01062 to 0.01061, storing weights.\n",
      "\n",
      "Epoch 00521: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.01061 to 0.01059, storing weights.\n",
      "\n",
      "Epoch 00529: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00530: val_loss improved from 0.01059 to 0.01058, storing weights.\n",
      "\n",
      "Epoch 00531: val_loss is 0.01097, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00532: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.01247, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00547: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00552: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.01058 to 0.01056, storing weights.\n",
      "\n",
      "Epoch 00554: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00555: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00556: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00557: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00558: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.01164, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00568: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00569: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00570: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00571: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00572: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00573: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00574: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00575: val_loss improved from 0.01056 to 0.01056, storing weights.\n",
      "\n",
      "Epoch 00576: val_loss is 0.01086, did not improve\n",
      "\n",
      "Epoch 00577: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00578: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00579: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.01086, did not improve\n",
      "\n",
      "Epoch 00581: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00582: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.01237, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00588: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00589: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00590: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00591: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00592: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00593: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00594: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00595: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00596: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00597: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00598: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00599: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00600: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00601: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00602: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00603: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00604: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00605: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00606: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00607: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00608: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00609: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00610: val_loss is 0.01084, did not improve\n",
      "\n",
      "Epoch 00611: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00612: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00613: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00614: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00615: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00616: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00617: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00618: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00619: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00620: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00621: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00622: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00623: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00624: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00625: val_loss improved from 0.01056 to 0.01049, storing weights.\n",
      "\n",
      "Epoch 00626: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00627: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00628: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00629: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00630: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00631: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00632: val_loss improved from 0.01049 to 0.01046, storing weights.\n",
      "\n",
      "Epoch 00633: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00634: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00635: val_loss is 0.01052, did not improve\n",
      "\n",
      "Epoch 00636: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00637: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00638: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00639: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00640: val_loss is 0.01081, did not improve\n",
      "\n",
      "Epoch 00641: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00642: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00643: val_loss is 0.01088, did not improve\n",
      "\n",
      "Epoch 00644: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00645: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00646: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00647: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00648: val_loss is 0.01050, did not improve\n",
      "\n",
      "Epoch 00649: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00650: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00651: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00652: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00653: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00654: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00655: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00656: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00657: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00658: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00659: val_loss is 0.01347, did not improve\n",
      "\n",
      "Epoch 00660: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00661: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00662: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00663: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00664: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00665: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00666: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00667: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00668: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00669: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00670: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00671: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00672: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00673: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00674: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00675: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00676: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00677: val_loss is 0.01131, did not improve\n",
      "\n",
      "Epoch 00678: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00679: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00680: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00681: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00682: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00683: val_loss is 0.01243, did not improve\n",
      "\n",
      "Epoch 00684: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00685: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00686: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00687: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00688: val_loss is 0.01088, did not improve\n",
      "\n",
      "Epoch 00689: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00690: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00691: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00692: val_loss is 0.01072, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00693: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00694: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00695: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00696: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00697: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00698: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00699: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00700: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00701: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00702: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00703: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00704: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00705: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00706: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00707: val_loss is 0.01062, did not improve\n",
      "Epoch 00707: early stopping\n",
      "Using epoch 00632 with val_loss: 0.01046\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06741, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06741 to 0.06671, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06671 to 0.06524, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06524 to 0.06461, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06461 to 0.06424, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06424 to 0.06365, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06365 to 0.06342, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06342 to 0.06202, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06202 to 0.06096, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.06096 to 0.06024, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06024 to 0.05951, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05951 to 0.05845, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05845 to 0.05789, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05789 to 0.05672, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05672 to 0.05629, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05629 to 0.05511, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05511 to 0.05415, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.05415 to 0.05347, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05347 to 0.05244, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05244 to 0.05176, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05176 to 0.05139, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05139 to 0.05025, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.05047, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.05025 to 0.04984, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.06437, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04984 to 0.04711, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.04711 to 0.04635, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.04733, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.04654, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.04635 to 0.04411, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04411 to 0.04374, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04374 to 0.04313, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04313 to 0.04274, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04274 to 0.04225, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04225 to 0.04174, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.06660, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04174 to 0.04118, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04118 to 0.04012, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04012 to 0.03950, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.03960, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.03950 to 0.03868, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03868 to 0.03847, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.06111, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03847 to 0.03840, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.04014, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03840 to 0.03714, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03714 to 0.03644, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03644 to 0.03640, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.04262, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.03705, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03640 to 0.03540, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03540 to 0.03486, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.03486 to 0.03474, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03474 to 0.03443, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.03683, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.03443 to 0.03400, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.03416, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.03400 to 0.03353, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.03353 to 0.03329, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.03329 to 0.03289, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.04438, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.04564, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.03411, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.03477, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.04525, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.03289 to 0.03230, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.03230 to 0.03209, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.03209 to 0.03161, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.03161 to 0.03100, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.05525, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.04174, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.03100 to 0.03029, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.03029 to 0.03016, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.03016 to 0.02984, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.02984 to 0.02966, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.02966 to 0.02957, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.03972, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.02957 to 0.02942, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.02942 to 0.02920, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.02920 to 0.02896, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.02896 to 0.02866, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.02867, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.02866 to 0.02818, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.02909, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.02818 to 0.02794, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.02815, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.02794 to 0.02740, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.02740 to 0.02722, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.03138, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.02750, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.05152, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.02722 to 0.02690, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.02690 to 0.02668, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.03311, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.02723, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.02668 to 0.02631, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.02631 to 0.02600, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.02600 to 0.02575, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss is 0.02580, did not improve\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.02575 to 0.02520, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.03355, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.02520 to 0.02514, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.02514 to 0.02474, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.02477, did not improve\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.02474 to 0.02438, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02438 to 0.02430, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.02855, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.02430 to 0.02375, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss is 0.02427, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.02389, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.02375 to 0.02361, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02361 to 0.02342, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00113: val_loss improved from 0.02342 to 0.02326, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss is 0.02372, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.02601, did not improve\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.02326 to 0.02316, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss is 0.02337, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.02316 to 0.02284, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.02388, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02284 to 0.02264, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02264 to 0.02226, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.02226 to 0.02220, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.02309, did not improve\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.02220 to 0.02215, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss is 0.02229, did not improve\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02215 to 0.02193, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.02193 to 0.02170, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss is 0.02208, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.03500, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.02235, did not improve\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.02170 to 0.02112, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss is 0.02522, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.02117, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.02112 to 0.02092, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss is 0.03149, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.03569, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.03318, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.02100, did not improve\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.02092 to 0.02080, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.02080 to 0.02034, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss is 0.02327, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.02070, did not improve\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.02034 to 0.02032, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.02032 to 0.01979, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.02008, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01979 to 0.01965, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss is 0.01977, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.04678, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.01977, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01989, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01975, did not improve\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.01965 to 0.01929, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01929 to 0.01892, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01892 to 0.01857, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss is 0.02051, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.01878, did not improve\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.01857 to 0.01847, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.01847 to 0.01827, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss is 0.01875, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01908, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.03995, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01911, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01860, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.01837, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.01942, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.01842, did not improve\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.01827 to 0.01822, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.01822 to 0.01792, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.01792 to 0.01759, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss is 0.02119, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.04396, did not improve\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.01759 to 0.01735, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.01735 to 0.01717, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss is 0.01722, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.01722, did not improve\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.01717 to 0.01693, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.01693 to 0.01693, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss is 0.01724, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01754, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.02936, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01695, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01693 to 0.01660, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.01678, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01682, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01756, did not improve\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.01660 to 0.01637, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss is 0.01804, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01727, did not improve\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.01637 to 0.01605, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss is 0.01620, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.01700, did not improve\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.01605 to 0.01600, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss is 0.01617, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.04747, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.04374, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01633, did not improve\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.01600 to 0.01577, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss is 0.01593, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.01589, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01578, did not improve\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.01577 to 0.01556, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss is 0.01583, did not improve\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.01556 to 0.01517, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss is 0.01535, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01527, did not improve\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.01517 to 0.01512, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.01512 to 0.01503, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss is 0.01562, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.04707, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01713, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01573, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01650, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.02080, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01520, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.03134, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01524, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01632, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01541, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.01525, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01646, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01571, did not improve\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.01503 to 0.01461, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss is 0.01528, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.04053, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01609, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.03252, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01560, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01535, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01889, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01515, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01804, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.01491, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.01745, did not improve\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.01461 to 0.01438, storing weights.\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.01438 to 0.01403, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss is 0.01414, did not improve\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.01403 to 0.01398, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss is 0.01426, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01717, did not improve\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.01398 to 0.01379, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss is 0.01387, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01389, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01389, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01425, did not improve\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.01379 to 0.01356, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss is 0.01411, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.03369, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01638, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01490, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.03611, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.01372, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.04511, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01435, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.01356 to 0.01333, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00255: val_loss is 0.01354, did not improve\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.01333 to 0.01326, storing weights.\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.01326 to 0.01316, storing weights.\n",
      "\n",
      "Epoch 00258: val_loss is 0.04131, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01418, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01588, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01323, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.01320, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.01364, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.01382, did not improve\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.01316 to 0.01299, storing weights.\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.01299 to 0.01297, storing weights.\n",
      "\n",
      "Epoch 00267: val_loss is 0.01332, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01318, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01328, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01345, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01339, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01308, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.01346, did not improve\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.01297 to 0.01288, storing weights.\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.01288 to 0.01267, storing weights.\n",
      "\n",
      "Epoch 00276: val_loss is 0.01326, did not improve\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.01267 to 0.01243, storing weights.\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.01243 to 0.01242, storing weights.\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.01242 to 0.01239, storing weights.\n",
      "\n",
      "Epoch 00280: val_loss is 0.01251, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.01302, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.01909, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01288, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01293, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.01239 to 0.01224, storing weights.\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.01224 to 0.01215, storing weights.\n",
      "\n",
      "Epoch 00290: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01522, did not improve\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.01215 to 0.01206, storing weights.\n",
      "\n",
      "Epoch 00294: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01281, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01272, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01226, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.05402, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01405, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.02358, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01366, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.01206 to 0.01195, storing weights.\n",
      "\n",
      "Epoch 00307: val_loss is 0.06415, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.01201, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.03386, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01546, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.01265, did not improve\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.01195 to 0.01160, storing weights.\n",
      "\n",
      "Epoch 00314: val_loss is 0.01555, did not improve\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.01160 to 0.01146, storing weights.\n",
      "\n",
      "Epoch 00316: val_loss is 0.01339, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.04233, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01771, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01434, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.03882, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01394, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01236, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01312, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01261, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01258, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.01404, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01259, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.01414, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.01146 to 0.01133, storing weights.\n",
      "\n",
      "Epoch 00348: val_loss is 0.03861, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01229, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.05035, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.01285, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.03363, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01955, did not improve\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.01133 to 0.01117, storing weights.\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.01117 to 0.01095, storing weights.\n",
      "\n",
      "Epoch 00364: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.02790, did not improve\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.01095 to 0.01076, storing weights.\n",
      "\n",
      "Epoch 00374: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01115, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01349, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.01257, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01199, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.01182, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.01137, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.01115, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.01438, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01118, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00409: val_loss is 0.01111, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.01112, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.01115, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.01134, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.04948, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.01437, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.02345, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.01135, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.01396, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.01177, did not improve\n",
      "Epoch 00448: early stopping\n",
      "Using epoch 00373 with val_loss: 0.01076\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06286, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.07822, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 0.07988, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 0.06549, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06286 to 0.06028, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.07464, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06028 to 0.05866, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05866 to 0.05742, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05742 to 0.05663, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.05843, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.05663 to 0.05505, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.05531, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05505 to 0.05399, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.05399 to 0.05336, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05336 to 0.05269, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.05303, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.05269 to 0.05126, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.05179, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05126 to 0.05036, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.06398, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.05036 to 0.05034, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.05034 to 0.04954, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04954 to 0.04784, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04784 to 0.04713, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.04713, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04713 to 0.04535, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.06239, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.04535 to 0.04515, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.04515 to 0.04424, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.04517, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.04424 to 0.04233, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04233 to 0.04170, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04170 to 0.04160, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04160 to 0.04054, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.05521, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.04062, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.04275, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.04157, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04054 to 0.03909, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.03909 to 0.03755, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.03776, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03755 to 0.03745, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.03745 to 0.03729, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03729 to 0.03684, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.03695, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03684 to 0.03644, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03644 to 0.03614, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03614 to 0.03602, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.03602 to 0.03553, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.03632, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03553 to 0.03544, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03544 to 0.03539, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.03539 to 0.03535, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03535 to 0.03485, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.03485 to 0.03432, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.03432 to 0.03410, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.03463, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.03751, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.03410 to 0.03299, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.03308, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.03299 to 0.03279, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.03378, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.03332, did not improve\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.03279 to 0.03216, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.03219, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.03216 to 0.03172, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.03215, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.03172 to 0.03140, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.03140 to 0.03109, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.03122, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.03109 to 0.03092, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.03384, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.03092 to 0.03047, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.03083, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.03062, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.03047 to 0.02988, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.03025, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.02990, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.03068, did not improve\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.02988 to 0.02962, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.02962 to 0.02902, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.02902 to 0.02875, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss is 0.02934, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.02939, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.02875 to 0.02859, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.02917, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.02859 to 0.02819, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.02819 to 0.02804, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.02804 to 0.02780, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.02780 to 0.02761, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.02761 to 0.02737, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.02737 to 0.02712, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.02713, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.02887, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.02712 to 0.02676, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00097: val_loss is 0.02679, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.02772, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.02676 to 0.02604, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.02615, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.02670, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.02604 to 0.02598, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss is 0.02628, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.02598 to 0.02555, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.02782, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.02555 to 0.02532, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.02557, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.02859, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.02532 to 0.02502, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.02524, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.02539, did not improve\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.02502 to 0.02449, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss is 0.03337, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.02449 to 0.02385, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss is 0.02556, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.02412, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.02385 to 0.02372, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.02512, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.03332, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.02372 to 0.02330, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.02330 to 0.02299, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss is 0.02314, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.02299 to 0.02290, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss is 0.02335, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.02429, did not improve\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.02290 to 0.02271, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss is 0.02426, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.02352, did not improve\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.02271 to 0.02227, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss is 0.02233, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.02283, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.02227 to 0.02221, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.02232, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.02285, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.02376, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.02266, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.03213, did not improve\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.02221 to 0.02103, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.02132, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.02188, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.02152, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.02167, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.02192, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.02214, did not improve\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.02103 to 0.02066, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss is 0.02335, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.02121, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.02066 to 0.02038, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.03632, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.02180, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.02356, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.02264, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.02038 to 0.02022, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.02023, did not improve\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.02022 to 0.02009, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.02009 to 0.02003, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.02122, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.02096, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.02003 to 0.01977, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.01977 to 0.01960, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.01960 to 0.01953, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss is 0.02014, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.05389, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.01994, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.01953 to 0.01921, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.01921 to 0.01831, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.01975, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.01888, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01992, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.01897, did not improve\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.01831 to 0.01792, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss is 0.01855, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01846, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.02094, did not improve\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.01792 to 0.01771, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss is 0.01856, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01800, did not improve\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.01771 to 0.01758, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss is 0.01809, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.01790, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01794, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01758 to 0.01721, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.01721 to 0.01718, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.01718 to 0.01716, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.01716 to 0.01698, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss is 0.01884, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.04227, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01841, did not improve\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.01698 to 0.01676, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss is 0.01684, did not improve\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.01676 to 0.01667, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.01667 to 0.01666, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss is 0.03129, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01691, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01683, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01730, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01777, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.01666 to 0.01623, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss is 0.01836, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01928, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01665, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.01623 to 0.01591, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.01591 to 0.01559, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss is 0.01632, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01649, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.01616, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.05359, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01605, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01595, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01640, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01570, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.04092, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01684, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01629, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01973, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01592, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01656, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.01573, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01584, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01704, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.01903, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01701, did not improve\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.01559 to 0.01544, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.01544 to 0.01500, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss is 0.01595, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01545, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01579, did not improve\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.01500 to 0.01490, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss is 0.01507, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01511, did not improve\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.01490 to 0.01437, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss is 0.01450, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.01489, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.01681, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01574, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01711, did not improve\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.01437 to 0.01430, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.01430 to 0.01416, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00240: val_loss is 0.01430, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.01467, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01530, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01508, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01548, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01446, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01626, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01456, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01440, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01472, did not improve\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.01416 to 0.01388, storing weights.\n",
      "\n",
      "Epoch 00251: val_loss is 0.01545, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01552, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01649, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.01388 to 0.01370, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.01370 to 0.01358, storing weights.\n",
      "\n",
      "Epoch 00256: val_loss is 0.01427, did not improve\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.01358 to 0.01334, storing weights.\n",
      "\n",
      "Epoch 00258: val_loss is 0.01443, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01363, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01422, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.08354, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.01673, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.01447, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.01362, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.03947, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01395, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01339, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01368, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01378, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01368, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01339, did not improve\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.01334 to 0.01268, storing weights.\n",
      "\n",
      "Epoch 00274: val_loss is 0.01458, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01306, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01349, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.01322, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.01408, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.01432, did not improve\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.01268 to 0.01262, storing weights.\n",
      "\n",
      "Epoch 00281: val_loss is 0.04552, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.01399, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01390, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01435, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01440, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01342, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.01262 to 0.01241, storing weights.\n",
      "\n",
      "Epoch 00289: val_loss is 0.01382, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.02450, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01279, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.02968, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01358, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01516, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01436, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01334, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.01293, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01366, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01460, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.01241 to 0.01230, storing weights.\n",
      "\n",
      "Epoch 00305: val_loss is 0.01262, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01320, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.01641, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.01421, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01292, did not improve\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.01230 to 0.01214, storing weights.\n",
      "\n",
      "Epoch 00313: val_loss is 0.01322, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.01214 to 0.01212, storing weights.\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.01212 to 0.01186, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01276, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.04189, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.14099, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.01186 to 0.01178, storing weights.\n",
      "\n",
      "Epoch 00328: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01231, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01347, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01269, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.07708, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01385, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.01271, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.01445, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01394, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01410, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.02007, did not improve\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.01178 to 0.01138, storing weights.\n",
      "\n",
      "Epoch 00342: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01277, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01259, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01211, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01247, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01285, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.01226, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.01138 to 0.01122, storing weights.\n",
      "\n",
      "Epoch 00358: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01653, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.01225, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01231, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01351, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.03013, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01274, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.01281, did not improve\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.01122 to 0.01122, storing weights.\n",
      "\n",
      "Epoch 00375: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.04480, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01225, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01318, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01461, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01262, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01707, did not improve\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.01122 to 0.01111, storing weights.\n",
      "\n",
      "Epoch 00386: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.01134, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.01111 to 0.01096, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00396: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.01163, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.01342, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.01164, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01271, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.01385, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.01334, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01135, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.01264, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.01164, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.01264, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.01328, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.01480, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.01689, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00446: val_loss improved from 0.01096 to 0.01061, storing weights.\n",
      "\n",
      "Epoch 00447: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.01210, did not improve\n",
      "\n",
      "Epoch 00449: val_loss improved from 0.01061 to 0.01060, storing weights.\n",
      "\n",
      "Epoch 00450: val_loss is 0.01338, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.05473, did not improve\n",
      "\n",
      "Epoch 00453: val_loss improved from 0.01060 to 0.01015, storing weights.\n",
      "\n",
      "Epoch 00454: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.01386, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.01353, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.01040, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.01428, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.01347, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.01015 to 0.01002, storing weights.\n",
      "\n",
      "Epoch 00472: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.02171, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.01332, did not improve\n",
      "\n",
      "Epoch 00479: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.01338, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.01215, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.01567, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.01727, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.01137, did not improve\n",
      "\n",
      "Epoch 00497: val_loss is 0.01352, did not improve\n",
      "\n",
      "Epoch 00498: val_loss is 0.01454, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.01195, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00501: val_loss is 0.04627, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00504: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.01256, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.01356, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.04087, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00514: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.01183, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00519: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00520: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00521: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.04612, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.01149, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.04818, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00530: val_loss is 0.01292, did not improve\n",
      "\n",
      "Epoch 00531: val_loss is 0.01237, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.01249, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.01182, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.01382, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.01386, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.01216, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.01134, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.01221, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.03125, did not improve\n",
      "Epoch 00546: early stopping\n",
      "Using epoch 00471 with val_loss: 0.01002\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00628] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00699]\n",
      " [ 0.0059 ]\n",
      " [ 0.00595]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.0034] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00297]\n",
      " [ 0.0042 ]\n",
      " [ 0.00303]]\n",
      "mse over all validation data 0.00628485497844\n",
      "path plots/mlp_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effddc86198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cfg = {'lr': 0.2213474827989724, 'batch_size': 20, 'l1': 0.0005, 'l2': 0.0005} \n",
    "# config found by hyperband on L1L2 case\n",
    "cfg = {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
    "res_mlp_l1l2 = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, L1L2=True)\n",
    "t.scatter_plot(Y, res_mlp_l1l2['y_preds'][0], 'mlp L1L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path plots/mlp L1L2_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effde0a4be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.scatter_plot(Y, res_mlp_l1l2, 'mlp L1L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'lr': 0.2213474827989724, 'batch_size': 20, 'l2': 0.0005, 'l1': 0.0005}\n",
      "evaluating with early stopping\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13878, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13878 to 0.13441, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13441 to 0.13311, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13311 to 0.12898, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12898 to 0.12612, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12612 to 0.12332, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12332 to 0.12179, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12179 to 0.11723, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11723 to 0.11458, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11458 to 0.11094, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.11159, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.11094 to 0.10704, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10704 to 0.10298, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10298 to 0.09987, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09987 to 0.09763, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09763 to 0.09566, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09566 to 0.09190, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09190 to 0.09067, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09067 to 0.08468, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08468 to 0.08131, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08131 to 0.07876, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.07936, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07876 to 0.07391, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.07391 to 0.07179, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.07274, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07179 to 0.06694, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.06719, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06694 to 0.06254, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06254 to 0.06189, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06189 to 0.05762, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05762 to 0.05643, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05643 to 0.05382, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.05598, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.05382 to 0.05181, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05181 to 0.04973, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04973 to 0.04836, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04836 to 0.04614, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.04641, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04614 to 0.04497, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04497 to 0.04257, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04257 to 0.04066, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04066 to 0.04062, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04062 to 0.03852, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03852 to 0.03753, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03753 to 0.03734, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03734 to 0.03710, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03710 to 0.03538, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03538 to 0.03534, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.03559, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03534 to 0.03295, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03295 to 0.03158, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03158 to 0.03145, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.03145 to 0.03029, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.03115, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.03029 to 0.02868, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02868 to 0.02785, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.02840, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.02815, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02785 to 0.02677, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02677 to 0.02572, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.02631, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.02598, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.02740, did not improve\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02572 to 0.02377, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02377 to 0.02319, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02319 to 0.02265, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.02307, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.02290, did not improve\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.02265 to 0.02206, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02206 to 0.02113, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.02147, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.02171, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.02113 to 0.02090, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.02291, did not improve\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.02090 to 0.01963, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.01964, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.02112, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.01963 to 0.01910, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.01910 to 0.01869, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01869 to 0.01820, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss is 0.01830, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.02027, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.01820 to 0.01791, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.02002, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.01833, did not improve\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.01791 to 0.01723, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.01740, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.01840, did not improve\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.01723 to 0.01676, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.01676 to 0.01643, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.01728, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.01645, did not improve\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.01643 to 0.01583, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.02016, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.01583 to 0.01551, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss is 0.01596, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.01743, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.01563, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.01725, did not improve\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01551 to 0.01509, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.01509 to 0.01475, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss is 0.01476, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.01776, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.01508, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.01489, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.01479, did not improve\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.01475 to 0.01474, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss is 0.01537, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.01474 to 0.01414, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.01414 to 0.01404, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.01517, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01404 to 0.01401, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01401 to 0.01387, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.01409, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.01405, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01387 to 0.01374, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.01374 to 0.01353, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.01400, did not improve\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01353 to 0.01332, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.01391, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_loss is 0.01502, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01332 to 0.01315, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01315 to 0.01315, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss is 0.01368, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.01610, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.01481, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.01406, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.01569, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01315 to 0.01286, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.01411, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01777, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01511, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.02091, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01386, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01286 to 0.01257, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.01482, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01264, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.01341, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01439, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01933, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.02194, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01257 to 0.01229, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.01229 to 0.01227, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss is 0.01237, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.01336, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.01261, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.01227 to 0.01214, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01226, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01243, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.01214 to 0.01203, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss is 0.01532, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.01215, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01455, did not improve\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.01203 to 0.01201, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01426, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01370, did not improve\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.01201 to 0.01193, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.01203, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01205, did not improve\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.01193 to 0.01187, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01320, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01210, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.01187 to 0.01183, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.01183 to 0.01178, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01268, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.01182, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.01231, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01636, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01539, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.01441, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01225, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01358, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.01178 to 0.01157, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.01157 to 0.01152, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.01152 to 0.01148, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.01148 to 0.01144, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss is 0.01257, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01147, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01171, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01293, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.01144 to 0.01142, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.01142 to 0.01133, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.01133 to 0.01132, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss is 0.01293, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.01132 to 0.01128, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss is 0.01264, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01706, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.01128 to 0.01121, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.01121 to 0.01118, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss is 0.01423, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01135, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01316, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01651, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.01118 to 0.01115, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss is 0.01369, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01288, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01683, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01137, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01719, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01210, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.01115 to 0.01113, storing weights.\n",
      "\n",
      "Epoch 00264: val_loss is 0.01231, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.01113 to 0.01110, storing weights.\n",
      "\n",
      "Epoch 00268: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01405, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.01147, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00274: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.01110 to 0.01106, storing weights.\n",
      "\n",
      "Epoch 00277: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.01106 to 0.01106, storing weights.\n",
      "\n",
      "Epoch 00279: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.01394, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.01115, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01604, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.01349, did not improve\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.01106 to 0.01106, storing weights.\n",
      "\n",
      "Epoch 00290: val_loss is 0.01300, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.01110, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01450, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01677, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01264, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.01356, did not improve\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.01106 to 0.01096, storing weights.\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.01096 to 0.01095, storing weights.\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.01095 to 0.01095, storing weights.\n",
      "\n",
      "Epoch 00304: val_loss is 0.01981, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01111, did not improve\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.01095 to 0.01091, storing weights.\n",
      "\n",
      "Epoch 00308: val_loss is 0.01337, did not improve\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.01091 to 0.01089, storing weights.\n",
      "\n",
      "Epoch 00310: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.01089 to 0.01080, storing weights.\n",
      "\n",
      "Epoch 00313: val_loss is 0.01081, did not improve\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.01080 to 0.01076, storing weights.\n",
      "\n",
      "Epoch 00315: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.01190, did not improve\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.01076 to 0.01065, storing weights.\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.01065 to 0.01057, storing weights.\n",
      "\n",
      "Epoch 00320: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.01624, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.01104, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01385, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01369, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01255, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.01057 to 0.01053, storing weights.\n",
      "\n",
      "Epoch 00337: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01440, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01211, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.01053 to 0.01048, storing weights.\n",
      "\n",
      "Epoch 00353: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.01048 to 0.01045, storing weights.\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.01045 to 0.01043, storing weights.\n",
      "\n",
      "Epoch 00356: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01504, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01251, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01910, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01221, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.01275, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01372, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01316, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.01081, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01638, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01289, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01347, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.01624, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.01302, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01852, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.01046, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.02943, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01430, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01550, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.01326, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.01363, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01247, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.01198, did not improve\n",
      "Epoch 00430: early stopping\n",
      "Using epoch 00355 with val_loss: 0.01043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12250, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12250 to 0.11789, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11789 to 0.11508, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11508 to 0.11202, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11202 to 0.10928, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10928 to 0.10618, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10618 to 0.10392, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10392 to 0.10027, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10027 to 0.09770, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09770 to 0.09396, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09396 to 0.09140, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09140 to 0.08981, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08981 to 0.08741, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08741 to 0.08393, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08393 to 0.08024, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08024 to 0.07783, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07783 to 0.07630, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07630 to 0.07607, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07607 to 0.07209, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07209 to 0.06926, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06926 to 0.06766, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06766 to 0.06521, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.06521 to 0.06398, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06398 to 0.06104, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06104 to 0.05944, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05944 to 0.05823, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05823 to 0.05553, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.05553 to 0.05381, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05381 to 0.05215, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05215 to 0.05101, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05101 to 0.04905, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04905 to 0.04766, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04766 to 0.04687, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04687 to 0.04581, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04581 to 0.04356, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.04358, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04356 to 0.04128, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04128 to 0.04052, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04052 to 0.03897, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.03897 to 0.03829, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.03829 to 0.03733, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.03789, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.03733 to 0.03664, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03664 to 0.03407, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03407 to 0.03296, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.03384, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03296 to 0.03170, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03170 to 0.03066, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.03066 to 0.03055, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03055 to 0.02932, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.02947, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.02932 to 0.02831, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.02858, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.02831 to 0.02647, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02647 to 0.02604, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02604 to 0.02563, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02563 to 0.02486, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.02486 to 0.02427, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.02432, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02427 to 0.02311, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02311 to 0.02242, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.02242 to 0.02225, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02225 to 0.02174, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02174 to 0.02121, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02121 to 0.02080, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.02123, did not improve\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.02080 to 0.02019, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss is 0.02079, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.02141, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02019 to 0.01936, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.01936 to 0.01854, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.01854 to 0.01836, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.01836 to 0.01822, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.01860, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.01854, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.01822 to 0.01720, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.01720 to 0.01681, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss is 0.01689, did not improve\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.01681 to 0.01667, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01667 to 0.01628, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss is 0.01945, did not improve\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.01628 to 0.01571, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.01571 to 0.01556, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.01556 to 0.01507, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss is 0.01812, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.01575, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01507 to 0.01471, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss is 0.01511, did not improve\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.01471 to 0.01456, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.01523, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.01557, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.01456 to 0.01383, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.01383 to 0.01379, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.01418, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.01397, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.01379 to 0.01357, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.01377, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.01457, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01357 to 0.01313, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.01330, did not improve\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.01313 to 0.01255, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss is 0.01263, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.01320, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.01403, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.01340, did not improve\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.01255 to 0.01238, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss is 0.01285, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.01473, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.01256, did not improve\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.01238 to 0.01198, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.01730, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.01351, did not improve\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01198 to 0.01182, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01182 to 0.01132, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.01183, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.01300, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.01254, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00125: val_loss improved from 0.01132 to 0.01121, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.01352, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.01376, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01121 to 0.01099, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.01289, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01306, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.01099 to 0.01086, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.01112, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.01086 to 0.01063, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.01813, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.01088, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.01063 to 0.01048, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.01048 to 0.01025, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.01576, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.01111, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.01549, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.01025 to 0.01022, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.01263, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.01035, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01042, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.01479, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.01147, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.01022 to 0.01022, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01226, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01176, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01036, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01595, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.01359, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01033, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01744, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01222, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.02155, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.01043, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.01040, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01570, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01404, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01032, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01689, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01134, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01530, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.01022 to 0.01017, storing weights.\n",
      "\n",
      "Epoch 00221: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.01043, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01393, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01274, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01279, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.01364, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.01155, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01258, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01203, did not improve\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.01017 to 0.01005, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01041, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.01546, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01019, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01086, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01375, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01387, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.01027, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.01028, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01243, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01019, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01315, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01589, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.01156, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00283: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01027, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01084, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.01033, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01797, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01988, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01261, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.01224, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01135, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01320, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01020, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01695, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.01308, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.01005 to 0.00991, storing weights.\n",
      "\n",
      "Epoch 00316: val_loss is 0.01008, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.01553, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01572, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01521, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01135, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.01322, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01376, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01296, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.01223, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01154, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01155, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.01539, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.02002, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01205, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01596, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01008, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.01533, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.01163, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01291, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01375, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01016, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01209, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01041, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01447, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.01669, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01323, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.01455, did not improve\n",
      "Epoch 00390: early stopping\n",
      "Using epoch 00315 with val_loss: 0.00991\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11707, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11707 to 0.11430, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11430 to 0.11198, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11198 to 0.10855, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10855 to 0.10712, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10712 to 0.10297, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10297 to 0.10029, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10029 to 0.09819, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09819 to 0.09519, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09519 to 0.09318, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09318 to 0.09009, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09009 to 0.08674, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08674 to 0.08487, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08487 to 0.08283, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08283 to 0.08057, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08057 to 0.07802, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07802 to 0.07573, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07573 to 0.07488, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07488 to 0.07132, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07132 to 0.06967, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06967 to 0.06738, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06738 to 0.06543, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.06543 to 0.06351, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06351 to 0.06146, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.06176, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06146 to 0.05801, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05801 to 0.05633, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.05642, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05633 to 0.05234, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05234 to 0.05164, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05164 to 0.04956, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.04956 to 0.04943, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04943 to 0.04755, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04755 to 0.04546, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04546 to 0.04476, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04476 to 0.04307, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04307 to 0.04171, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00038: val_loss improved from 0.04171 to 0.04092, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04092 to 0.03992, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.03992 to 0.03974, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.03974 to 0.03969, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03969 to 0.03732, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.03942, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03732 to 0.03666, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03666 to 0.03535, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03535 to 0.03395, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03395 to 0.03266, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03266 to 0.03244, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.03244 to 0.03143, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03143 to 0.03022, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03022 to 0.02944, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.02983, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.02944 to 0.02899, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.02979, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02899 to 0.02715, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02715 to 0.02668, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02668 to 0.02613, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.02639, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02613 to 0.02483, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02483 to 0.02466, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.02608, did not improve\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.02466 to 0.02427, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02427 to 0.02403, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02403 to 0.02349, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02349 to 0.02217, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.02370, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.02228, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.02217 to 0.02063, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.02225, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02063 to 0.02051, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.02517, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.02051 to 0.02032, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.02032 to 0.01954, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.01954 to 0.01949, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.01961, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.01949 to 0.01869, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.02301, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.01904, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.01896, did not improve\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01869 to 0.01814, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.01814 to 0.01752, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.01855, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.01780, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.01752 to 0.01652, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss is 0.01955, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.01710, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01652 to 0.01615, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01615 to 0.01607, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.01607 to 0.01601, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.02163, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.01669, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.02016, did not improve\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.01601 to 0.01601, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.01601 to 0.01571, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.01571 to 0.01506, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.01843, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.01647, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01506 to 0.01505, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01505 to 0.01408, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.01765, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.01437, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.01526, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.01408 to 0.01387, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.01424, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.01397, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.01495, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.01407, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.01500, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.01423, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.01517, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01387 to 0.01355, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01355 to 0.01309, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.01385, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.01309 to 0.01248, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.01270, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.01564, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.01326, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.01588, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.01444, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01248 to 0.01223, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.01359, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.01448, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.01236, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.01483, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.02067, did not improve\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.01223 to 0.01192, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.01319, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.01471, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.01500, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01256, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01493, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.01505, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.01336, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.01546, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.01217, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.01306, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.01372, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.02052, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01289, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01599, did not improve\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.01192 to 0.01176, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.01176 to 0.01162, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.01288, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.01254, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01865, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01389, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01237, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.01616, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01566, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01512, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01305, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00180: val_loss is 0.01209, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01296, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.01162 to 0.01096, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01215, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01176, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01258, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01389, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01280, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.01322, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01332, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.01629, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01369, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.01576, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.01793, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.01374, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.01291, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01131, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01565, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.01203, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01658, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.01096 to 0.01083, storing weights.\n",
      "\n",
      "Epoch 00220: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.02030, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01225, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01812, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.02266, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01131, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01262, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.01669, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01271, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01359, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01104, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.01319, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01373, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01329, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.01452, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.02440, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01435, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01353, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01447, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.02132, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01258, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.01403, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.01318, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01255, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01340, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01285, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01631, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.01249, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.01381, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01481, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.01252, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.02302, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.01083 to 0.01079, storing weights.\n",
      "\n",
      "Epoch 00282: val_loss is 0.01561, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01355, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01215, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01688, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01332, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.01216, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01728, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01216, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.01201, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01388, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.01325, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.01294, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.01670, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.01865, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01474, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01407, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.01267, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01276, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.01079 to 0.01067, storing weights.\n",
      "\n",
      "Epoch 00330: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01307, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01259, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.01119, did not improve\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.01067 to 0.01056, storing weights.\n",
      "\n",
      "Epoch 00335: val_loss is 0.01302, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01410, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00339: val_loss improved from 0.01056 to 0.01036, storing weights.\n",
      "\n",
      "Epoch 00340: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01535, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01081, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01415, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01516, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01639, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01321, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01346, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.01363, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01359, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01555, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01414, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.01364, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.02210, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01419, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.01594, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01783, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01205, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01434, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.01473, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01093, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01704, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01141, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.01254, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.01533, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.01251, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.01829, did not improve\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.01036 to 0.01031, storing weights.\n",
      "\n",
      "Epoch 00396: val_loss is 0.01619, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01659, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01438, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01709, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.01934, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01973, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.01491, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.01419, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.01038, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.01368, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.01462, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.01359, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.02092, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.01287, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.01723, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.01036, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.01321, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.01708, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.01035, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.01389, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.01279, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.01464, did not improve\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.01031 to 0.01025, storing weights.\n",
      "\n",
      "Epoch 00440: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.01025 to 0.00998, storing weights.\n",
      "\n",
      "Epoch 00442: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.01493, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.01288, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.01854, did not improve\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.00998 to 0.00992, storing weights.\n",
      "\n",
      "Epoch 00451: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.01513, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.01401, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.01167, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.01123, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.01616, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.01318, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.01764, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.01017, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.01247, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.01774, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.01006, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.01410, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.01277, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.01013, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00479: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.01345, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.03615, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.01469, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.01145, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.01138, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.01164, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.01507, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.00992 to 0.00950, storing weights.\n",
      "\n",
      "Epoch 00498: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.01171, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00500: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00501: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00504: val_loss is 0.01018, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.01007, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.01041, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.01438, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.01236, did not improve\n",
      "\n",
      "Epoch 00513: val_loss improved from 0.00950 to 0.00921, storing weights.\n",
      "\n",
      "Epoch 00514: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.01327, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.00951, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.01817, did not improve\n",
      "\n",
      "Epoch 00519: val_loss is 0.00995, did not improve\n",
      "\n",
      "Epoch 00520: val_loss is 0.01293, did not improve\n",
      "\n",
      "Epoch 00521: val_loss is 0.01255, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.01022, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.01346, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.01336, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.01504, did not improve\n",
      "\n",
      "Epoch 00530: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00531: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.01269, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.01338, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.01859, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.01111, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.01016, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.02437, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.01042, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.01342, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.01757, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.00956, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00547: val_loss is 0.01042, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.01199, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.01607, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.01180, did not improve\n",
      "\n",
      "Epoch 00552: val_loss is 0.01420, did not improve\n",
      "\n",
      "Epoch 00553: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00554: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00555: val_loss is 0.00999, did not improve\n",
      "\n",
      "Epoch 00556: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00557: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00558: val_loss is 0.01265, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.01249, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.00975, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.00946, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.00990, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00568: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00569: val_loss is 0.00982, did not improve\n",
      "\n",
      "Epoch 00570: val_loss is 0.01011, did not improve\n",
      "\n",
      "Epoch 00571: val_loss is 0.01604, did not improve\n",
      "\n",
      "Epoch 00572: val_loss is 0.01407, did not improve\n",
      "\n",
      "Epoch 00573: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00574: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00575: val_loss is 0.00978, did not improve\n",
      "\n",
      "Epoch 00576: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00577: val_loss is 0.01007, did not improve\n",
      "\n",
      "Epoch 00578: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00579: val_loss is 0.01400, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00581: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00582: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.01449, did not improve\n",
      "\n",
      "Epoch 00588: val_loss is 0.00989, did not improve\n",
      "Epoch 00588: early stopping\n",
      "Using epoch 00513 with val_loss: 0.00921\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00588] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0067 ]\n",
      " [ 0.00563]\n",
      " [ 0.00531]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00402] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00376]\n",
      " [ 0.00366]\n",
      " [ 0.00464]]\n",
      "mse over all validation data 0.00588251943148\n",
      "path plots/mlp L1L2_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effde8c1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20, 'l1': 0.0005, 'l2': 0.0005} \n",
    "# config found by hyperband on L1L2 case\n",
    "# cfg = {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
    "res_mlp_l1l2 = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, L1L2=True)\n",
    "t.scatter_plot(Y, res_mlp_l1l2['y_preds'][0], 'mlp L1L2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this mse mlp_500 0.00615437846885\n",
      "this mse from list mlp_500 0.00615437846885\n",
      "this mse earlystop 0.00568764191678\n",
      "this mse from list earlystop 0.00568764191678\n",
      "this mse dropout 0.00593283374683\n",
      "this mse from list dropout 0.00593283374683\n",
      "this mse l1l2 0.00588251943148\n",
      "this mse from list l1l2 0.00588251943148\n",
      "path plots/means of regularisation for mlp_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdcdbf780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.box_plot(Y, (5,5), [res_mlp_500, res_mlp_es, res_mlp_do, res_mlp_l1l2],\n",
    "           ['mlp_500', 'earlystop', 'dropout', 'l1l2'], 'means of regularisation for mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'lr': 0.2213474827989724, 'batch_size': 20, 'k_exp': 0.005043479631870928}\n",
      "evaluating with early stopping\n",
      "evaluating with exponential decay\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04899, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04899 to 0.04654, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.04964, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 0.04700, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04654 to 0.04416, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.04463, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04416 to 0.04257, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.04594, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04257 to 0.04139, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04139 to 0.04068, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04068 to 0.03866, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03866 to 0.03788, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03788 to 0.03738, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03738 to 0.03540, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03540 to 0.03295, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.03356, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03295 to 0.03015, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03015 to 0.02963, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02963 to 0.02765, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02765 to 0.02690, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02690 to 0.02543, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02543 to 0.02477, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02477 to 0.02266, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02266 to 0.02076, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.02076 to 0.02001, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.02001 to 0.01893, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01893 to 0.01862, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01862 to 0.01677, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01677 to 0.01665, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01665 to 0.01543, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01543 to 0.01462, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01462 to 0.01421, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01421 to 0.01251, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01251 to 0.01200, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01200 to 0.01104, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01104 to 0.01060, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01060 to 0.00971, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00971 to 0.00938, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00938 to 0.00920, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00923, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00920 to 0.00867, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00906, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00867 to 0.00841, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00856, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00884, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00841 to 0.00828, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00828 to 0.00811, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00811 to 0.00808, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.00951, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00850, did not improve\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00808 to 0.00788, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00788 to 0.00773, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00773 to 0.00771, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00771 to 0.00758, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00758 to 0.00754, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00754 to 0.00751, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00751 to 0.00748, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00748 to 0.00747, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00747 to 0.00741, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00741 to 0.00735, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00737, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00735 to 0.00734, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00734 to 0.00732, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00732 to 0.00728, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00728 to 0.00728, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00804, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00728 to 0.00725, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00725 to 0.00724, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00788, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00758, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00133: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00724 to 0.00721, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00721 to 0.00717, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00717 to 0.00717, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00717 to 0.00714, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00714 to 0.00711, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00711 to 0.00709, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00709 to 0.00703, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00703 to 0.00702, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00702 to 0.00700, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00700 to 0.00695, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00695 to 0.00694, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00694 to 0.00690, storing weights.\n",
      "new lr:  0.0807241559483\n",
      "\n",
      "Epoch 00201: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00690 to 0.00689, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00689 to 0.00688, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00688 to 0.00681, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00681 to 0.00681, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00681 to 0.00678, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00678 to 0.00676, storing weights.\n",
      "\n",
      "Epoch 00253: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00676 to 0.00669, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00684, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00285: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.00669 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00292: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00670, did not improve\n",
      "new lr:  0.048749254134\n",
      "\n",
      "Epoch 00301: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.00668 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00303: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.00668 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00305: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.00667 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00314: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.00667 to 0.00666, storing weights.\n",
      "\n",
      "Epoch 00323: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.00666 to 0.00664, storing weights.\n",
      "\n",
      "Epoch 00327: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.00664 to 0.00663, storing weights.\n",
      "\n",
      "Epoch 00329: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.00663 to 0.00661, storing weights.\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.00661 to 0.00660, storing weights.\n",
      "\n",
      "Epoch 00366: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.00660 to 0.00659, storing weights.\n",
      "\n",
      "Epoch 00372: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.00659 to 0.00658, storing weights.\n",
      "\n",
      "Epoch 00375: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.00658 to 0.00658, storing weights.\n",
      "\n",
      "Epoch 00379: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.00658 to 0.00654, storing weights.\n",
      "\n",
      "Epoch 00396: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00667, did not improve\n",
      "new lr:  0.0294396361375\n",
      "\n",
      "Epoch 00401: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.00654 to 0.00654, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00441: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.00654 to 0.00652, storing weights.\n",
      "\n",
      "Epoch 00443: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.00652 to 0.00651, storing weights.\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.00651 to 0.00649, storing weights.\n",
      "\n",
      "Epoch 00452: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00478: val_loss improved from 0.00649 to 0.00648, storing weights.\n",
      "\n",
      "Epoch 00479: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00496: val_loss improved from 0.00648 to 0.00647, storing weights.\n",
      "\n",
      "Epoch 00497: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00498: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.00650, did not improve\n",
      "new lr:  0.0177785730532\n",
      "\n",
      "Epoch 00501: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00504: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00514: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00516: val_loss improved from 0.00647 to 0.00647, storing weights.\n",
      "\n",
      "Epoch 00517: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00519: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00520: val_loss improved from 0.00647 to 0.00647, storing weights.\n",
      "\n",
      "Epoch 00521: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00525: val_loss improved from 0.00647 to 0.00647, storing weights.\n",
      "\n",
      "Epoch 00526: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00530: val_loss improved from 0.00647 to 0.00646, storing weights.\n",
      "\n",
      "Epoch 00531: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00546: val_loss improved from 0.00646 to 0.00645, storing weights.\n",
      "\n",
      "Epoch 00547: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00552: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00553: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00554: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00555: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00556: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00557: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00558: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00568: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00569: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00570: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00571: val_loss improved from 0.00645 to 0.00645, storing weights.\n",
      "\n",
      "Epoch 00572: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00573: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00574: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00575: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00576: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00577: val_loss improved from 0.00645 to 0.00644, storing weights.\n",
      "\n",
      "Epoch 00578: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00579: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00581: val_loss improved from 0.00644 to 0.00643, storing weights.\n",
      "\n",
      "Epoch 00582: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00588: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00589: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00590: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00591: val_loss improved from 0.00643 to 0.00643, storing weights.\n",
      "\n",
      "Epoch 00592: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00593: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00594: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00595: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00596: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00597: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00598: val_loss is 0.00645, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00599: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00600: val_loss is 0.00644, did not improve\n",
      "new lr:  0.0107364662501\n",
      "\n",
      "Epoch 00601: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00602: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00603: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00604: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00605: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00606: val_loss improved from 0.00643 to 0.00643, storing weights.\n",
      "\n",
      "Epoch 00607: val_loss improved from 0.00643 to 0.00642, storing weights.\n",
      "\n",
      "Epoch 00608: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00609: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00610: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00611: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00612: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00613: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00614: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00615: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00616: val_loss improved from 0.00642 to 0.00641, storing weights.\n",
      "\n",
      "Epoch 00617: val_loss improved from 0.00641 to 0.00641, storing weights.\n",
      "\n",
      "Epoch 00618: val_loss improved from 0.00641 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00619: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00620: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00621: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00622: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00623: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00624: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00625: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00626: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00627: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00628: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00629: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00630: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00631: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00632: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00633: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00634: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00635: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00636: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00637: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00638: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00639: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00640: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00641: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00642: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00643: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00644: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00645: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00646: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00647: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00648: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00649: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00650: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00651: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00652: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00653: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00654: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00655: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00656: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00657: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00658: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00659: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00660: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00661: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00662: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00663: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00664: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00665: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00666: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00667: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00668: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00669: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00670: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00671: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00672: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00673: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00674: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00675: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00676: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00677: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00678: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00679: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00680: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00681: val_loss improved from 0.00640 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00682: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00683: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00684: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00685: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00686: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00687: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00688: val_loss improved from 0.00640 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00689: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00690: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00691: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00692: val_loss improved from 0.00640 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00693: val_loss is 0.00640, did not improve\n",
      "Epoch 00693: early stopping\n",
      "Using epoch 00692 with val_loss: 0.00640\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03466, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03466 to 0.02952, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02952 to 0.02898, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.03419, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02898 to 0.02813, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.02918, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02813 to 0.02643, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02643 to 0.02504, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02504 to 0.02488, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02488 to 0.02294, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02294 to 0.02191, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02191 to 0.02131, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.02182, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02131 to 0.01983, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.02117, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01983 to 0.01823, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01823 to 0.01779, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.01803, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01779 to 0.01696, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01696 to 0.01634, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01634 to 0.01504, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01504 to 0.01445, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01445 to 0.01401, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.01435, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01401 to 0.01264, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01264 to 0.01214, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01214 to 0.01134, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01134 to 0.01119, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01119 to 0.01040, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01040 to 0.01000, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01000 to 0.00982, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.01029, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00982 to 0.00929, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00929 to 0.00889, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00889 to 0.00882, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00882 to 0.00846, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00846 to 0.00843, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00843 to 0.00836, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00836 to 0.00835, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00835 to 0.00809, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00809 to 0.00801, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00803, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00801 to 0.00776, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00776 to 0.00774, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00774 to 0.00771, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00937, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00771 to 0.00766, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00766 to 0.00745, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00745 to 0.00744, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00744 to 0.00734, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00734 to 0.00733, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00827, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00733 to 0.00716, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00716 to 0.00713, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00713 to 0.00712, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00712 to 0.00702, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00702 to 0.00701, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00701 to 0.00698, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00698 to 0.00692, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00692 to 0.00684, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00713, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00684 to 0.00684, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00684 to 0.00682, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00682 to 0.00677, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00677 to 0.00676, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00676 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss is 0.00829, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00667 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00667 to 0.00657, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00657 to 0.00656, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00656 to 0.00651, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00651 to 0.00646, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00646 to 0.00637, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00637 to 0.00635, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00635 to 0.00633, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00633 to 0.00630, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss is 0.00673, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00197: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00630 to 0.00621, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00628, did not improve\n",
      "new lr:  0.0807241559483\n",
      "\n",
      "Epoch 00201: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00621 to 0.00620, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00620 to 0.00620, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00620 to 0.00619, storing weights.\n",
      "\n",
      "Epoch 00214: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00619 to 0.00614, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00614 to 0.00613, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00613 to 0.00610, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00610 to 0.00610, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00610 to 0.00604, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00604 to 0.00603, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.00603 to 0.00598, storing weights.\n",
      "\n",
      "Epoch 00250: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.00598 to 0.00594, storing weights.\n",
      "\n",
      "Epoch 00261: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.00594 to 0.00593, storing weights.\n",
      "\n",
      "Epoch 00277: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.00593 to 0.00591, storing weights.\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.00591 to 0.00582, storing weights.\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.00582 to 0.00582, storing weights.\n",
      "\n",
      "Epoch 00287: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.00582 to 0.00581, storing weights.\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.00581 to 0.00580, storing weights.\n",
      "\n",
      "Epoch 00291: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00592, did not improve\n",
      "new lr:  0.048749254134\n",
      "\n",
      "Epoch 00301: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00580 to 0.00580, storing weights.\n",
      "\n",
      "Epoch 00311: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.00580 to 0.00579, storing weights.\n",
      "\n",
      "Epoch 00325: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.00579 to 0.00576, storing weights.\n",
      "\n",
      "Epoch 00327: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00576, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00349: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.00576 to 0.00574, storing weights.\n",
      "\n",
      "Epoch 00352: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.00574 to 0.00573, storing weights.\n",
      "\n",
      "Epoch 00360: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.00573 to 0.00572, storing weights.\n",
      "\n",
      "Epoch 00362: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.00572 to 0.00567, storing weights.\n",
      "\n",
      "Epoch 00373: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00570, did not improve\n",
      "new lr:  0.0294396361375\n",
      "\n",
      "Epoch 00401: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.00567 to 0.00566, storing weights.\n",
      "\n",
      "Epoch 00410: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.00566 to 0.00565, storing weights.\n",
      "\n",
      "Epoch 00420: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.00565 to 0.00563, storing weights.\n",
      "\n",
      "Epoch 00424: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.00563 to 0.00560, storing weights.\n",
      "\n",
      "Epoch 00448: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.00560 to 0.00560, storing weights.\n",
      "\n",
      "Epoch 00460: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.00560 to 0.00559, storing weights.\n",
      "\n",
      "Epoch 00474: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00475: val_loss improved from 0.00559 to 0.00559, storing weights.\n",
      "\n",
      "Epoch 00476: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00477: val_loss improved from 0.00559 to 0.00558, storing weights.\n",
      "\n",
      "Epoch 00478: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00479: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00497: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00498: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.00559, did not improve\n",
      "new lr:  0.0177785730532\n",
      "\n",
      "Epoch 00501: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.00558 to 0.00558, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00504: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00514: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.00558 to 0.00557, storing weights.\n",
      "\n",
      "Epoch 00520: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00521: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00530: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00531: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00533: val_loss improved from 0.00557 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00534: val_loss improved from 0.00556 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00535: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00547: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00552: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.00556 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00554: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00555: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00556: val_loss improved from 0.00556 to 0.00554, storing weights.\n",
      "\n",
      "Epoch 00557: val_loss improved from 0.00554 to 0.00554, storing weights.\n",
      "\n",
      "Epoch 00558: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00568: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00569: val_loss improved from 0.00554 to 0.00554, storing weights.\n",
      "\n",
      "Epoch 00570: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00571: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00572: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00573: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00574: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00575: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00576: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00577: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00578: val_loss improved from 0.00554 to 0.00554, storing weights.\n",
      "\n",
      "Epoch 00579: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00581: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00582: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00588: val_loss improved from 0.00554 to 0.00553, storing weights.\n",
      "\n",
      "Epoch 00589: val_loss improved from 0.00553 to 0.00553, storing weights.\n",
      "\n",
      "Epoch 00590: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00591: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00592: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00593: val_loss improved from 0.00553 to 0.00553, storing weights.\n",
      "\n",
      "Epoch 00594: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00595: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00596: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00597: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00598: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00599: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00600: val_loss is 0.00553, did not improve\n",
      "new lr:  0.0107364662501\n",
      "\n",
      "Epoch 00601: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00602: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00603: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00604: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00605: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00606: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00607: val_loss improved from 0.00553 to 0.00552, storing weights.\n",
      "\n",
      "Epoch 00608: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00609: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00610: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00611: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00612: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00613: val_loss improved from 0.00552 to 0.00552, storing weights.\n",
      "\n",
      "Epoch 00614: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00615: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00616: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00617: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00618: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00619: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00620: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00621: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00622: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00623: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00624: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00625: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00626: val_loss improved from 0.00552 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00627: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00628: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00629: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00630: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00631: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00632: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00633: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00634: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00635: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00636: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00637: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00638: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00639: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00640: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00641: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00642: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00643: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00644: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00645: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00646: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00647: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00648: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00649: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00650: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00651: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00652: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00653: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00654: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00655: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00656: val_loss improved from 0.00551 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00657: val_loss improved from 0.00551 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00658: val_loss improved from 0.00551 to 0.00550, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00659: val_loss improved from 0.00550 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00660: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00661: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00662: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00663: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00664: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00665: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00666: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00667: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00668: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00669: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00670: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00671: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00672: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00673: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00674: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00675: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00676: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00677: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00678: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00679: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00680: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00681: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00682: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00683: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00684: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00685: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00686: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.00550 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00688: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00689: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00690: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00691: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00692: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00693: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00694: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00695: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00696: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00697: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00698: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00699: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00700: val_loss is 0.00551, did not improve\n",
      "new lr:  0.00648374350381\n",
      "\n",
      "Epoch 00701: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00702: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00703: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00704: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00705: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00706: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00707: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00708: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00709: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00710: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00711: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00712: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00713: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00714: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00715: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00716: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00717: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00718: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00719: val_loss improved from 0.00550 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00720: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00721: val_loss improved from 0.00550 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00722: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00723: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00724: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00725: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00726: val_loss improved from 0.00550 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00727: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00728: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00729: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00730: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00731: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00732: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00733: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00734: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00735: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00736: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00737: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00738: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00739: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00740: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00741: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00742: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00743: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00744: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00745: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00746: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00747: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00748: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00749: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00750: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00751: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00752: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00753: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00754: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00755: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00756: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00757: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00758: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00759: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00760: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00761: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00762: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00763: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00764: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00765: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00766: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00767: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00768: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00769: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00770: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00771: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00772: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00773: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00774: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00775: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00776: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00777: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00778: val_loss improved from 0.00549 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00779: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00780: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00781: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00782: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00783: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00784: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00785: val_loss improved from 0.00549 to 0.00548, storing weights.\n",
      "\n",
      "Epoch 00786: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00787: val_loss improved from 0.00548 to 0.00548, storing weights.\n",
      "\n",
      "Epoch 00788: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00789: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00790: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00791: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00792: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00793: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00794: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00795: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00796: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00797: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00798: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00799: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00800: val_loss improved from 0.00548 to 0.00548, storing weights.\n",
      "new lr:  0.00391552759015\n",
      "\n",
      "Epoch 00801: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00802: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00803: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00804: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00805: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00806: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00807: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00808: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00809: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00810: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00811: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00812: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00813: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00814: val_loss is 0.00548, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00815: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00816: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00817: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00818: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00819: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00820: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00821: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00822: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00823: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00824: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00825: val_loss is 0.00548, did not improve\n",
      "Epoch 00825: early stopping\n",
      "Using epoch 00800 with val_loss: 0.00548\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02643, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02643 to 0.02582, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02582 to 0.02525, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.02621, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02525 to 0.02418, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02418 to 0.02345, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.02471, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02345 to 0.02199, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.02403, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02199 to 0.02085, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02085 to 0.02056, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02056 to 0.01973, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01973 to 0.01884, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01884 to 0.01831, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.01932, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01831 to 0.01718, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01718 to 0.01603, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.01610, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01603 to 0.01561, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01561 to 0.01398, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01398 to 0.01337, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01337 to 0.01314, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01314 to 0.01202, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01202 to 0.01162, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01162 to 0.01145, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01145 to 0.01039, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01039 to 0.01012, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01012 to 0.00973, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00985, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00973 to 0.00855, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00855 to 0.00852, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00852 to 0.00803, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00984, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00803 to 0.00796, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00796 to 0.00780, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00780 to 0.00769, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00769 to 0.00762, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00762 to 0.00722, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00722 to 0.00715, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00715 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00668 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00668 to 0.00661, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00661 to 0.00648, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00842, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00648 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00640 to 0.00640, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00640 to 0.00621, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00621 to 0.00620, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00620 to 0.00601, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00633, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00601 to 0.00599, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00707, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00599 to 0.00584, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00613, did not improve\n",
      "new lr:  0.0807241559483\n",
      "\n",
      "Epoch 00201: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00602, did not improve\n",
      "Epoch 00223: early stopping\n",
      "Using epoch 00148 with val_loss: 0.00584\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00591] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0064 ]\n",
      " [ 0.00548]\n",
      " [ 0.00584]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00159] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00104]\n",
      " [ 0.00132]\n",
      " [ 0.00239]]\n",
      "mse over all validation data 0.00590785560253\n",
      "path plots/mlp with exponential decay_sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "box_plot() missing 1 required positional argument: 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-ccca12155d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_mlp_ed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mlp with exponential decay'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m t.box_plot(Y, [res_mlp_es, res_mlp_ed],\n\u001b[0;32m----> 6\u001b[0;31m            ['lr 0.22', 'exponential decay'])\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: box_plot() missing 1 required positional argument: 'title'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdcc3a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate mlp via cross validation\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20, 'k_exp': 0.005043479631870928} \n",
    "res_mlp_ed = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, lr_exp_decay=True)\n",
    "t.scatter_plot(Y, res_mlp_ed['y_preds'][0], 'mlp with exponential decay')\n",
    "t.box_plot(Y, (5,5), [res_mlp_es, res_mlp_ed],\n",
    "           ['lr 0.22', 'exponential decay'], 'with and without exponential decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 500 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 20, 'lr': 0.2213474827989724}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00571] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00634]\n",
      " [ 0.00556]\n",
      " [ 0.00521]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00071] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00016]\n",
      " [ 0.00126]\n",
      " [ 0.00071]]\n",
      "mse over all validation data 0.00570752794309\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 20, 'lr': 0.2213474827989724}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04766, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.04898, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04766 to 0.04554, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.04767, did not improve\n",
      "\n",
      "Epoch 00005: val_loss is 0.04634, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04554 to 0.04373, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.04427, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04373 to 0.04060, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04060 to 0.04041, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04041 to 0.03742, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03742 to 0.03662, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03662 to 0.03471, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03471 to 0.03372, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03372 to 0.02896, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02896 to 0.02715, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02715 to 0.02457, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02457 to 0.02342, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02342 to 0.02111, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.02415, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02111 to 0.02038, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02038 to 0.01774, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01774 to 0.01651, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.01816, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01651 to 0.01545, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01545 to 0.01485, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01485 to 0.01317, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.01330, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01317 to 0.01204, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.01639, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01204 to 0.01143, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01143 to 0.00960, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00993, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00996, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00960 to 0.00906, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00977, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00906 to 0.00879, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00879 to 0.00809, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00809 to 0.00794, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.00864, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00894, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00794 to 0.00764, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00943, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00950, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00896, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00764 to 0.00758, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00758 to 0.00757, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00805, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00926, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00757 to 0.00741, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00872, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00925, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00741 to 0.00734, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00963, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00734 to 0.00729, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00729 to 0.00727, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00898, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00727 to 0.00724, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00780, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00724 to 0.00722, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00765, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00732, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00132: val_loss improved from 0.00722 to 0.00715, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00715 to 0.00714, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00714 to 0.00713, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00951, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00938, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00764, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00871, did not improve\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00713 to 0.00710, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00710 to 0.00700, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00902, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00700 to 0.00698, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss is 0.00872, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00842, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00698 to 0.00683, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00917, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00849, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00962, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01261, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00857, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00764, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00899, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00692, did not improve\n",
      "Epoch 00268: early stopping\n",
      "Using epoch 00193 with val_loss: 0.00683\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03425, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03425 to 0.02969, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02969 to 0.02942, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02942 to 0.02861, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02861 to 0.02737, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02737 to 0.02611, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.02794, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02611 to 0.02319, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02319 to 0.02155, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02155 to 0.02042, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02042 to 0.01854, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.02006, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01854 to 0.01639, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.01672, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.01639 to 0.01483, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01483 to 0.01430, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01430 to 0.01317, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.01348, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01317 to 0.01165, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01165 to 0.01109, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01109 to 0.01091, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01091 to 0.00993, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.01050, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00993 to 0.00930, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00930 to 0.00877, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00882, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00877 to 0.00822, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00822 to 0.00814, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00814 to 0.00783, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00783 to 0.00754, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00754 to 0.00723, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00723 to 0.00714, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00997, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00714 to 0.00683, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00683 to 0.00678, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00678 to 0.00667, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00667 to 0.00657, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00657 to 0.00638, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00638 to 0.00637, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00780, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00637 to 0.00631, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00631 to 0.00629, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00629 to 0.00626, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00626 to 0.00622, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00622 to 0.00615, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00615 to 0.00606, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00805, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00606 to 0.00594, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00843, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00594 to 0.00582, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00582 to 0.00582, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00582 to 0.00570, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00875, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00570 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00549 to 0.00545, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00545 to 0.00543, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00566, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_loss improved from 0.00543 to 0.00533, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00533 to 0.00520, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00520 to 0.00519, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00519 to 0.00518, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00518 to 0.00485, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00485, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00485 to 0.00472, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss is 0.00488, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00486, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00497, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00485, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00483, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00497, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00493, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00473, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00492, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00504, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00496, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00502, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00486, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00480, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00484, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00489, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00503, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00528, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00506, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00487, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00504, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.00472 to 0.00448, storing weights.\n",
      "\n",
      "Epoch 00285: val_loss is 0.00481, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00481, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00449, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00483, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00477, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00476, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00489, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00482, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00465, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00471, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00468, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00494, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00461, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00463, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00489, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00492, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00453, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00464, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00328: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00497, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00480, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00474, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00491, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00469, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00469, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00462, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00496, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00505, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00504, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00462, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00468, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00494, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00504, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00516, did not improve\n",
      "Epoch 00359: early stopping\n",
      "Using epoch 00284 with val_loss: 0.00448\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02776, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02776 to 0.02615, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02615 to 0.02569, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02569 to 0.02432, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02432 to 0.02334, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.02566, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02334 to 0.02235, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02235 to 0.02105, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02105 to 0.02056, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02056 to 0.01767, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01767 to 0.01626, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.01630, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01626 to 0.01473, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01473 to 0.01445, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01445 to 0.01348, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.01427, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01348 to 0.01198, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01198 to 0.01102, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01102 to 0.01054, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01054 to 0.01008, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01008 to 0.00991, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00991 to 0.00946, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.00975, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00946 to 0.00885, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00885 to 0.00841, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00841 to 0.00790, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00927, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.01022, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00790 to 0.00763, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00885, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00763 to 0.00726, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00973, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00726 to 0.00706, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00706 to 0.00688, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00954, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00688 to 0.00657, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.00920, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00901, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00788, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00903, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00887, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00657 to 0.00622, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.01006, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00622 to 0.00580, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00580 to 0.00569, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00114: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00569 to 0.00532, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00532 to 0.00520, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00524, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00520 to 0.00488, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss is 0.00492, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00488 to 0.00484, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00484 to 0.00461, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00503, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00488, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00495, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00461 to 0.00447, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00481, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00454, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00460, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00507, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00493, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00486, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00492, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00467, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00455, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00486, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00468, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00464, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00475, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00505, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00510, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00474, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00509, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00463, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00481, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00495, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00492, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00474, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00523, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00489, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00495, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00272: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00480, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00608, did not improve\n",
      "Epoch 00281: early stopping\n",
      "Using epoch 00206 with val_loss: 0.00447\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00526] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00683]\n",
      " [ 0.00448]\n",
      " [ 0.00447]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00184] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00209]\n",
      " [ 0.00158]\n",
      " [ 0.00184]]\n",
      "mse over all validation data 0.00526659897434\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 20, 'lr': 0.2213474827989724}\n",
      "evaluating with early stopping\n",
      "create mlp using Dropout\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04673, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.04888, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04673 to 0.04553, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04553 to 0.04398, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04398 to 0.04331, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.04401, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04331 to 0.04212, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04212 to 0.03936, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03936 to 0.03900, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03900 to 0.03697, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03697 to 0.03539, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03539 to 0.03201, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03201 to 0.03159, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03159 to 0.03033, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03033 to 0.02748, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02748 to 0.02665, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.02728, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02665 to 0.02454, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02454 to 0.02397, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02397 to 0.02077, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.02187, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.02160, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02077 to 0.01941, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01941 to 0.01882, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01882 to 0.01640, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01640 to 0.01573, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01573 to 0.01521, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.01580, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01521 to 0.01445, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.01724, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01445 to 0.01346, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.01485, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01346 to 0.01228, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.01573, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.01466, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.01231, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01228 to 0.01200, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01200 to 0.01136, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.01296, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01136 to 0.01055, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01055 to 0.01019, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.01236, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.01560, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.01019 to 0.00956, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00963, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00956 to 0.00956, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00956 to 0.00914, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.01027, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00914 to 0.00889, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00889 to 0.00866, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00944, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00866 to 0.00849, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00884, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00881, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00849 to 0.00815, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.01331, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00856, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00991, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00947, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00818, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00815 to 0.00787, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00867, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00879, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00924, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.01252, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00988, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00914, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00901, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00787 to 0.00777, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00889, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00875, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.01112, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00916, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.01003, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00777 to 0.00772, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.01144, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.01039, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.01404, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00895, did not improve\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00772 to 0.00769, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00769 to 0.00767, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00767 to 0.00754, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss is 0.00793, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00754 to 0.00729, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00815, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00969, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: val_loss improved from 0.00729 to 0.00726, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00873, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00927, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00915, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00965, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00805, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00932, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01004, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00889, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01301, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01157, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00901, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00726 to 0.00721, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.00864, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00929, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00919, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00765, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00870, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00850, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00994, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00935, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00945, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00840, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00721 to 0.00709, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss is 0.01514, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00709 to 0.00699, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00842, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00981, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01012, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00946, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00973, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00935, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00928, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00938, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00827, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00943, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00971, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01017, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01328, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00854, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00764, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.00699 to 0.00697, storing weights.\n",
      "\n",
      "Epoch 00265: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00858, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00936, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00788, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00801, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00969, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00776, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00283: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00832, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00879, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00959, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.00697 to 0.00689, storing weights.\n",
      "\n",
      "Epoch 00299: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00909, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00876, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00970, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00764, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00827, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00871, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00852, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00929, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00905, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00829, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00882, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00905, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00872, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.00689 to 0.00684, storing weights.\n",
      "\n",
      "Epoch 00346: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00867, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00923, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00907, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00919, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.00922, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.00886, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00954, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00814, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00933, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00842, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00840, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00865, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00805, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00907, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00774, did not improve\n",
      "Epoch 00420: early stopping\n",
      "Using epoch 00345 with val_loss: 0.00684\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02976, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02976 to 0.02881, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02881 to 0.02828, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02828 to 0.02788, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02788 to 0.02607, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02607 to 0.02521, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02521 to 0.02365, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02365 to 0.02194, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02194 to 0.02070, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02070 to 0.01985, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01985 to 0.01805, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01805 to 0.01738, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01738 to 0.01730, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01730 to 0.01635, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss improved from 0.01635 to 0.01591, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.02016, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01591 to 0.01352, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01352 to 0.01320, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01375, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01320 to 0.01196, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01196 to 0.01138, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01138 to 0.01095, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01095 to 0.01089, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.01298, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01089 to 0.01000, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01000 to 0.00983, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00983 to 0.00923, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00923 to 0.00895, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00895 to 0.00857, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00968, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00892, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00865, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00857 to 0.00842, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00962, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00842 to 0.00756, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00881, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00756 to 0.00739, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00913, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00739 to 0.00738, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00738 to 0.00733, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00733 to 0.00715, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.00777, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00870, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00804, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00952, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00715 to 0.00712, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00712 to 0.00697, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.00793, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00990, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00697 to 0.00672, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00672 to 0.00638, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00965, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00887, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00842, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00638 to 0.00588, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.00808, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00925, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00892, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00588 to 0.00587, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00587 to 0.00567, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00567 to 0.00564, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00564 to 0.00542, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00542 to 0.00536, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00912, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00829, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00536 to 0.00517, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00518, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00711, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00166: val_loss improved from 0.00517 to 0.00514, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00515, did not improve\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00514 to 0.00508, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00765, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00532, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00521, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00538, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00563, did not improve\n",
      "Epoch 00246: early stopping\n",
      "Using epoch 00171 with val_loss: 0.00508\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02522, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02522 to 0.02490, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.02623, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 0.02779, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02490 to 0.02337, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.02407, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02337 to 0.02039, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02039 to 0.01903, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01903 to 0.01844, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.02152, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01844 to 0.01685, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01685 to 0.01608, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01608 to 0.01557, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01557 to 0.01472, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01472 to 0.01456, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01456 to 0.01400, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01400 to 0.01300, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01300 to 0.01224, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01224 to 0.01199, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01199 to 0.01126, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01126 to 0.01092, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01092 to 0.01040, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01040 to 0.00994, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00994 to 0.00987, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00987 to 0.00964, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00964 to 0.00960, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00960 to 0.00884, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.00936, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00929, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.01014, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.01004, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00884 to 0.00877, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00877 to 0.00812, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00961, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00812 to 0.00797, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.01245, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00797 to 0.00786, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00786 to 0.00743, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.01111, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00743 to 0.00734, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00805, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00956, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00734 to 0.00720, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00720 to 0.00679, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.01046, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00861, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00908, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00067: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00679 to 0.00658, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.00876, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00658 to 0.00646, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00983, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.01012, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00893, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00646 to 0.00626, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00626 to 0.00606, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00901, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00606 to 0.00574, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00991, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00832, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00993, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00670, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00933, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00574 to 0.00547, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00547 to 0.00526, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00526 to 0.00524, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00726, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00227: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00524 to 0.00516, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00526, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00517, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00573, did not improve\n",
      "Epoch 00311: early stopping\n",
      "Using epoch 00236 with val_loss: 0.00516\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00569] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00684]\n",
      " [ 0.00508]\n",
      " [ 0.00516]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.0027] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00113]\n",
      " [ 0.00265]\n",
      " [ 0.00432]]\n",
      "mse over all validation data 0.00569774190519\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'batch_size': 20, 'lr': 0.2213474827989724, 'l1': 0.0005, 'l2': 0.0005}\n",
      "evaluating with early stopping\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14125, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14125 to 0.13698, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13698 to 0.13212, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13212 to 0.12974, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12974 to 0.12749, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12749 to 0.12622, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12622 to 0.12236, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12236 to 0.11953, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11953 to 0.11518, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11518 to 0.11380, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11380 to 0.10928, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10928 to 0.10639, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10639 to 0.10485, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.10485 to 0.10061, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.10061 to 0.09799, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.09799 to 0.09322, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.09322 to 0.09302, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09302 to 0.08830, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.08830 to 0.08539, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08539 to 0.08171, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08171 to 0.07860, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.07860 to 0.07737, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.07737 to 0.07324, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.07427, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.07324 to 0.07001, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.07001 to 0.06645, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.06645 to 0.06419, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06419 to 0.06223, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.06223 to 0.06062, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06062 to 0.05816, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05816 to 0.05769, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05769 to 0.05525, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.05525 to 0.05236, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.05236 to 0.05083, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.05083 to 0.05074, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.05074 to 0.04920, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04920 to 0.04698, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04698 to 0.04518, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.04604, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04518 to 0.04317, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04317 to 0.04196, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.04196 to 0.04088, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.04088 to 0.03923, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03923 to 0.03869, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.03905, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03869 to 0.03807, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_loss improved from 0.03807 to 0.03566, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03566 to 0.03487, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.03771, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03487 to 0.03314, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03314 to 0.03230, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.03230 to 0.03120, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.03120 to 0.03049, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03049 to 0.02987, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02987 to 0.02946, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02946 to 0.02929, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02929 to 0.02807, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.02815, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02807 to 0.02663, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02663 to 0.02655, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02655 to 0.02624, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.02884, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02624 to 0.02501, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.02546, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02501 to 0.02395, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02395 to 0.02368, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.02368 to 0.02299, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss is 0.02327, did not improve\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.02299 to 0.02217, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.02256, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.02292, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.02409, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.02217 to 0.02161, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.02161 to 0.02109, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.02109 to 0.02045, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.02045 to 0.01999, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.01999 to 0.01988, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.01988 to 0.01982, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.01982 to 0.01852, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01852 to 0.01830, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.01830 to 0.01804, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.01822, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.01942, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.01804 to 0.01769, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.01769 to 0.01729, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.01729 to 0.01726, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01726 to 0.01709, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01709 to 0.01656, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.01763, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.01752, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.01656 to 0.01602, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.01639, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.01632, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.01687, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.01712, did not improve\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.01602 to 0.01598, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.01598 to 0.01493, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01493 to 0.01479, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01479 to 0.01473, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.01756, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.01473 to 0.01457, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss is 0.01527, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.01609, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.01612, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.01463, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.01458, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.01457 to 0.01430, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.01430 to 0.01395, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.01461, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.01477, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.01498, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.01478, did not improve\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.01395 to 0.01370, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.01370 to 0.01353, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.01353 to 0.01346, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.01374, did not improve\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.01346 to 0.01339, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss is 0.01361, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.01388, did not improve\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01339 to 0.01303, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.01376, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.01318, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.01528, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.01387, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.01322, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.01627, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.01394, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.01384, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.01506, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01303 to 0.01302, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.01302 to 0.01297, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.01297 to 0.01269, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss is 0.01296, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01277, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.01420, did not improve\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01269 to 0.01261, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01291, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.01442, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01404, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01261 to 0.01248, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.01248 to 0.01248, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss is 0.01410, did not improve\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.01248 to 0.01220, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss is 0.01259, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01360, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.01296, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.01220 to 0.01217, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.01217 to 0.01216, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss is 0.01308, did not improve\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.01216 to 0.01216, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss is 0.01246, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.01491, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01217, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01581, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01256, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.01484, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.01216 to 0.01196, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.01209, did not improve\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.01196 to 0.01191, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.01583, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.01229, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.01281, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01278, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01235, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.01254, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01205, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01312, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.01929, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01223, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.01418, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01229, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00185: val_loss is 0.01225, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.01191 to 0.01160, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss is 0.01449, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01583, did not improve\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.01160 to 0.01150, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01396, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.01150 to 0.01146, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss is 0.01240, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01229, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.01146 to 0.01142, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.01577, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.01183, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01147, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01423, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01472, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01216, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.01142 to 0.01137, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss is 0.01352, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.01147, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.01696, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01587, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.01137 to 0.01133, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.01133 to 0.01119, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.01119 to 0.01101, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01161, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.01244, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.01513, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01258, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01152, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.01172, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01461, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.01101 to 0.01100, storing weights.\n",
      "\n",
      "Epoch 00251: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01380, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01487, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01171, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01163, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01624, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.01100 to 0.01097, storing weights.\n",
      "\n",
      "Epoch 00263: val_loss is 0.01153, did not improve\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.01097 to 0.01093, storing weights.\n",
      "\n",
      "Epoch 00265: val_loss is 0.01308, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.01131, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.01093 to 0.01091, storing weights.\n",
      "\n",
      "Epoch 00273: val_loss is 0.01539, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.01091 to 0.01085, storing weights.\n",
      "\n",
      "Epoch 00277: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.01309, did not improve\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.01085 to 0.01083, storing weights.\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.01083 to 0.01071, storing weights.\n",
      "\n",
      "Epoch 00282: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01805, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01375, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01503, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.01720, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01101, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01210, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01098, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.01697, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.01444, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.01255, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.01071 to 0.01056, storing weights.\n",
      "\n",
      "Epoch 00314: val_loss is 0.01579, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.01252, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.01317, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01118, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.01297, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.02292, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01536, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.01056 to 0.01050, storing weights.\n",
      "\n",
      "Epoch 00333: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01393, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.01094, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01649, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01063, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.01366, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00341: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01104, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01391, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.01056, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.01052, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.01261, did not improve\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.01050 to 0.01050, storing weights.\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.01050 to 0.01049, storing weights.\n",
      "\n",
      "Epoch 00357: val_loss is 0.01250, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.01948, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.01049 to 0.01048, storing weights.\n",
      "\n",
      "Epoch 00363: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.01084, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.01252, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.01403, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.01086, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.01103, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.01104, did not improve\n",
      "\n",
      "Epoch 00373: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.01124, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.01196, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.01399, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.01545, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.01492, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.01181, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.01746, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.01048 to 0.01045, storing weights.\n",
      "\n",
      "Epoch 00389: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.01045 to 0.01045, storing weights.\n",
      "\n",
      "Epoch 00391: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00393: val_loss improved from 0.01045 to 0.01044, storing weights.\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.01044 to 0.01040, storing weights.\n",
      "\n",
      "Epoch 00395: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.01214, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.01564, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.01446, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.01228, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.01351, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.01369, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.01274, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00415: val_loss improved from 0.01040 to 0.01039, storing weights.\n",
      "\n",
      "Epoch 00416: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.01342, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.01482, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.01878, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.01039 to 0.01035, storing weights.\n",
      "\n",
      "Epoch 00427: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.01078, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.01043, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.01173, did not improve\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.01035 to 0.01030, storing weights.\n",
      "\n",
      "Epoch 00443: val_loss is 0.01106, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.01035, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.01050, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.01788, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00448: val_loss is 0.01276, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.01049, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.01146, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.01286, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.01485, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.01057, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.01554, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.01143, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.01033, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.01928, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.01279, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.01412, did not improve\n",
      "\n",
      "Epoch 00479: val_loss is 0.01445, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.01159, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.01068, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.01189, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.01040, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.01032, did not improve\n",
      "\n",
      "Epoch 00489: val_loss is 0.01150, did not improve\n",
      "\n",
      "Epoch 00490: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.01104, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.01217, did not improve\n",
      "\n",
      "Epoch 00497: val_loss is 0.01368, did not improve\n",
      "\n",
      "Epoch 00498: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.01231, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00501: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.01039, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.01060, did not improve\n",
      "\n",
      "Epoch 00504: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00506: val_loss improved from 0.01030 to 0.01030, storing weights.\n",
      "\n",
      "Epoch 00507: val_loss is 0.01350, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.01071, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.01226, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.01747, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.01050, did not improve\n",
      "\n",
      "Epoch 00514: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.01062, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.01038, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.01066, did not improve\n",
      "Epoch 00517: early stopping\n",
      "Using epoch 00506 with val_loss: 0.01030\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12322, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12322 to 0.11879, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11879 to 0.11681, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11681 to 0.11408, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11408 to 0.11094, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11094 to 0.10854, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10854 to 0.10464, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.10464 to 0.10104, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10104 to 0.09816, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09816 to 0.09468, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09468 to 0.09167, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09167 to 0.08852, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.09054, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08852 to 0.08307, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08307 to 0.08192, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08192 to 0.07974, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07974 to 0.07597, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07597 to 0.07561, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.07674, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07561 to 0.06973, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06973 to 0.06727, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06727 to 0.06552, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.06552 to 0.06351, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06351 to 0.06195, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06195 to 0.05958, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.05958 to 0.05825, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05825 to 0.05619, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.05619 to 0.05490, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.05490 to 0.05294, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05294 to 0.05141, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05141 to 0.05000, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05000 to 0.04941, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04941 to 0.04823, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04823 to 0.04599, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04599 to 0.04545, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04545 to 0.04385, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04385 to 0.04336, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04336 to 0.04267, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04267 to 0.04092, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04092 to 0.04061, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04061 to 0.03857, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03857 to 0.03724, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.03794, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.03724 to 0.03555, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03555 to 0.03454, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03454 to 0.03374, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03374 to 0.03335, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03335 to 0.03323, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.03323 to 0.03181, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03181 to 0.03065, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03065 to 0.02985, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.03108, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.02985 to 0.02898, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.02898 to 0.02779, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.02909, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02779 to 0.02737, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02737 to 0.02626, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.02641, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02626 to 0.02586, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02586 to 0.02451, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02451 to 0.02394, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.02394 to 0.02341, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02341 to 0.02299, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02299 to 0.02236, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.02488, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.02236 to 0.02147, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.02422, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.02147 to 0.02097, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.02319, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02097 to 0.02002, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.02013, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.02002 to 0.01936, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss is 0.02054, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.01936 to 0.01869, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.02096, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.01869 to 0.01793, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.01847, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.01793 to 0.01731, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss is 0.01867, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.01775, did not improve\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.01731 to 0.01723, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.01723 to 0.01649, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss is 0.01660, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.01677, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.01649 to 0.01617, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.01683, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.01617 to 0.01564, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01564 to 0.01549, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.01570, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.01549 to 0.01466, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.01477, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.01543, did not improve\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.01466 to 0.01443, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.01669, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.01826, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.01479, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.01572, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.01443 to 0.01390, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01390 to 0.01384, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.01397, did not improve\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.01384 to 0.01356, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.01356 to 0.01334, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.01334 to 0.01309, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.01311, did not improve\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.01309 to 0.01268, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss is 0.01923, did not improve\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.01268 to 0.01260, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00108: val_loss is 0.01299, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.01430, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.01314, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.01260 to 0.01222, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss is 0.01241, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01222 to 0.01214, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss is 0.01233, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.01234, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.01676, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.01266, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.01469, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.01238, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.01214 to 0.01170, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss is 0.01201, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.01174, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.01170 to 0.01157, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.01157 to 0.01146, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss is 0.01209, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.01227, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.01377, did not improve\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.01146 to 0.01105, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.01155, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.01122, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.01155, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.01274, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.01105 to 0.01078, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01078 to 0.01058, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss is 0.01072, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.01059, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01198, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01160, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.01058 to 0.01055, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.01211, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.01070, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.01188, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.01088, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.01055 to 0.01034, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss is 0.01083, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01407, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.01034 to 0.01016, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.01016 to 0.01009, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.01009 to 0.01001, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01008, did not improve\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.01001 to 0.00994, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01186, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01073, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.01046, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.01040, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01219, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01013, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.01382, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01388, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.01039, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01140, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.01346, did not improve\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00994 to 0.00973, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01583, did not improve\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00973 to 0.00965, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00965 to 0.00952, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss is 0.00962, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01512, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00978, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00962, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00983, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01349, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01043, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.01248, did not improve\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00952 to 0.00939, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00989, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01009, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00977, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00997, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01028, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00997, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01003, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.01553, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01162, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01091, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00968, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00975, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00950, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00964, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01003, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01253, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00944, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01005, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.01018, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00988, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01252, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00973, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.01128, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00939 to 0.00935, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00935 to 0.00924, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss is 0.01014, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01005, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00947, did not improve\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00924 to 0.00913, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00913 to 0.00906, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss is 0.01249, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00918, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00963, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01139, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01193, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01066, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01432, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01169, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01567, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01048, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00260: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01357, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00990, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.01265, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.00906 to 0.00899, storing weights.\n",
      "\n",
      "Epoch 00266: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00932, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00905, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00928, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00938, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00922, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00909, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01011, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.01127, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.01378, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01192, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.01032, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00964, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.00899 to 0.00895, storing weights.\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.00895 to 0.00881, storing weights.\n",
      "\n",
      "Epoch 00288: val_loss is 0.01185, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.01053, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01018, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00912, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00956, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00989, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00987, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.01176, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00973, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00969, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01310, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00988, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00919, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01012, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00907, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00885, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00936, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00959, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00953, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00947, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.01136, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00882, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.01652, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00918, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.01582, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00971, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.01102, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00915, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.01255, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00925, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00904, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.01076, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00958, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00924, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00990, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00938, did not improve\n",
      "\n",
      "Epoch 00331: val_loss is 0.01448, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.01075, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00955, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.01260, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00922, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.01190, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00934, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.01283, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.01011, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.01158, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.01182, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.01011, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.01606, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00948, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00912, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00957, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00992, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.01008, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.01561, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.01021, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.01357, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00949, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00993, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.01048, did not improve\n",
      "Epoch 00362: early stopping\n",
      "Using epoch 00287 with val_loss: 0.00881\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11803, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11803 to 0.11568, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11568 to 0.11254, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11254 to 0.11125, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11125 to 0.10710, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.10710 to 0.10530, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.10530 to 0.10085, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.10172, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.10085 to 0.09605, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.09605 to 0.09257, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09257 to 0.09257, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09257 to 0.08752, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08752 to 0.08513, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08513 to 0.08296, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08296 to 0.08056, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08056 to 0.07814, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.07814 to 0.07610, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07610 to 0.07402, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.07402 to 0.07152, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.07152 to 0.06984, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.06984 to 0.06966, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.06966 to 0.06489, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.06506, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06489 to 0.06211, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.06211 to 0.06038, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.06038 to 0.05798, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.05798 to 0.05605, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.05605 to 0.05395, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.05505, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.05395 to 0.05115, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.05115 to 0.05017, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.05017 to 0.04963, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.04963 to 0.04732, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.04732 to 0.04639, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.04639 to 0.04481, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.04481 to 0.04392, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.04392 to 0.04229, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.04229 to 0.04157, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.04157 to 0.04078, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.04078 to 0.04018, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.04018 to 0.03995, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03995 to 0.03790, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_loss improved from 0.03790 to 0.03679, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.03857, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.03774, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.03679 to 0.03396, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.03396 to 0.03383, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.03383 to 0.03241, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.03268, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03241 to 0.03212, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.03212 to 0.03115, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.03221, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.03115 to 0.03063, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.03063 to 0.02875, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02875 to 0.02871, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.02941, did not improve\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02871 to 0.02638, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.02687, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02638 to 0.02582, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02582 to 0.02553, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02553 to 0.02517, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.02546, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02517 to 0.02364, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.02366, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.02364 to 0.02269, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.02284, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.02473, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.02269 to 0.02159, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.02285, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.02159 to 0.02070, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.02070 to 0.02004, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.02089, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.02006, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.02004 to 0.01921, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.02032, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.02019, did not improve\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.01921 to 0.01874, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss is 0.01984, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.01900, did not improve\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.01874 to 0.01853, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss is 0.02217, did not improve\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.01853 to 0.01721, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss is 0.01737, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.01731, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.02080, did not improve\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.01721 to 0.01680, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.01822, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.01680 to 0.01597, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.01665, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.01669, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.01626, did not improve\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.01597 to 0.01570, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.01570 to 0.01506, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.01506 to 0.01478, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss is 0.01530, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.01658, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.01553, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.01478 to 0.01468, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.01468 to 0.01441, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.01441 to 0.01433, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.01469, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.01537, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.01477, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.01433 to 0.01365, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.01365 to 0.01318, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss is 0.01755, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.01362, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.01318 to 0.01306, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.01306 to 0.01299, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.01504, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.01542, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.01490, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.01502, did not improve\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.01299 to 0.01289, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.01355, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.01402, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.01295, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.01470, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.01635, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.01506, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.01289 to 0.01285, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.01285 to 0.01263, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss is 0.01759, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.01400, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.01263 to 0.01209, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss is 0.01232, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.01505, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.01222, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.01209 to 0.01177, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.01187, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.01236, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.01218, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.01292, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.01282, did not improve\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.01177 to 0.01175, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.01177, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.01366, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.01289, did not improve\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.01175 to 0.01163, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss is 0.01339, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.01239, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.01576, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.01163 to 0.01139, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss is 0.01312, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.01313, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.01446, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.01183, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.02329, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.01328, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.01400, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.01391, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.01273, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.01206, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.01535, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.01403, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.01301, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.01338, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.01290, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.01139 to 0.01096, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.01109, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.01367, did not improve\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.01096 to 0.01083, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss is 0.01166, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01788, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.01083 to 0.01030, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss is 0.01176, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.01077, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.01212, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.01355, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.01116, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01089, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00184: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.01052, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01151, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.01036, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.01217, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.01277, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.01175, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.01461, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.01092, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.02257, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.01033, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.01213, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.01307, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.01354, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.01074, did not improve\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.01030 to 0.01018, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss is 0.01121, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.01142, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.01672, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.01027, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.01329, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.01120, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.01207, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.01018 to 0.00984, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss is 0.01096, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.01683, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.01045, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.01021, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.01030, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00995, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.01090, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.01079, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.01038, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.01080, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.01220, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.01634, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.01329, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.01178, did not improve\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00984 to 0.00956, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss is 0.01036, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.02004, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00961, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00983, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.01125, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.01866, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.01191, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.01015, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.01022, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00980, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.01204, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.01447, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.01259, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.01126, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.01148, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.01211, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.01046, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.01190, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.01055, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.01061, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.01054, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00961, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.01049, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.01021, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.01082, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.01303, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00985, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.01011, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.01027, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.01440, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.01385, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.01829, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.01087, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.01100, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00963, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.01028, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00996, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.01085, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00991, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.01170, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.01199, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.01129, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01034, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.01108, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00984, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.01069, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.01067, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.01089, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.01880, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.01039, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.01197, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.01020, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00998, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00970, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.01065, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.01049, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.01015, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.01639, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.01329, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.01164, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.01187, did not improve\n",
      "Epoch 00308: early stopping\n",
      "Using epoch 00233 with val_loss: 0.00956\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00564] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00713]\n",
      " [ 0.00441]\n",
      " [ 0.00538]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00416] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.004  ]\n",
      " [ 0.00314]\n",
      " [ 0.00532]]\n",
      "mse over all validation data 0.00564235112306\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [0] steps\n",
      "config {'k_exp': 0.005043479631870928, 'batch_size': 20, 'lr': 0.2213474827989724}\n",
      "evaluating with early stopping\n",
      "evaluating with exponential decay\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04934, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04934 to 0.04641, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.04731, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04641 to 0.04418, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04418 to 0.04214, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04214 to 0.03851, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03851 to 0.03764, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03764 to 0.03602, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03602 to 0.03387, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03387 to 0.02997, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02997 to 0.02775, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02775 to 0.02715, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02715 to 0.02521, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02521 to 0.02253, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02253 to 0.02209, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.02209 to 0.01916, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01916 to 0.01889, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01889 to 0.01666, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01666 to 0.01596, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01596 to 0.01511, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.01529, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01511 to 0.01441, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01441 to 0.01439, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01439 to 0.01260, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01260 to 0.01229, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01229 to 0.01204, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01204 to 0.01118, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01118 to 0.01080, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.01156, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01080 to 0.01012, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.01105, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01012 to 0.00992, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.01130, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.01044, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.01031, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00992 to 0.00898, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00918, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00898 to 0.00888, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00901, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.01032, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00888 to 0.00868, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00930, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00868 to 0.00857, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00857 to 0.00824, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00894, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00824 to 0.00820, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00820 to 0.00819, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00819 to 0.00798, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00798 to 0.00791, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00791 to 0.00786, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00786 to 0.00782, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00782 to 0.00772, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00840, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00772 to 0.00769, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00769 to 0.00748, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.01005, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00748 to 0.00745, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00911, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00745 to 0.00744, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00744 to 0.00742, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00832, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00889, did not improve\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00742 to 0.00733, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00786, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00733 to 0.00732, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00732 to 0.00727, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00727 to 0.00714, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00714 to 0.00703, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00706, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00703 to 0.00695, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00695 to 0.00690, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00690 to 0.00688, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00688 to 0.00683, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00683 to 0.00670, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00670 to 0.00660, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00660 to 0.00659, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00659 to 0.00652, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00652 to 0.00651, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00651 to 0.00648, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss is 0.00654, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00157: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00648 to 0.00639, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00639 to 0.00635, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00635 to 0.00631, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00640, did not improve\n",
      "new lr:  0.0807241559483\n",
      "\n",
      "Epoch 00201: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00637, did not improve\n",
      "Epoch 00252: early stopping\n",
      "Using epoch 00177 with val_loss: 0.00631\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02891, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02891 to 0.02794, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02794 to 0.02704, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02704 to 0.02551, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02551 to 0.02395, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02395 to 0.02236, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02236 to 0.02086, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02086 to 0.02050, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02050 to 0.01740, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.01763, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01740 to 0.01611, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01611 to 0.01437, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01437 to 0.01364, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.01417, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01364 to 0.01249, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01249 to 0.01156, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01156 to 0.01100, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01100 to 0.01058, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01058 to 0.01016, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01016 to 0.00985, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00985 to 0.00921, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00921 to 0.00886, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.00892, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00886 to 0.00832, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00832 to 0.00808, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00833, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00808 to 0.00776, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00776 to 0.00761, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00761 to 0.00737, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00737 to 0.00730, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00730 to 0.00725, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00725 to 0.00712, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00712 to 0.00682, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00817, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00682 to 0.00652, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00652 to 0.00649, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00649 to 0.00633, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00633 to 0.00623, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00917, did not improve\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00048: val_loss improved from 0.00623 to 0.00621, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00621 to 0.00610, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00610 to 0.00593, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.01230, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00593 to 0.00578, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00578 to 0.00576, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00576 to 0.00571, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00571 to 0.00560, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00641, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00593, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00560 to 0.00557, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00557 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00608, did not improve\n",
      "Epoch 00181: early stopping\n",
      "Using epoch 00106 with val_loss: 0.00556\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "new lr:  0.221347482799\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02540, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.02544, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02540 to 0.02422, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02422 to 0.02340, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02340 to 0.02165, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02165 to 0.02075, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02075 to 0.01913, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.02272, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01913 to 0.01689, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.01700, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01689 to 0.01525, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01525 to 0.01483, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01483 to 0.01389, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01389 to 0.01301, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01301 to 0.01258, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.01258 to 0.01241, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01241 to 0.01143, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01143 to 0.01071, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01242, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01071 to 0.00993, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00993 to 0.00925, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00925 to 0.00897, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00897 to 0.00878, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.00908, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00878 to 0.00818, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00873, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00911, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00818 to 0.00804, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00804 to 0.00748, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00795, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00748 to 0.00730, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00783, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00802, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00920, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00730 to 0.00712, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00712 to 0.00701, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00701 to 0.00673, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00673 to 0.00646, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00646 to 0.00630, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00964, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00630 to 0.00602, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00803, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00602 to 0.00569, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00662, did not improve\n",
      "new lr:  0.133671570351\n",
      "\n",
      "Epoch 00101: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00569 to 0.00568, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00568 to 0.00566, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00581, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00566 to 0.00553, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00602, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00553 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00550 to 0.00521, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00560, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00577, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00537, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00569, did not improve\n",
      "new lr:  0.0807241559483\n",
      "\n",
      "Epoch 00201: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00622, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00567, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00604, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00601, did not improve\n",
      "Epoch 00235: early stopping\n",
      "Using epoch 00160 with val_loss: 0.00521\n",
      "MSE on validation data on [0] steps: means over folds: *** [ 0.00569] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00631]\n",
      " [ 0.00556]\n",
      " [ 0.00521]]\n",
      "MSE on train data on [0] steps: means over folds: *** [ 0.00265] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00223]\n",
      " [ 0.00332]\n",
      " [ 0.0024 ]]\n",
      "mse over all validation data 0.00569571499962\n"
     ]
    }
   ],
   "source": [
    "# run all non rnn tasks and save results\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_500 = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=500, splits = 3, earlystop=False) \n",
    "t.pickle_to_file(res_mlp_500, 'res_mlp_500')\n",
    "\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_es = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True)\n",
    "t.pickle_to_file(res_mlp_es, 'res_mlp_es')\n",
    "\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20} \n",
    "res_mlp_do = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, dropout=True)\n",
    "t.pickle_to_file(res_mlp_do, 'res_mlp_do')\n",
    "\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20, 'l1': 0.0005, 'l2': 0.0005} \n",
    "# config found by hyperband on L1L2 case\n",
    "# cfg = {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
    "res_mlp_l1l2 = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, L1L2=True)\n",
    "t.pickle_to_file(res_mlp_l1l2, 'res_mlp_l1l2')\n",
    "\n",
    "cfg = {'lr': 0.2213474827989724, 'batch_size': 20, 'k_exp': 0.005043479631870928} \n",
    "res_mlp_ed = m.eval_cv('mlp', configs, Y, cfg=cfg, epochs=1000, splits = 3, earlystop=True, lr_exp_decay=True)\n",
    "t.pickle_to_file(res_mlp_ed, 'res_mlp_ed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set format\n",
      "path plots/mlp_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98d3dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set format\n",
      "path plots/mlp with earlystop_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98b61588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set format\n",
      "path plots/mlp with dropout_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98b1bf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set format\n",
      "path plots/mlp with L1L2_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98b16898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set format\n",
      "path plots/mlp with exponential decay_sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b989d6fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.scatter_plot(Y, t.pickle_from_file('res_mlp_500'), 'mlp')\n",
    "t.scatter_plot(Y, t.pickle_from_file('res_mlp_es'), 'mlp with earlystop')\n",
    "t.scatter_plot(Y, t.pickle_from_file('res_mlp_do'), 'mlp with dropout')\n",
    "t.scatter_plot(Y, t.pickle_from_file('res_mlp_l1l2'), 'mlp with L1L2')\n",
    "t.scatter_plot(Y, t.pickle_from_file('res_mlp_ed'), 'mlp with exponential decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b661160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.box_plot_single(Y, (5,5), [t.pickle_from_file('res_mlp_es'), t.pickle_from_file('res_mlp_ed')],\n",
    "           ['lr 0.22', 'exponential decay'], 'with and without exponential decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 5 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03841, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03841 to 0.02144, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02144 to 0.01620, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01620 to 0.00893, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00893 to 0.00655, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00655 to 0.00385, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00385 to 0.00355, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00355 to 0.00288, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00288 to 0.00283, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00283 to 0.00255, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00270, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00290, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00302, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00343, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00345, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00373, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00372, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00371, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00349, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00324, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00298, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00275, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00257, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00255 to 0.00244, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00244 to 0.00236, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00236 to 0.00232, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00232 to 0.00231, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00241, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00251, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00255, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00256, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00254, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00250, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00243, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00239, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00234, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00231, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00231 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00229 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00227 to 0.00226, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00226 to 0.00224, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00224 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00222 to 0.00221, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00221 to 0.00219, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00219 to 0.00218, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00218 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00216 to 0.00215, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00215 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00212 to 0.00210, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00210 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00206 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00202 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00196 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00190 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00183 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00175 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00165 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00156 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00145 to 0.00135, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00135 to 0.00125, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00125 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00116 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00108 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00103 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00196, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00217, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00210, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00100 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00100 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00099 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00098 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00097 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00096 to 0.00095, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: val_loss improved from 0.00095 to 0.00094, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00094 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00093 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00091 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00087 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00085 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00072 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00066 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00065 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00064 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00064 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00063 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00063 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00061 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00060 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00060 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00058 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00057 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00055 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00054 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00054 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00053 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00051 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00039 to 0.00038, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00253: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00254: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00047, did not improve\n",
      "Epoch 00325: early stopping\n",
      "Using epoch 00253 with val_loss: 0.00038\n",
      "validate on 5 steps, mse on train / validation data: 0.03367 / 0.04668\n",
      "validate on 10 steps, mse on train / validation data: 0.03294 / 0.04512\n",
      "validate on 20 steps, mse on train / validation data: 0.04143 / 0.05570\n",
      "validate on 30 steps, mse on train / validation data: 0.03833 / 0.05190\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02232, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.03457, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 0.02233, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02232 to 0.00722, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00722 to 0.00278, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00457, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00278 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00186 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00117 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00101 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00088 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00079 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00066 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00058 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00053 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00049 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00047 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00068, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00053, did not improve\n",
      "Epoch 00120: early stopping\n",
      "Using epoch 00045 with val_loss: 0.00041\n",
      "validate on 5 steps, mse on train / validation data: 0.04070 / 0.03240\n",
      "validate on 10 steps, mse on train / validation data: 0.04060 / 0.03231\n",
      "validate on 20 steps, mse on train / validation data: 0.03865 / 0.03078\n",
      "validate on 30 steps, mse on train / validation data: 0.05149 / 0.04087\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09558, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09558 to 0.08155, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08155 to 0.02731, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02731 to 0.00597, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00597 to 0.00526, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00526 to 0.00377, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00377 to 0.00273, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00273 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00160 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00134 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00116 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00107 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00103 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00095 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00092 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00086 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00083 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00080 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00077 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00075 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00072 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00063 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00060 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00055 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00053 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00050 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00049 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00049 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00048 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00044 to 0.00044, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00073: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00043, did not improve\n",
      "Epoch 00171: early stopping\n",
      "Using epoch 00147 with val_loss: 0.00042\n",
      "validate on 5 steps, mse on train / validation data: 0.04613 / 0.02783\n",
      "validate on 10 steps, mse on train / validation data: 0.04523 / 0.02721\n",
      "validate on 20 steps, mse on train / validation data: 0.04275 / 0.02565\n",
      "validate on 30 steps, mse on train / validation data: 0.03125 / 0.01846\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.03564  0.03488  0.03738  0.03708] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04668  0.04512  0.0557   0.0519 ]\n",
      " [ 0.0324   0.03231  0.03078  0.04087]\n",
      " [ 0.02783  0.02721  0.02565  0.01846]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04017  0.03959  0.04094  0.04036] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.03367  0.03294  0.04143  0.03833]\n",
      " [ 0.0407   0.0406   0.03865  0.05149]\n",
      " [ 0.04613  0.04523  0.04275  0.03125]]\n",
      "mse over all validation data 0.0371339693018\n",
      "cross validate 1000 epochs, train on 10 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07340, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07340 to 0.02909, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02909 to 0.01916, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.01916 to 0.00486, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00486 to 0.00213, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00320, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00213 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00180 to 0.00168, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00168 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00141 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00127 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00104 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00086 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00080 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00075 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00072 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00069 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00061 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00058 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00084, did not improve\n",
      "Epoch 00101: early stopping\n",
      "Using epoch 00026 with val_loss: 0.00054\n",
      "validate on 5 steps, mse on train / validation data: 0.05636 / 0.08935\n",
      "validate on 10 steps, mse on train / validation data: 0.05785 / 0.09236\n",
      "validate on 20 steps, mse on train / validation data: 0.06913 / 0.10966\n",
      "validate on 30 steps, mse on train / validation data: 0.05808 / 0.09241\n",
      "train fold 2 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09279, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09279 to 0.04862, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04862 to 0.02798, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02798 to 0.01432, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01432 to 0.01242, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01242 to 0.00604, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00604 to 0.00296, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00296 to 0.00166, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00166 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00071 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00044, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00043: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00039, did not improve\n",
      "Epoch 00154: early stopping\n",
      "Using epoch 00099 with val_loss: 0.00039\n",
      "validate on 5 steps, mse on train / validation data: 0.04324 / 0.03465\n",
      "validate on 10 steps, mse on train / validation data: 0.04351 / 0.03491\n",
      "validate on 20 steps, mse on train / validation data: 0.04192 / 0.03361\n",
      "validate on 30 steps, mse on train / validation data: 0.02009 / 0.01593\n",
      "train fold 3 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11866, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11866 to 0.04006, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04006 to 0.00835, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00835 to 0.00698, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00698 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00228 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00154 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00082 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00067, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from 0.00053 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00049 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00037 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00035 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00034 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00033 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00037, did not improve\n",
      "Epoch 00141: early stopping\n",
      "Using epoch 00082 with val_loss: 0.00031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate on 5 steps, mse on train / validation data: 0.05284 / 0.03300\n",
      "validate on 10 steps, mse on train / validation data: 0.05236 / 0.03228\n",
      "validate on 20 steps, mse on train / validation data: 0.05860 / 0.03601\n",
      "validate on 30 steps, mse on train / validation data: 0.03803 / 0.02312\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.05233  0.05318  0.05976  0.04382] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.08935  0.09236  0.10966  0.09241]\n",
      " [ 0.03465  0.03491  0.03361  0.01593]\n",
      " [ 0.033    0.03228  0.03601  0.02312]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.05081  0.05124  0.05655  0.03873] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.05636  0.05785  0.06913  0.05808]\n",
      " [ 0.04324  0.04351  0.04192  0.02009]\n",
      " [ 0.05284  0.05236  0.0586   0.03803]]\n",
      "mse over all validation data 0.0440058553659\n",
      "cross validate 1000 epochs, train on 20 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02917, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02917 to 0.01587, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01587 to 0.00757, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00757 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00117 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00069 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00062 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00060, did not improve\n",
      "Epoch 00083: early stopping\n",
      "Using epoch 00008 with val_loss: 0.00042\n",
      "validate on 5 steps, mse on train / validation data: 0.02300 / 0.03649\n",
      "validate on 10 steps, mse on train / validation data: 0.00734 / 0.00916\n",
      "validate on 20 steps, mse on train / validation data: 0.00518 / 0.00438\n",
      "validate on 30 steps, mse on train / validation data: 0.00274 / 0.00227\n",
      "train fold 2 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09216, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09216 to 0.05531, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05531 to 0.00721, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.00942, did not improve\n",
      "\n",
      "Epoch 00005: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00721 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00197 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00077 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00050 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00034 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00030 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00029 to 0.00029, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00029 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00028 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00027 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00026 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00028, did not improve\n",
      "Epoch 00155: early stopping\n",
      "Using epoch 00091 with val_loss: 0.00025\n",
      "validate on 5 steps, mse on train / validation data: 0.01124 / 0.00828\n",
      "validate on 10 steps, mse on train / validation data: 0.00351 / 0.00239\n",
      "validate on 20 steps, mse on train / validation data: 0.00359 / 0.00386\n",
      "validate on 30 steps, mse on train / validation data: 0.00170 / 0.00137\n",
      "train fold 3 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11981, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11981 to 0.07597, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07597 to 0.01432, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.01432 to 0.00532, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00532 to 0.00487, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00487 to 0.00314, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00314 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00106 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00080 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00068 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00058 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00056 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00053 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00050 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00048 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00048 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00037 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00035 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00034 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00033 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00030 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00029 to 0.00029, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: val_loss improved from 0.00029 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00028 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00036, did not improve\n",
      "Epoch 00202: early stopping\n",
      "Using epoch 00172 with val_loss: 0.00027\n",
      "validate on 5 steps, mse on train / validation data: 0.02791 / 0.02917\n",
      "validate on 10 steps, mse on train / validation data: 0.01271 / 0.01067\n",
      "validate on 20 steps, mse on train / validation data: 0.00325 / 0.00335\n",
      "validate on 30 steps, mse on train / validation data: 0.00112 / 0.00149\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.02465  0.00741  0.00386  0.00171] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03649  0.00916  0.00438  0.00227]\n",
      " [ 0.00828  0.00239  0.00386  0.00137]\n",
      " [ 0.02917  0.01067  0.00335  0.00149]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.02072  0.00785  0.00401  0.00186] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.023    0.00734  0.00518  0.00274]\n",
      " [ 0.01124  0.00351  0.00359  0.0017 ]\n",
      " [ 0.02791  0.01271  0.00325  0.00112]]\n",
      "mse over all validation data 0.00171396584175\n",
      "results validation data \n",
      " [[ 0.03564  0.03488  0.03738  0.03708]\n",
      " [ 0.05233  0.05318  0.05976  0.04382]\n",
      " [ 0.02465  0.00741  0.00386  0.00171]]\n",
      "results training data\n",
      " [[ 0.04017  0.03959  0.04094  0.04036]\n",
      " [ 0.05081  0.05124  0.05655  0.03873]\n",
      " [ 0.02072  0.00785  0.00401  0.00186]]\n"
     ]
    }
   ],
   "source": [
    "# task 3.2\n",
    "cfg = {'batch_size': 20, 'lr': 0.002}\n",
    "res_train, res_val = np.zeros((3,4)), np.zeros((3,4))\n",
    "res_lstm_ns = []   # evaluating with next steps\n",
    "for i, train_steps in enumerate([5,10,20]):\n",
    "    res = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                    steps=(train_steps,[5,10,20,30]), \n",
    "                    cfg=cfg, epochs=1000, earlystop=True, mode='nextstep')\n",
    "    res_train[i], res_val[i] = res['trn_means'], res['val_means']\n",
    "    res_lstm_ns.append(res)\n",
    "print(\"results validation data \\n\", res_val)  \n",
    "print(\"results training data\\n\", res_train)\n",
    "t.pickle_to_file(res_lstm_ns, 'res_lstm_nextstep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train with random nr. of epochs, evaluate with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08584, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08584 to 0.07439, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07439 to 0.02369, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02369 to 0.01386, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01386 to 0.01289, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01289 to 0.00480, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00480 to 0.00335, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00353, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00335 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00280, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00342, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00121 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00099 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00090 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00396, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00270, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00318, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00363, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00339, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00065 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00181, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00063 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00365, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00285, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00046 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00219, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00059, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00150: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00036, did not improve\n",
      "Epoch 00160: early stopping\n",
      "Using epoch 00085 with val_loss: 0.00027\n",
      "validate on 5 steps, mse on train / validation data: 0.01471 / 0.02526\n",
      "validate on 10 steps, mse on train / validation data: 0.01031 / 0.01362\n",
      "validate on 20 steps, mse on train / validation data: 0.00436 / 0.00365\n",
      "validate on 30 steps, mse on train / validation data: 0.00166 / 0.00143\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train with random nr. of epochs, evaluate with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60643, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60643 to 0.04722, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04722 to 0.04653, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.06111, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04653 to 0.03205, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.03300, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03205 to 0.02693, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02693 to 0.01068, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01068 to 0.00309, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00309 to 0.00285, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00296, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00285 to 0.00163, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00163 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00095 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00060 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00055 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00041 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00035 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00026 to 0.00020, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00057, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00134: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00040, did not improve\n",
      "Epoch 00135: early stopping\n",
      "Using epoch 00081 with val_loss: 0.00020\n",
      "validate on 5 steps, mse on train / validation data: 0.16159 / 0.08641\n",
      "validate on 10 steps, mse on train / validation data: 0.12393 / 0.07440\n",
      "validate on 20 steps, mse on train / validation data: 0.03269 / 0.02646\n",
      "validate on 30 steps, mse on train / validation data: 0.00476 / 0.00441\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "train with random nr. of epochs, evaluate with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11001, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11001 to 0.08327, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08327 to 0.03608, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03608 to 0.01065, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01065 to 0.00554, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00554 to 0.00247, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00247 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00231, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00202 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00197 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00120 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00058 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00043 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00036 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00031 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00026, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00039, did not improve\n",
      "Epoch 00119: early stopping\n",
      "Using epoch 00055 with val_loss: 0.00025\n",
      "validate on 5 steps, mse on train / validation data: 0.02207 / 0.03434\n",
      "validate on 10 steps, mse on train / validation data: 0.01448 / 0.02045\n",
      "validate on 20 steps, mse on train / validation data: 0.00771 / 0.00859\n",
      "validate on 30 steps, mse on train / validation data: 0.00305 / 0.00316\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04867  0.03615  0.0129   0.003  ] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02526  0.01362  0.00365  0.00143]\n",
      " [ 0.08641  0.0744   0.02646  0.00441]\n",
      " [ 0.03434  0.02045  0.00859  0.00316]]\n",
      "MSE on training data on [5, 10, 20, 30] steps: means over folds: *** [ 0.06613  0.04957  0.01492  0.00315] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01471  0.01031  0.00436  0.00166]\n",
      " [ 0.16159  0.12393  0.03269  0.00476]\n",
      " [ 0.02207  0.01448  0.00771  0.00305]]\n",
      "results training data\n",
      " [ 0.06612556  0.04957401  0.01491995  0.00315308]\n",
      "results validation data \n",
      " [ 0.04866848  0.03615473  0.01290235  0.00300086]\n"
     ]
    }
   ],
   "source": [
    "# 3.3 train with random lenghts\n",
    "res = m.eval_cv('multi_lstm', [configs, lcs], Y, steps=(0,[5,10,20,30]), \n",
    "                cfg=cfg, epochs=1000, earlystop=True, mode='nextstep')\n",
    "\n",
    "print(\"results validation data \\n\", res['val_means'])  \n",
    "print(\"results training data\\n\", res['trn_means'])\n",
    "t.pickle_to_file(res, 'res_lstm_nextstep_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 5 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11554, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11554 to 0.04302, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04302 to 0.02813, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02813 to 0.01769, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01769 to 0.01097, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01097 to 0.00882, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00882 to 0.00847, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00847 to 0.00606, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00606 to 0.00438, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00979, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00438 to 0.00315, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.01117, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00341, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00329, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.01114, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.01599, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.01675, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.01499, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.01350, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.01058, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.01165, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.01304, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00317, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00866, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00371, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00410, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00448, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00477, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00413, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00315 to 0.00251, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00276, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00349, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00315, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00280, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00251 to 0.00250, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00250 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00220 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00181 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00160 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00137 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00297, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00513, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00398, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00252, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00287, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00247, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00347, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00362, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00285, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00272, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00235, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00251, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00254, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00239, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00219, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00228, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00252, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00271, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00229, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00256, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00256, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00228, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00203, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00228, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00245, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00238, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00220, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00226, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00223, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00219, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00203, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00186, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00186, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00192, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00195, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00199, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00226, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00268, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00428, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00266, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00150, did not improve\n",
      "Epoch 00123: early stopping\n",
      "Using epoch 00049 with val_loss: 0.00132\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 459us/step\n",
      "mse:  0.00131853502845\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 870us/step\n",
      "mse:  0.00133469417448\n",
      "validate on 5 steps, mse on train / validation data: 0.00133 / 0.00132\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "mse:  0.001162388689\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 1ms/step\n",
      "mse:  0.00171085036444\n",
      "validate on 10 steps, mse on train / validation data: 0.00171 / 0.00116\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "mse:  0.00321647753217\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "mse:  0.00388603562235\n",
      "validate on 20 steps, mse on train / validation data: 0.00389 / 0.00322\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "mse:  0.00459700725512\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 3ms/step\n",
      "mse:  0.00526945944875\n",
      "validate on 30 steps, mse on train / validation data: 0.00527 / 0.00460\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.34632, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.34632 to 0.06494, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06494 to 0.05340, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05340 to 0.02735, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02735 to 0.01483, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.02208, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.02008, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01483 to 0.01388, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01388 to 0.01224, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01224 to 0.00833, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00833 to 0.00687, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00687 to 0.00294, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00422, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00361, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.01338, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00979, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.01179, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.01202, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00840, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00460, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00359, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00848, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00386, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00294 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00257, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00398, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00671, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00487, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00265, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00330, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00441, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00438, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00239, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00324, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00421, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00466, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00334, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00272, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00348, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00401, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00348, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00256, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00312, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00347, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00317, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00266, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00289, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00302, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00284, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00267, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00267, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00271, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00269, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00264, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00256, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00254, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00252, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00250, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00247, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00244, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00242, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00239, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00238, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00237, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00234, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00229 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00228 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00227 to 0.00226, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00226 to 0.00223, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00223 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00222 to 0.00221, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00221 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00220 to 0.00217, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00217 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00216 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00216 to 0.00214, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00214 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00212 to 0.00211, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00211 to 0.00211, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00211 to 0.00209, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00209 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00207 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00207 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00206 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00204 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00203 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00202 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00201 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00199 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00198 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00197 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00195 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00194 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00193 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00191 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00190 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00189 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00188 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00187 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00186 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00185 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00184 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00183 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00182 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00181 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00181 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00180 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00179 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00178 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00177 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00176 to 0.00175, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: val_loss improved from 0.00175 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00174 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00173 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00173 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00172 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00172 to 0.00171, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00171 to 0.00170, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00170 to 0.00170, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00170 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00169 to 0.00168, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00168 to 0.00168, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00168 to 0.00167, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00167 to 0.00167, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00167 to 0.00166, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00166 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00165 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00165 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00164 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00164 to 0.00163, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00163 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00162 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00162 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00161 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00161 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00160 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00160 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00159 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00159 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00158 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00158 to 0.00157, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00157 to 0.00157, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00157 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00156 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00156 to 0.00155, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00155 to 0.00155, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00155 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00154 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00154 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00153 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00153 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00152 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00152 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00151 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00151 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00150 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00150 to 0.00149, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00149 to 0.00149, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00149 to 0.00148, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00148 to 0.00148, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00148 to 0.00147, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00147 to 0.00147, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00147 to 0.00146, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00146 to 0.00146, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00146 to 0.00146, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00146 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00145 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00145 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00144 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00144 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00143 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00143 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00143 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00142 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00142 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00141 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00141 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00141 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00140 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00140 to 0.00139, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00139 to 0.00139, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00139 to 0.00139, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.00139 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00138 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00138 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00138 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00137 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00137 to 0.00136, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00136 to 0.00136, storing weights.\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00136 to 0.00136, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00136 to 0.00135, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00135 to 0.00135, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.00135 to 0.00135, storing weights.\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00135 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00134 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00134 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00134 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00133 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00133 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00133 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.00132 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00132 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.00132 to 0.00131, storing weights.\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00131 to 0.00131, storing weights.\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.00131 to 0.00130, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00130 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00231: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00129 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00129 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00129 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00129 to 0.00128, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00128 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00127 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.00127 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.00127 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00127 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00247: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00126 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00126, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00251: val_loss improved from 0.00126 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00126 to 0.00125, storing weights.\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.00125 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00124 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.00124 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00256: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.00124 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00259: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.00124 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00261: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.00123 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.00123 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.00123 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00266: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.00122 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00268: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.00122 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00274: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.00121 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00276: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00120 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.00120 to 0.00119, storing weights.\n",
      "\n",
      "Epoch 00282: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.00119 to 0.00119, storing weights.\n",
      "\n",
      "Epoch 00289: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.00119 to 0.00118, storing weights.\n",
      "\n",
      "Epoch 00291: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00299: val_loss improved from 0.00118 to 0.00118, storing weights.\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.00118 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00301: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.00117 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00303: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.00117 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00310: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.00117 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00312: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.00116 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.00116 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00319: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.00116 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.00116 to 0.00115, storing weights.\n",
      "\n",
      "Epoch 00324: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00116, did not improve\n",
      "Epoch 00328: early stopping\n",
      "Using epoch 00323 with val_loss: 0.00115\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.00115162648779\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 903us/step\n",
      "mse:  0.0012707624862\n",
      "validate on 5 steps, mse on train / validation data: 0.00127 / 0.00115\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.00158448308833\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  0.0011413448456\n",
      "validate on 10 steps, mse on train / validation data: 0.00114 / 0.00158\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  0.0039176084207\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.00348516953004\n",
      "validate on 20 steps, mse on train / validation data: 0.00349 / 0.00392\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.0050399990075\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 1s 3ms/step\n",
      "mse:  0.00497433785639\n",
      "validate on 30 steps, mse on train / validation data: 0.00497 / 0.00504\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.99042, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.99042 to 1.47941, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 2.96802, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.47941 to 0.63913, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.63913 to 0.51863, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51863 to 0.08843, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08843 to 0.05703, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.05703 to 0.04830, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04830 to 0.03768, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03768 to 0.03411, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03411 to 0.02496, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.02528, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02496 to 0.02449, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02449 to 0.02441, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.02461, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.02456, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02441 to 0.02439, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.02445, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.02444, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.02445, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.02446, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.02447, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.02448, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.02449, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.02449, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.02449, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.02449, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.02450, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.02450, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.02450, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.02450, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.02451, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.02451, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.02451, did not improve\n",
      "Epoch 00093: early stopping\n",
      "Using epoch 00018 with val_loss: 0.02439\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 765us/step\n",
      "mse:  0.0243879513053\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 776us/step\n",
      "mse:  0.0299257414868\n",
      "validate on 5 steps, mse on train / validation data: 0.02993 / 0.02439\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.0243879513053\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  0.0299257414868\n",
      "validate on 10 steps, mse on train / validation data: 0.02993 / 0.02439\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  0.0243879513053\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.0299257414868\n",
      "validate on 20 steps, mse on train / validation data: 0.02993 / 0.02439\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.0243879513053\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.0299257414868\n",
      "validate on 30 steps, mse on train / validation data: 0.02993 / 0.02439\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00895  0.00904  0.01051  0.01134] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00132  0.00116  0.00322  0.0046 ]\n",
      " [ 0.00115  0.00158  0.00392  0.00504]\n",
      " [ 0.02439  0.02439  0.02439  0.02439]]\n",
      "MSE on training data on [5, 10, 20, 30] steps: means over folds: *** [ 0.01084  0.01093  0.01243  0.01339] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00133  0.00171  0.00389  0.00527]\n",
      " [ 0.00127  0.00114  0.00349  0.00497]\n",
      " [ 0.02993  0.02993  0.02993  0.02993]]\n",
      "cross validate 1000 epochs, train on 10 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12057, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12057 to 0.06355, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06355 to 0.03759, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03759 to 0.00790, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00790 to 0.00766, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00766 to 0.00323, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00895, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 0.01408, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00372, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00454, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.01132, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00389, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00323 to 0.00304, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.00340, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00337, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00318, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00304 to 0.00301, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00301 to 0.00289, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00289 to 0.00259, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00259 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00227 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00199 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00178 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00152 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00286, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00180, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00354, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00241, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00122 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00120 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00104 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00226, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00149, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00089 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00087 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00085 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00084, did not improve\n",
      "Epoch 00120: early stopping\n",
      "Using epoch 00088 with val_loss: 0.00082\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 481us/step\n",
      "mse:  0.0608066631418\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 855us/step\n",
      "mse:  0.0477681301365\n",
      "validate on 5 steps, mse on train / validation data: 0.04777 / 0.06081\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 1ms/step\n",
      "mse:  0.000824270867403\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 1ms/step\n",
      "mse:  0.000763803920894\n",
      "validate on 10 steps, mse on train / validation data: 0.00076 / 0.00082\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "mse:  0.00128009282\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "mse:  0.00143760890404\n",
      "validate on 20 steps, mse on train / validation data: 0.00144 / 0.00128\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "mse:  0.00213678000401\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 1s 3ms/step\n",
      "mse:  0.0023780453167\n",
      "validate on 30 steps, mse on train / validation data: 0.00238 / 0.00214\n",
      "train fold 2 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26239, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26239 to 0.07691, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.12018, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07691 to 0.05873, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05873 to 0.02621, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.03345, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02621 to 0.02494, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02494 to 0.01605, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01605 to 0.01107, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01107 to 0.00395, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00395 to 0.00253, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00253 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00169 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00090 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00079 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00072 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00066 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00064 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00061 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00065, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00060: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00061 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00060 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00068, did not improve\n",
      "Epoch 00106: early stopping\n",
      "Using epoch 00083 with val_loss: 0.00060\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 590us/step\n",
      "mse:  0.0690140077336\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 744us/step\n",
      "mse:  0.0738325941319\n",
      "validate on 5 steps, mse on train / validation data: 0.07383 / 0.06901\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.000604276981903\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  0.000690422686459\n",
      "validate on 10 steps, mse on train / validation data: 0.00069 / 0.00060\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  0.00140974406068\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.0012300674403\n",
      "validate on 20 steps, mse on train / validation data: 0.00123 / 0.00141\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.00224876565732\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 3ms/step\n",
      "mse:  0.00229339740215\n",
      "validate on 30 steps, mse on train / validation data: 0.00229 / 0.00225\n",
      "train fold 3 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12354, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12354 to 0.04591, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.04597, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04591 to 0.02748, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02748 to 0.01963, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01963 to 0.01252, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01252 to 0.00803, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00803 to 0.00658, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00658 to 0.00560, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00560 to 0.00375, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00375 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00290, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00194 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00174 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00172 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00193, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00153 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00150 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00140 to 0.00110, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00110 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00108 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00104 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00205, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00216, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00099 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00095 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00095 to 0.00094, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00076: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00094 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00093 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "Epoch 00104: early stopping\n",
      "Using epoch 00104 with val_loss: 0.00091\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 526us/step\n",
      "mse:  0.789464980364\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 710us/step\n",
      "mse:  0.750682481601\n",
      "validate on 5 steps, mse on train / validation data: 0.75068 / 0.78946\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.000914607464272\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  0.000559727040101\n",
      "validate on 10 steps, mse on train / validation data: 0.00056 / 0.00091\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.980713968927\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.812348923104\n",
      "validate on 20 steps, mse on train / validation data: 0.81235 / 0.98071\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.750668579882\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 1s 4ms/step\n",
      "mse:  0.836846585664\n",
      "validate on 30 steps, mse on train / validation data: 0.83685 / 0.75067\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.30643  0.00078  0.3278   0.25168] ***\n",
      "Results validation data of all Folds: \n",
      "[[  6.08100000e-02   8.20000000e-04   1.28000000e-03   2.14000000e-03]\n",
      " [  6.90100000e-02   6.00000000e-04   1.41000000e-03   2.25000000e-03]\n",
      " [  7.89460000e-01   9.10000000e-04   9.80710000e-01   7.50670000e-01]]\n",
      "MSE on training data on [5, 10, 20, 30] steps: means over folds: *** [ 0.29076  0.00067  0.27167  0.28051] ***\n",
      "Results training data of all Folds: \n",
      "[[  4.77700000e-02   7.60000000e-04   1.44000000e-03   2.38000000e-03]\n",
      " [  7.38300000e-02   6.90000000e-04   1.23000000e-03   2.29000000e-03]\n",
      " [  7.50680000e-01   5.60000000e-04   8.12350000e-01   8.36850000e-01]]\n",
      "cross validate 1000 epochs, train on 20 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14798, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14798 to 0.04405, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04405 to 0.00993, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00993 to 0.00817, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00817 to 0.00592, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00592 to 0.00324, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 0.00419, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00324 to 0.00244, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00244 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00096 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00267, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00093 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00059 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00055 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00050 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00252, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00064, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00079: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00063, did not improve\n",
      "Epoch 00116: early stopping\n",
      "Using epoch 00041 with val_loss: 0.00047\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 641us/step\n",
      "mse:  0.0258297447869\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 860us/step\n",
      "mse:  0.0263428334147\n",
      "validate on 5 steps, mse on train / validation data: 0.02634 / 0.02583\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 1ms/step\n",
      "mse:  0.0107730397683\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 1ms/step\n",
      "mse:  0.00910780364013\n",
      "validate on 10 steps, mse on train / validation data: 0.00911 / 0.01077\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 2ms/step\n",
      "mse:  0.000469433154199\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "mse:  0.000500161555961\n",
      "validate on 20 steps, mse on train / validation data: 0.00050 / 0.00047\n",
      "evaluate lstm with consideration of configs\n",
      "89/89 [==============================] - 0s 3ms/step\n",
      "mse:  0.000675560233544\n",
      "evaluate lstm with consideration of configs\n",
      "176/176 [==============================] - 0s 3ms/step\n",
      "mse:  0.000807838148665\n",
      "validate on 30 steps, mse on train / validation data: 0.00081 / 0.00068\n",
      "train fold 2 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.17151, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.17151 to 1.22318, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.22318 to 0.66304, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.96452, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66304 to 0.11085, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11085 to 0.07196, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.07196 to 0.03687, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03687 to 0.03687, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03687 to 0.00837, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.01021, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00837 to 0.00530, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00530 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00227 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00175 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00161 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00126 to 0.00113, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00113 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00107 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00103 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00100 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00096 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00093 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00090 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00087 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00085 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00083 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00072 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00070 to 0.00069, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00075: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00065 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00063 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00061 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00060 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00060 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00055 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00053 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00051 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00051 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00051 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00037 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00044, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00210: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00051, did not improve\n",
      "Epoch 00223: early stopping\n",
      "Using epoch 00156 with val_loss: 0.00035\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 665us/step\n",
      "mse:  0.0250337426974\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 799us/step\n",
      "mse:  0.0298722941786\n",
      "validate on 5 steps, mse on train / validation data: 0.02987 / 0.02503\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  4.91890081492\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  5.00050854009\n",
      "validate on 10 steps, mse on train / validation data: 5.00051 / 4.91890\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  0.000351062770113\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.000462018283239\n",
      "validate on 20 steps, mse on train / validation data: 0.00046 / 0.00035\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  3.78144966472\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  3.87956652129\n",
      "validate on 30 steps, mse on train / validation data: 3.87957 / 3.78145\n",
      "train fold 3 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11390, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11390 to 0.05036, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05036 to 0.02813, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02813 to 0.01418, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01418 to 0.00257, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00446, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.00323, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 0.00398, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00294, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00257 to 0.00224, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00224 to 0.00218, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00218 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00158 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00129 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00126 to 0.00113, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00113 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00106 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00106 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00105 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00104 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00104 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00103 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00102 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00102 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00101 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00100 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00100 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00099 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00098 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00098 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00097 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00097 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00097 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00097 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00096 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00096 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00095 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00091 to 0.00090, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00102: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00087 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00085 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00083 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00083 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00081 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00076 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss is 0.00073, did not improve\n",
      "Epoch 00213: early stopping\n",
      "Using epoch 00212 with val_loss: 0.00073\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 614us/step\n",
      "mse:  0.00897776255045\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 853us/step\n",
      "mse:  0.0123261121959\n",
      "validate on 5 steps, mse on train / validation data: 0.01233 / 0.00898\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 1ms/step\n",
      "mse:  0.00932959319008\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 1ms/step\n",
      "mse:  0.0085558105197\n",
      "validate on 10 steps, mse on train / validation data: 0.00856 / 0.00933\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 2ms/step\n",
      "mse:  0.000731091864344\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 2ms/step\n",
      "mse:  0.000461046307382\n",
      "validate on 20 steps, mse on train / validation data: 0.00046 / 0.00073\n",
      "evaluate lstm with consideration of configs\n",
      "88/88 [==============================] - 0s 3ms/step\n",
      "mse:  0.000526615978742\n",
      "evaluate lstm with consideration of configs\n",
      "177/177 [==============================] - 0s 3ms/step\n",
      "mse:  0.000265021034481\n",
      "validate on 30 steps, mse on train / validation data: 0.00027 / 0.00053\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [  1.99500000e-02   1.64633000e+00   5.20000000e-04   1.26088000e+00] ***\n",
      "Results validation data of all Folds: \n",
      "[[  2.58300000e-02   1.07700000e-02   4.70000000e-04   6.80000000e-04]\n",
      " [  2.50300000e-02   4.91890000e+00   3.50000000e-04   3.78145000e+00]\n",
      " [  8.98000000e-03   9.33000000e-03   7.30000000e-04   5.30000000e-04]]\n",
      "MSE on training data on [5, 10, 20, 30] steps: means over folds: *** [  2.28500000e-02   1.67272000e+00   4.70000000e-04   1.29355000e+00] ***\n",
      "Results training data of all Folds: \n",
      "[[  2.63400000e-02   9.11000000e-03   5.00000000e-04   8.10000000e-04]\n",
      " [  2.98700000e-02   5.00051000e+00   4.60000000e-04   3.87957000e+00]\n",
      " [  1.23300000e-02   8.56000000e-03   4.60000000e-04   2.70000000e-04]]\n",
      "[[  1.08437327e-02   1.09259789e-02   1.24323155e-02   1.33898463e-02]\n",
      " [  2.90761069e-01   6.71317882e-04   2.71672200e-01   2.80506009e-01]\n",
      " [  2.28470799e-02   1.67272405e+00   4.74408716e-04   1.29354646e+00]]\n",
      "[[  8.95270427e-03   9.04494103e-03   1.05073458e-02   1.13416525e-02]\n",
      " [  3.06428550e-01   7.81051771e-04   3.27801269e-01   2.51684709e-01]\n",
      " [  1.99470833e-02   1.64633448e+00   5.17195930e-04   1.26088395e+00]]\n"
     ]
    }
   ],
   "source": [
    "# task 3.3 base line training with fixed lenghts (on final epoch)\n",
    "cfg = {'batch_size': 20, 'lr': 0.002}\n",
    "res_train, res_val = np.zeros((3,4)), np.zeros((3,4))\n",
    "res_lstm_finalstep = []   # evaluating directly on final steps\n",
    "for i, train_steps in enumerate([5,10,20]):\n",
    "    res = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                     steps=(train_steps,[5,10,20,30]), \n",
    "                     cfg=cfg, epochs=1000, earlystop=True, \n",
    "                     mode='finalstep')\n",
    "    res_train[i], res_val[i] = res['trn_means'], res['val_means']\n",
    "    res_lstm_finalstep.append(res)    \n",
    "print(\"results validation data \\n\", res_val)  \n",
    "print(\"results training data\\n\", res_train)\n",
    "t.pickle_to_file(res_lstm_finalstep, 'res_lstm_finalstep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06410, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06410 to 0.03095, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03095 to 0.00941, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.01184, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00941 to 0.00702, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00702 to 0.00428, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00428 to 0.00373, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00440, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00373 to 0.00358, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00617, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00358 to 0.00316, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00437, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00316 to 0.00297, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00340, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00313, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00520, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00297 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00329, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00180 to 0.00167, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00193, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00275, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00311, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00330, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00221, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00426, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00432, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00333, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00254, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00167 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00277, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00412, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00387, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00408, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00366, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00229, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00453, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00341, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00245, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00389, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00280, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00291, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00205, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00210, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00162 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00348, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00285, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00150 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.00179, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00353, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00338, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00349, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00434, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00360, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00186, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00143 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00215, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00121 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00323, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00266, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00363, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00530, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00450, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00193, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00101 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00360, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00244, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00276, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00213, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00087 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.00235, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00312, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00281, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00311, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00220, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00083 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss is 0.00248, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00075 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00101, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00148: val_loss is 0.00392, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00336, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00440, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00278, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00235, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00068 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00062 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00059 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00287, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00214, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00209, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00193, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00086, did not improve\n",
      "Epoch 00301: early stopping\n",
      "Using epoch 00235 with val_loss: 0.00059\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00130 / 0.00146\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00073 / 0.00066\n",
      "evaluate lstm with consideration of configs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00058 / 0.00057\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00128 / 0.00111\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09386, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09386 to 0.05620, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05620 to 0.01881, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01881 to 0.00845, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.01113, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00845 to 0.00803, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00803 to 0.00357, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00357 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00325, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00228 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00276, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00137 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00226, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00197, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00122 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00201, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00196, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00216, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00103 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00087 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00076 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00073 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00071 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00067 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00063 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00063, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00146: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00050 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00045 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00043 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00200, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "Epoch 00253: early stopping\n",
      "Using epoch 00253 with val_loss: 0.00041\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00144 / 0.00070\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00065 / 0.00049\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00053 / 0.00042\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00082 / 0.00061\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18725, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18725 to 0.08344, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08344 to 0.01869, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01869 to 0.01259, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01259 to 0.00759, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00759 to 0.00330, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00434, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 0.00375, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00344, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00365, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00549, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00412, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00330 to 0.00219, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00219 to 0.00208, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00371, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00287, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00208 to 0.00128, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00128 to 0.00111, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.00241, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00212, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00202, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00170, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00031: val_loss is 0.00295, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00209, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00251, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00245, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00200, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00242, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00252, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00195, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00274, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00228, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00111 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00216, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00093 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00199, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00090 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00223, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00087 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00124, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00190: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00096, did not improve\n",
      "Epoch 00226: early stopping\n",
      "Using epoch 00151 with val_loss: 0.00082\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00157 / 0.00258\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00053 / 0.00090\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00042 / 0.00059\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00049 / 0.00077\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00158  0.00068  0.00053  0.00083] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00146  0.00066  0.00057  0.00111]\n",
      " [ 0.0007   0.00049  0.00042  0.00061]\n",
      " [ 0.00258  0.0009   0.00059  0.00077]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00144  0.00064  0.00051  0.00086] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.0013   0.00073  0.00058  0.00128]\n",
      " [ 0.00144  0.00065  0.00053  0.00082]\n",
      " [ 0.00157  0.00053  0.00042  0.00049]]\n",
      "results validation data \n",
      " [ 0.00158  0.00068  0.00053  0.00083]\n",
      "results training data\n",
      " [ 0.00144  0.00064  0.00051  0.00086]\n"
     ]
    }
   ],
   "source": [
    "# 3.3 train train using final points with random lenghts\n",
    "res = m.eval_cv('multi_lstm', [configs, lcs], Y, steps=(0,[5,10,20,30]), \n",
    "                cfg=cfg, epochs=1000, earlystop=True, mode='finalstep')\n",
    "\n",
    "print(\"results validation data \\n\", res['val_means'])  \n",
    "print(\"results training data\\n\", res['trn_means'])\n",
    "t.pickle_to_file(res, 'res_lstm_finalstep_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 0 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'lr': 0.08119864140758115, 'subsample': 0.7946631901813815, 'n_estimators': 1000, 'gamma': 0.007833441242813044, 'maxdepth': 10, 'cols_bt': 0.9376450587145334}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train on new epoch 5 true value for curve no. 13 (example) 0.584156378552\n",
      "train on new epoch 6 true value for curve no. 13 (example) 0.578395060919\n",
      "train on new epoch 7 true value for curve no. 13 (example) 0.527057613488\n",
      "train on new epoch 8 true value for curve no. 13 (example) 0.500720170913\n",
      "train on new epoch 9 true value for curve no. 13 (example) 0.494855966833\n",
      "train on new epoch 10 true value for curve no. 13 (example) 0.454835391707\n",
      "train on new epoch 11 true value for curve no. 13 (example) 0.458230453509\n",
      "train on new epoch 12 true value for curve no. 13 (example) 0.465432094203\n",
      "train on new epoch 13 true value for curve no. 13 (example) 0.472633742624\n",
      "train on new epoch 14 true value for curve no. 13 (example) 0.44094650061\n",
      "train on new epoch 15 true value for curve no. 13 (example) 0.398662551686\n",
      "train on new epoch 16 true value for curve no. 13 (example) 0.417901235598\n",
      "train on new epoch 17 true value for curve no. 13 (example) 0.432510285466\n",
      "train on new epoch 18 true value for curve no. 13 (example) 0.37952675422\n",
      "train on new epoch 19 true value for curve no. 13 (example) 0.399382723702\n",
      "train on new epoch 20 true value for curve no. 13 (example) 0.371913578775\n",
      "train on new epoch 21 true value for curve no. 13 (example) 0.374074074957\n",
      "train on new epoch 22 true value for curve no. 13 (example) 0.378189303257\n",
      "train on new epoch 23 true value for curve no. 13 (example) 0.351543205756\n",
      "train on new epoch 24 true value for curve no. 13 (example) 0.330349789725\n",
      "train on new epoch 25 true value for curve no. 13 (example) 0.318209884343\n",
      "train on new epoch 26 true value for curve no. 13 (example) 0.36121398652\n",
      "train on new epoch 27 true value for curve no. 13 (example) 0.320370373902\n",
      "train on new epoch 28 true value for curve no. 13 (example) 0.34917695434\n",
      "train on new epoch 29 true value for curve no. 13 (example) 0.318004115864\n",
      "train on new epoch 30 true value for curve no. 13 (example) 0.313580245883\n",
      "train on new epoch 31 true value for curve no. 13 (example) 0.321296292323\n",
      "train on new epoch 32 true value for curve no. 13 (example) 0.32448559558\n",
      "train on new epoch 33 true value for curve no. 13 (example) 0.34002057049\n",
      "train on new epoch 34 true value for curve no. 13 (example) 0.311934159862\n",
      "train on new epoch 35 true value for curve no. 13 (example) 0.339094645447\n",
      "train on new epoch 36 true value for curve no. 13 (example) 0.330349800763\n",
      "train on new epoch 37 true value for curve no. 13 (example) 0.306172834502\n",
      "train on new epoch 38 true value for curve no. 13 (example) 0.32294238276\n",
      "train on new epoch 39 true value for curve no. 13 (example) 0.302572014155\n",
      "train on new epoch 40 true value for curve no. 13 (example) 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 5 prediction / true value for lc number 13 0.326982 / 0.276659959129\n",
      "step nr. 6 prediction / true value for lc number 13 0.318048 / 0.275050303766\n",
      "step nr. 7 prediction / true value for lc number 13 0.325919 / 0.288933598569\n",
      "step nr. 8 prediction / true value for lc number 13 0.308534 / 0.275251509888\n",
      "step nr. 9 prediction / true value for lc number 13 0.317099 / 0.311066399728\n",
      "step nr. 10 prediction / true value for lc number 13 0.306027 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.311122 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.301471 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.301088 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.296533 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.296533 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.296533 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.296533 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.296533 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.296533 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.296533 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.296533 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.296533 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.296533 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.296533 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.296533 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.296533 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.296533 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.296533 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.296533 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.296533 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.296533 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.296533 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.296533 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.296533 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.296533 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.296533 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.296533 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.296533 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.296533 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 5 prediction / true value for lc number 13 0.827147 / 0.578395060919\n",
      "step nr. 6 prediction / true value for lc number 13 0.792634 / 0.527057613488\n",
      "step nr. 7 prediction / true value for lc number 13 0.71391 / 0.500720170913\n",
      "step nr. 8 prediction / true value for lc number 13 0.742944 / 0.494855966833\n",
      "step nr. 9 prediction / true value for lc number 13 0.870816 / 0.454835391707\n",
      "step nr. 10 prediction / true value for lc number 13 0.838877 / 0.458230453509\n",
      "step nr. 11 prediction / true value for lc number 13 0.817926 / 0.465432094203\n",
      "step nr. 12 prediction / true value for lc number 13 0.842618 / 0.472633742624\n",
      "step nr. 13 prediction / true value for lc number 13 0.874557 / 0.44094650061\n",
      "step nr. 14 prediction / true value for lc number 13 0.874557 / 0.398662551686\n",
      "step nr. 15 prediction / true value for lc number 13 0.874557 / 0.417901235598\n",
      "step nr. 16 prediction / true value for lc number 13 0.874557 / 0.432510285466\n",
      "step nr. 17 prediction / true value for lc number 13 0.874557 / 0.37952675422\n",
      "step nr. 18 prediction / true value for lc number 13 0.874557 / 0.399382723702\n",
      "step nr. 19 prediction / true value for lc number 13 0.874557 / 0.371913578775\n",
      "step nr. 20 prediction / true value for lc number 13 0.874557 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.874557 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.874557 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.874557 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.874557 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.874557 / 0.36121398652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 26 prediction / true value for lc number 13 0.874557 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.874557 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.874557 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.874557 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.874557 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.874557 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.874557 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.874557 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.874557 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.874557 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.874557 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.874557 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.874557 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.874557 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 10 prediction / true value for lc number 13 0.281761 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.293365 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.273654 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.287996 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.27613 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.285244 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.273654 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.283982 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.273654 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.281323 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.273654 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.27613 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.273654 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.273654 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.273654 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.273654 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.273654 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.273654 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.273654 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.273654 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.273654 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.273654 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.273654 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.273654 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.273654 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.273654 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.273654 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.273654 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.273654 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.273654 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 10 prediction / true value for lc number 13 0.542816 / 0.458230453509\n",
      "step nr. 11 prediction / true value for lc number 13 0.474905 / 0.465432094203\n",
      "step nr. 12 prediction / true value for lc number 13 0.501156 / 0.472633742624\n",
      "step nr. 13 prediction / true value for lc number 13 0.474768 / 0.44094650061\n",
      "step nr. 14 prediction / true value for lc number 13 0.559699 / 0.398662551686\n",
      "step nr. 15 prediction / true value for lc number 13 0.470011 / 0.417901235598\n",
      "step nr. 16 prediction / true value for lc number 13 0.501156 / 0.432510285466\n",
      "step nr. 17 prediction / true value for lc number 13 0.474768 / 0.37952675422\n",
      "step nr. 18 prediction / true value for lc number 13 0.584386 / 0.399382723702\n",
      "step nr. 19 prediction / true value for lc number 13 0.470011 / 0.371913578775\n",
      "step nr. 20 prediction / true value for lc number 13 0.501156 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.474768 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.692753 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.470011 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.501156 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.50006 / 0.36121398652\n",
      "step nr. 26 prediction / true value for lc number 13 0.771477 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.479863 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.501156 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.504955 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.792428 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.479863 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.501156 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.504955 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.792428 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.479863 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.501156 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.504955 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.792428 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.479863 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 20 prediction / true value for lc number 13 0.240653 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.251472 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.244716 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.239961 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.244298 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.244716 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.244298 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.244298 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.244298 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.244298 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.244298 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.244298 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.244298 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.244298 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.244298 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.244298 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.244298 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.244298 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.244298 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.244298 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 20 prediction / true value for lc number 13 0.387555 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.383345 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.377112 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.367352 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.374395 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.365674 / 0.36121398652\n",
      "step nr. 26 prediction / true value for lc number 13 0.374395 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.35863 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.369658 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.354651 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.365404 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.354651 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.354376 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.354651 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.350397 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.350397 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.348069 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.348069 / 0.32294238276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 38 prediction / true value for lc number 13 0.348069 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.348069 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 30 prediction / true value for lc number 13 0.221099 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.221099 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.214998 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.216762 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.216762 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.214998 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.214998 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.214998 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.214998 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.214998 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 30 prediction / true value for lc number 13 0.316017 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.320824 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.311122 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.311122 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.306027 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.306027 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.301471 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.296533 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.296533 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.296533 / 0.330041154667\n",
      "validate on 30 steps, mse on train / validation data: 0.00049 / 0.00105\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train on new epoch 5 true value for curve no. 13 (example) 0.297987927284\n",
      "train on new epoch 6 true value for curve no. 13 (example) 0.276659959129\n",
      "train on new epoch 7 true value for curve no. 13 (example) 0.275050303766\n",
      "train on new epoch 8 true value for curve no. 13 (example) 0.288933598569\n",
      "train on new epoch 9 true value for curve no. 13 (example) 0.275251509888\n",
      "train on new epoch 10 true value for curve no. 13 (example) 0.311066399728\n",
      "train on new epoch 11 true value for curve no. 13 (example) 0.257645875216\n",
      "train on new epoch 12 true value for curve no. 13 (example) 0.26348088256\n",
      "train on new epoch 13 true value for curve no. 13 (example) 0.282394366605\n",
      "train on new epoch 14 true value for curve no. 13 (example) 0.245372237904\n",
      "train on new epoch 15 true value for curve no. 13 (example) 0.252716300743\n",
      "train on new epoch 16 true value for curve no. 13 (example) 0.246177060263\n",
      "train on new epoch 17 true value for curve no. 13 (example) 0.235714284437\n",
      "train on new epoch 18 true value for curve no. 13 (example) 0.264486921685\n",
      "train on new epoch 19 true value for curve no. 13 (example) 0.253319919109\n",
      "train on new epoch 20 true value for curve no. 13 (example) 0.230482899717\n",
      "train on new epoch 21 true value for curve no. 13 (example) 0.227062367967\n",
      "train on new epoch 22 true value for curve no. 13 (example) 0.232796779701\n",
      "train on new epoch 23 true value for curve no. 13 (example) 0.227364180343\n",
      "train on new epoch 24 true value for curve no. 13 (example) 0.229476860591\n",
      "train on new epoch 25 true value for curve no. 13 (example) 0.229577464717\n",
      "train on new epoch 26 true value for curve no. 13 (example) 0.248390346766\n",
      "train on new epoch 27 true value for curve no. 13 (example) 0.242354122656\n",
      "train on new epoch 28 true value for curve no. 13 (example) 0.243561365775\n",
      "train on new epoch 29 true value for curve no. 13 (example) 0.22173038125\n",
      "train on new epoch 30 true value for curve no. 13 (example) 0.215492953147\n",
      "train on new epoch 31 true value for curve no. 13 (example) 0.219617709517\n",
      "train on new epoch 32 true value for curve no. 13 (example) 0.235211265939\n",
      "train on new epoch 33 true value for curve no. 13 (example) 0.230382293463\n",
      "train on new epoch 34 true value for curve no. 13 (example) 0.227565382208\n",
      "train on new epoch 35 true value for curve no. 13 (example) 0.224044261234\n",
      "train on new epoch 36 true value for curve no. 13 (example) 0.331790747387\n",
      "train on new epoch 37 true value for curve no. 13 (example) 0.246981897524\n",
      "train on new epoch 38 true value for curve no. 13 (example) 0.214084506035\n",
      "train on new epoch 39 true value for curve no. 13 (example) 0.214084501777\n",
      "train on new epoch 40 true value for curve no. 13 (example) 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 5 prediction / true value for lc number 13 0.806425 / 0.578395060919\n",
      "step nr. 6 prediction / true value for lc number 13 0.756053 / 0.527057613488\n",
      "step nr. 7 prediction / true value for lc number 13 0.741435 / 0.500720170913\n",
      "step nr. 8 prediction / true value for lc number 13 0.735141 / 0.494855966833\n",
      "step nr. 9 prediction / true value for lc number 13 0.860325 / 0.454835391707\n",
      "step nr. 10 prediction / true value for lc number 13 0.814813 / 0.458230453509\n",
      "step nr. 11 prediction / true value for lc number 13 0.810539 / 0.465432094203\n",
      "step nr. 12 prediction / true value for lc number 13 0.829144 / 0.472633742624\n",
      "step nr. 13 prediction / true value for lc number 13 0.878929 / 0.44094650061\n",
      "step nr. 14 prediction / true value for lc number 13 0.878929 / 0.398662551686\n",
      "step nr. 15 prediction / true value for lc number 13 0.878929 / 0.417901235598\n",
      "step nr. 16 prediction / true value for lc number 13 0.878929 / 0.432510285466\n",
      "step nr. 17 prediction / true value for lc number 13 0.878929 / 0.37952675422\n",
      "step nr. 18 prediction / true value for lc number 13 0.878929 / 0.399382723702\n",
      "step nr. 19 prediction / true value for lc number 13 0.878929 / 0.371913578775\n",
      "step nr. 20 prediction / true value for lc number 13 0.878929 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.878929 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.878929 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.878929 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.878929 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.878929 / 0.36121398652\n",
      "step nr. 26 prediction / true value for lc number 13 0.878929 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.878929 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.878929 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.878929 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.878929 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.878929 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.878929 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.878929 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.878929 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.878929 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.878929 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.878929 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.878929 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.878929 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 5 prediction / true value for lc number 13 0.33173 / 0.276659959129\n",
      "step nr. 6 prediction / true value for lc number 13 0.308723 / 0.275050303766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 7 prediction / true value for lc number 13 0.323158 / 0.288933598569\n",
      "step nr. 8 prediction / true value for lc number 13 0.308723 / 0.275251509888\n",
      "step nr. 9 prediction / true value for lc number 13 0.311356 / 0.311066399728\n",
      "step nr. 10 prediction / true value for lc number 13 0.308723 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.307247 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.307247 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.307247 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.307247 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.307247 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.307247 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.307247 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.307247 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.307247 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.307247 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.307247 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.307247 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.307247 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.307247 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.307247 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.307247 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.307247 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.307247 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.307247 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.307247 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.307247 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.307247 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.307247 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.307247 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.307247 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.307247 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.307247 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.307247 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.307247 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 10 prediction / true value for lc number 13 0.518932 / 0.458230453509\n",
      "step nr. 11 prediction / true value for lc number 13 0.496154 / 0.465432094203\n",
      "step nr. 12 prediction / true value for lc number 13 0.47981 / 0.472633742624\n",
      "step nr. 13 prediction / true value for lc number 13 0.470411 / 0.44094650061\n",
      "step nr. 14 prediction / true value for lc number 13 0.518932 / 0.398662551686\n",
      "step nr. 15 prediction / true value for lc number 13 0.478753 / 0.417901235598\n",
      "step nr. 16 prediction / true value for lc number 13 0.478264 / 0.432510285466\n",
      "step nr. 17 prediction / true value for lc number 13 0.470411 / 0.37952675422\n",
      "step nr. 18 prediction / true value for lc number 13 0.518932 / 0.399382723702\n",
      "step nr. 19 prediction / true value for lc number 13 0.470411 / 0.371913578775\n",
      "step nr. 20 prediction / true value for lc number 13 0.478264 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.470411 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.518932 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.470411 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.478264 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.470411 / 0.36121398652\n",
      "step nr. 26 prediction / true value for lc number 13 0.518932 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.470411 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.478264 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.470411 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.518932 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.470411 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.478264 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.470411 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.518932 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.470411 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.478264 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.470411 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.518932 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.470411 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 10 prediction / true value for lc number 13 0.284761 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.293934 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.292961 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.295669 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.291778 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.301144 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.295669 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.301144 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.301144 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.301144 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.301144 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.301144 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.301144 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.301144 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.301144 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.301144 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.301144 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.301144 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.301144 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.301144 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.301144 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.301144 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.301144 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.301144 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.301144 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.301144 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.301144 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.301144 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.301144 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.301144 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 20 prediction / true value for lc number 13 0.402062 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.379441 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.384904 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.374249 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.384904 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.371541 / 0.36121398652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 26 prediction / true value for lc number 13 0.376876 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.366349 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.376876 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.363279 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.366349 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.359094 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.360761 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.359094 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.356575 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.351391 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.356575 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.351391 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.349468 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.344566 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 20 prediction / true value for lc number 13 0.238221 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.243812 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.231052 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.238221 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.231052 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.231052 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.231052 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.231052 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.231052 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.231052 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.231052 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.231052 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.231052 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.231052 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.231052 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.231052 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.231052 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.231052 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.231052 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.231052 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 30 prediction / true value for lc number 13 0.31241 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.329096 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.308723 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.311356 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.308723 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.307247 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.307247 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.307247 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.307247 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.307247 / 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 30 prediction / true value for lc number 13 0.221494 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.216509 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.212515 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.214149 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.209929 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.209929 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.209929 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.207869 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.207869 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.207869 / 0.205030181578\n",
      "validate on 30 steps, mse on train / validation data: 0.00050 / 0.00036\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "train on new epoch 5 true value for curve no. 13 (example) 0.297987927284\n",
      "train on new epoch 6 true value for curve no. 13 (example) 0.276659959129\n",
      "train on new epoch 7 true value for curve no. 13 (example) 0.275050303766\n",
      "train on new epoch 8 true value for curve no. 13 (example) 0.288933598569\n",
      "train on new epoch 9 true value for curve no. 13 (example) 0.275251509888\n",
      "train on new epoch 10 true value for curve no. 13 (example) 0.311066399728\n",
      "train on new epoch 11 true value for curve no. 13 (example) 0.257645875216\n",
      "train on new epoch 12 true value for curve no. 13 (example) 0.26348088256\n",
      "train on new epoch 13 true value for curve no. 13 (example) 0.282394366605\n",
      "train on new epoch 14 true value for curve no. 13 (example) 0.245372237904\n",
      "train on new epoch 15 true value for curve no. 13 (example) 0.252716300743\n",
      "train on new epoch 16 true value for curve no. 13 (example) 0.246177060263\n",
      "train on new epoch 17 true value for curve no. 13 (example) 0.235714284437\n",
      "train on new epoch 18 true value for curve no. 13 (example) 0.264486921685\n",
      "train on new epoch 19 true value for curve no. 13 (example) 0.253319919109\n",
      "train on new epoch 20 true value for curve no. 13 (example) 0.230482899717\n",
      "train on new epoch 21 true value for curve no. 13 (example) 0.227062367967\n",
      "train on new epoch 22 true value for curve no. 13 (example) 0.232796779701\n",
      "train on new epoch 23 true value for curve no. 13 (example) 0.227364180343\n",
      "train on new epoch 24 true value for curve no. 13 (example) 0.229476860591\n",
      "train on new epoch 25 true value for curve no. 13 (example) 0.229577464717\n",
      "train on new epoch 26 true value for curve no. 13 (example) 0.248390346766\n",
      "train on new epoch 27 true value for curve no. 13 (example) 0.242354122656\n",
      "train on new epoch 28 true value for curve no. 13 (example) 0.243561365775\n",
      "train on new epoch 29 true value for curve no. 13 (example) 0.22173038125\n",
      "train on new epoch 30 true value for curve no. 13 (example) 0.215492953147\n",
      "train on new epoch 31 true value for curve no. 13 (example) 0.219617709517\n",
      "train on new epoch 32 true value for curve no. 13 (example) 0.235211265939\n",
      "train on new epoch 33 true value for curve no. 13 (example) 0.230382293463\n",
      "train on new epoch 34 true value for curve no. 13 (example) 0.227565382208\n",
      "train on new epoch 35 true value for curve no. 13 (example) 0.224044261234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on new epoch 36 true value for curve no. 13 (example) 0.331790747387\n",
      "train on new epoch 37 true value for curve no. 13 (example) 0.246981897524\n",
      "train on new epoch 38 true value for curve no. 13 (example) 0.214084506035\n",
      "train on new epoch 39 true value for curve no. 13 (example) 0.214084501777\n",
      "train on new epoch 40 true value for curve no. 13 (example) 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.56285084  0.50601443  0.46792301  0.44506816  0.42983159  0.4212109\n",
      "  0.40797915  0.39695268  0.39314354  0.38301924  0.37880914  0.37540096\n",
      "  0.37359663  0.36257017  0.35805934  0.36086608  0.35294707  0.35244587\n",
      "  0.34532879  0.34653167  0.34192061  0.34101844  0.33690858  0.34161989\n",
      "  0.33580593  0.33309944  0.33340016  0.33199679  0.3255814   0.32668404\n",
      "  0.32407779  0.32457899  0.3223737   0.32117081  0.32056937  0.32317563\n",
      "  0.31776263  0.32016841  0.31345229  0.31134724]\n",
      "step nr. 5 prediction / true value for lc number 13 0.485691 / 0.421210902518\n",
      "step nr. 6 prediction / true value for lc number 13 0.437519 / 0.407979146417\n",
      "step nr. 7 prediction / true value for lc number 13 0.424689 / 0.396952684712\n",
      "step nr. 8 prediction / true value for lc number 13 0.4422 / 0.393143543139\n",
      "step nr. 9 prediction / true value for lc number 13 0.451538 / 0.383019244234\n",
      "step nr. 10 prediction / true value for lc number 13 0.421922 / 0.378809140802\n",
      "step nr. 11 prediction / true value for lc number 13 0.419173 / 0.375400962886\n",
      "step nr. 12 prediction / true value for lc number 13 0.43516 / 0.373596630477\n",
      "step nr. 13 prediction / true value for lc number 13 0.424689 / 0.3625701689\n",
      "step nr. 14 prediction / true value for lc number 13 0.415883 / 0.358059343721\n",
      "step nr. 15 prediction / true value for lc number 13 0.415883 / 0.360866077244\n",
      "step nr. 16 prediction / true value for lc number 13 0.419563 / 0.352947072736\n",
      "step nr. 17 prediction / true value for lc number 13 0.409141 / 0.35244586961\n",
      "step nr. 18 prediction / true value for lc number 13 0.40588 / 0.345328789204\n",
      "step nr. 19 prediction / true value for lc number 13 0.406599 / 0.34653167388\n",
      "step nr. 20 prediction / true value for lc number 13 0.397296 / 0.341920611545\n",
      "step nr. 21 prediction / true value for lc number 13 0.397296 / 0.341018444762\n",
      "step nr. 22 prediction / true value for lc number 13 0.397296 / 0.336908581313\n",
      "step nr. 23 prediction / true value for lc number 13 0.394435 / 0.341619886843\n",
      "step nr. 24 prediction / true value for lc number 13 0.394435 / 0.335805934693\n",
      "step nr. 25 prediction / true value for lc number 13 0.394435 / 0.333099439098\n",
      "step nr. 26 prediction / true value for lc number 13 0.394435 / 0.333400159689\n",
      "step nr. 27 prediction / true value for lc number 13 0.389773 / 0.331996794148\n",
      "step nr. 28 prediction / true value for lc number 13 0.389773 / 0.325581397219\n",
      "step nr. 29 prediction / true value for lc number 13 0.386784 / 0.326684044995\n",
      "step nr. 30 prediction / true value for lc number 13 0.376037 / 0.324077786171\n",
      "step nr. 31 prediction / true value for lc number 13 0.373892 / 0.324578990196\n",
      "step nr. 32 prediction / true value for lc number 13 0.373892 / 0.322373699011\n",
      "step nr. 33 prediction / true value for lc number 13 0.373892 / 0.321170811509\n",
      "step nr. 34 prediction / true value for lc number 13 0.373892 / 0.320569367116\n",
      "step nr. 35 prediction / true value for lc number 13 0.363841 / 0.323175625169\n",
      "step nr. 36 prediction / true value for lc number 13 0.361281 / 0.317762631281\n",
      "step nr. 37 prediction / true value for lc number 13 0.361281 / 0.320168406414\n",
      "step nr. 38 prediction / true value for lc number 13 0.35565 / 0.313452286068\n",
      "step nr. 39 prediction / true value for lc number 13 0.35565 / 0.311347236536\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 5 prediction / true value for lc number 13 0.311133 / 0.276659959129\n",
      "step nr. 6 prediction / true value for lc number 13 0.311415 / 0.275050303766\n",
      "step nr. 7 prediction / true value for lc number 13 0.308342 / 0.288933598569\n",
      "step nr. 8 prediction / true value for lc number 13 0.29057 / 0.275251509888\n",
      "step nr. 9 prediction / true value for lc number 13 0.305116 / 0.311066399728\n",
      "step nr. 10 prediction / true value for lc number 13 0.305116 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.300425 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.289175 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.295496 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.289611 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.289175 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.28329 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.28329 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.281266 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.281266 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.27627 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.27627 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.27627 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.27627 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.27627 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.27627 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.27627 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.27627 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.27627 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.27627 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.27627 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.27627 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.27627 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.27627 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.27627 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.27627 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.27627 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.27627 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.27627 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.27627 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.56285084  0.50601443  0.46792301  0.44506816  0.42983159  0.4212109\n",
      "  0.40797915  0.39695268  0.39314354  0.38301924  0.37880914  0.37540096\n",
      "  0.37359663  0.36257017  0.35805934  0.36086608  0.35294707  0.35244587\n",
      "  0.34532879  0.34653167  0.34192061  0.34101844  0.33690858  0.34161989\n",
      "  0.33580593  0.33309944  0.33340016  0.33199679  0.3255814   0.32668404\n",
      "  0.32407779  0.32457899  0.3223737   0.32117081  0.32056937  0.32317563\n",
      "  0.31776263  0.32016841  0.31345229  0.31134724]\n",
      "step nr. 10 prediction / true value for lc number 13 0.394435 / 0.378809140802\n",
      "step nr. 11 prediction / true value for lc number 13 0.391446 / 0.375400962886\n",
      "step nr. 12 prediction / true value for lc number 13 0.379026 / 0.373596630477\n",
      "step nr. 13 prediction / true value for lc number 13 0.384639 / 0.3625701689\n",
      "step nr. 14 prediction / true value for lc number 13 0.383023 / 0.358059343721\n",
      "step nr. 15 prediction / true value for lc number 13 0.376037 / 0.360866077244\n",
      "step nr. 16 prediction / true value for lc number 13 0.373892 / 0.352947072736\n",
      "step nr. 17 prediction / true value for lc number 13 0.373892 / 0.35244586961\n",
      "step nr. 18 prediction / true value for lc number 13 0.373892 / 0.345328789204\n",
      "step nr. 19 prediction / true value for lc number 13 0.373892 / 0.34653167388\n",
      "step nr. 20 prediction / true value for lc number 13 0.363841 / 0.341920611545\n",
      "step nr. 21 prediction / true value for lc number 13 0.361281 / 0.341018444762\n",
      "step nr. 22 prediction / true value for lc number 13 0.361281 / 0.336908581313\n",
      "step nr. 23 prediction / true value for lc number 13 0.35565 / 0.341619886843\n",
      "step nr. 24 prediction / true value for lc number 13 0.35565 / 0.335805934693\n",
      "step nr. 25 prediction / true value for lc number 13 0.342239 / 0.333099439098\n",
      "step nr. 26 prediction / true value for lc number 13 0.342239 / 0.333400159689\n",
      "step nr. 27 prediction / true value for lc number 13 0.342239 / 0.331996794148\n",
      "step nr. 28 prediction / true value for lc number 13 0.342239 / 0.325581397219\n",
      "step nr. 29 prediction / true value for lc number 13 0.342239 / 0.326684044995\n",
      "step nr. 30 prediction / true value for lc number 13 0.342239 / 0.324077786171\n",
      "step nr. 31 prediction / true value for lc number 13 0.342239 / 0.324578990196\n",
      "step nr. 32 prediction / true value for lc number 13 0.342239 / 0.322373699011\n",
      "step nr. 33 prediction / true value for lc number 13 0.342239 / 0.321170811509\n",
      "step nr. 34 prediction / true value for lc number 13 0.342239 / 0.320569367116\n",
      "step nr. 35 prediction / true value for lc number 13 0.342239 / 0.323175625169\n",
      "step nr. 36 prediction / true value for lc number 13 0.342239 / 0.317762631281\n",
      "step nr. 37 prediction / true value for lc number 13 0.342239 / 0.320168406414\n",
      "step nr. 38 prediction / true value for lc number 13 0.342239 / 0.313452286068\n",
      "step nr. 39 prediction / true value for lc number 13 0.342239 / 0.311347236536\n",
      "\n",
      "eval_xgb starting at step 10\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 10 prediction / true value for lc number 13 0.280891 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.289175 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.277666 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.297836 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.27627 / 0.252716300743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 15 prediction / true value for lc number 13 0.289175 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.27627 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.28329 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.27627 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.281266 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.27627 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.27627 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.27627 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.27627 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.27627 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.27627 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.27627 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.27627 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.27627 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.27627 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.27627 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.27627 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.27627 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.27627 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.27627 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.27627 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.27627 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.27627 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.27627 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.27627 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.56285084  0.50601443  0.46792301  0.44506816  0.42983159  0.4212109\n",
      "  0.40797915  0.39695268  0.39314354  0.38301924  0.37880914  0.37540096\n",
      "  0.37359663  0.36257017  0.35805934  0.36086608  0.35294707  0.35244587\n",
      "  0.34532879  0.34653167  0.34192061  0.34101844  0.33690858  0.34161989\n",
      "  0.33580593  0.33309944  0.33340016  0.33199679  0.3255814   0.32668404\n",
      "  0.32407779  0.32457899  0.3223737   0.32117081  0.32056937  0.32317563\n",
      "  0.31776263  0.32016841  0.31345229  0.31134724]\n",
      "step nr. 20 prediction / true value for lc number 13 0.342239 / 0.341920611545\n",
      "step nr. 21 prediction / true value for lc number 13 0.342239 / 0.341018444762\n",
      "step nr. 22 prediction / true value for lc number 13 0.342239 / 0.336908581313\n",
      "step nr. 23 prediction / true value for lc number 13 0.342239 / 0.341619886843\n",
      "step nr. 24 prediction / true value for lc number 13 0.342239 / 0.335805934693\n",
      "step nr. 25 prediction / true value for lc number 13 0.342239 / 0.333099439098\n",
      "step nr. 26 prediction / true value for lc number 13 0.342239 / 0.333400159689\n",
      "step nr. 27 prediction / true value for lc number 13 0.342239 / 0.331996794148\n",
      "step nr. 28 prediction / true value for lc number 13 0.342239 / 0.325581397219\n",
      "step nr. 29 prediction / true value for lc number 13 0.342239 / 0.326684044995\n",
      "step nr. 30 prediction / true value for lc number 13 0.342239 / 0.324077786171\n",
      "step nr. 31 prediction / true value for lc number 13 0.342239 / 0.324578990196\n",
      "step nr. 32 prediction / true value for lc number 13 0.342239 / 0.322373699011\n",
      "step nr. 33 prediction / true value for lc number 13 0.342239 / 0.321170811509\n",
      "step nr. 34 prediction / true value for lc number 13 0.342239 / 0.320569367116\n",
      "step nr. 35 prediction / true value for lc number 13 0.342239 / 0.323175625169\n",
      "step nr. 36 prediction / true value for lc number 13 0.342239 / 0.317762631281\n",
      "step nr. 37 prediction / true value for lc number 13 0.342239 / 0.320168406414\n",
      "step nr. 38 prediction / true value for lc number 13 0.342239 / 0.313452286068\n",
      "step nr. 39 prediction / true value for lc number 13 0.342239 / 0.311347236536\n",
      "\n",
      "eval_xgb starting at step 20\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 20 prediction / true value for lc number 13 0.228495 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.228228 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.227044 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.227044 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.227044 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.227044 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.227044 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.227044 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.227044 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.227044 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.227044 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.227044 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.227044 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.227044 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.227044 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.227044 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.227044 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.227044 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.227044 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.227044 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.56285084  0.50601443  0.46792301  0.44506816  0.42983159  0.4212109\n",
      "  0.40797915  0.39695268  0.39314354  0.38301924  0.37880914  0.37540096\n",
      "  0.37359663  0.36257017  0.35805934  0.36086608  0.35294707  0.35244587\n",
      "  0.34532879  0.34653167  0.34192061  0.34101844  0.33690858  0.34161989\n",
      "  0.33580593  0.33309944  0.33340016  0.33199679  0.3255814   0.32668404\n",
      "  0.32407779  0.32457899  0.3223737   0.32117081  0.32056937  0.32317563\n",
      "  0.31776263  0.32016841  0.31345229  0.31134724]\n",
      "step nr. 30 prediction / true value for lc number 13 0.324573 / 0.324077786171\n",
      "step nr. 31 prediction / true value for lc number 13 0.324573 / 0.324578990196\n",
      "step nr. 32 prediction / true value for lc number 13 0.324573 / 0.322373699011\n",
      "step nr. 33 prediction / true value for lc number 13 0.324573 / 0.321170811509\n",
      "step nr. 34 prediction / true value for lc number 13 0.324573 / 0.320569367116\n",
      "step nr. 35 prediction / true value for lc number 13 0.324573 / 0.323175625169\n",
      "step nr. 36 prediction / true value for lc number 13 0.324573 / 0.317762631281\n",
      "step nr. 37 prediction / true value for lc number 13 0.324573 / 0.320168406414\n",
      "step nr. 38 prediction / true value for lc number 13 0.324573 / 0.313452286068\n",
      "step nr. 39 prediction / true value for lc number 13 0.324573 / 0.311347236536\n",
      "\n",
      "eval_xgb starting at step 30\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 30 prediction / true value for lc number 13 0.211502 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.211502 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.211502 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.211502 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.211502 / 0.224044261234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step nr. 35 prediction / true value for lc number 13 0.211502 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.211502 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.211502 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.211502 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.211502 / 0.205030181578\n",
      "validate on 30 steps, mse on train / validation data: 0.00048 / 0.00101\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04854  0.01058  0.00153  0.00081] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04451  0.0149   0.00263  0.00105]\n",
      " [ 0.06447  0.01171  0.00082  0.00036]\n",
      " [ 0.03663  0.00513  0.00113  0.00101]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04393  0.01114  0.00172  0.00049] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.0508   0.01723  0.00177  0.00049]\n",
      " [ 0.04719  0.01064  0.00247  0.0005 ]\n",
      " [ 0.03379  0.00554  0.00093  0.00048]]\n",
      "results validation data \n",
      " [ 0.04854  0.01058  0.00153  0.00081]\n",
      "results training data\n",
      " [ 0.04393  0.01114  0.00172  0.00049]\n"
     ]
    }
   ],
   "source": [
    "# task 3.4 \n",
    "cfg = {'maxdepth': 10, 'lr': 0.08119864140758115, 'gamma': 0.007833441242813044, 'cols_bt': 0.9376450587145334, \n",
    "       'n_estimators': 1000, 'subsample': 0.7946631901813815}\n",
    "res = m.eval_cv('xgb_next', [configs, lcs], Y, steps=(0,[5,10,20,30]), cfg=cfg)\n",
    "print(\"results validation data \\n\", res['val_means'])  \n",
    "print(\"results training data\\n\", res['trn_means'])\n",
    "t.pickle_to_file(res, 'res_xgb_next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 5 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03983, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.04641, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03983 to 0.02769, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02769 to 0.02545, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02545 to 0.01185, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01185 to 0.00602, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00602 to 0.00379, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00379 to 0.00338, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00352, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00338 to 0.00257, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00322, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00257 to 0.00250, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00290, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00250 to 0.00243, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00265, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00243 to 0.00235, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00244, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00235 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00231, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00229 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00229 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00227 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00222 to 0.00213, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00213 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00201 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00187 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00172 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00156 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00143 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00133 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00126 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00121 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00116 to 0.00112, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00112 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00106 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00101 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00098 to 0.00094, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00094 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00090 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00088 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00197, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00081 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00077 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00074 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00071 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00067 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00065 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00061 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00058, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00055 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00053 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00050 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.00047 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00054, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00293: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00054, did not improve\n",
      "Epoch 00306: early stopping\n",
      "Using epoch 00231 with val_loss: 0.00037\n",
      "validate on 5 steps, mse on train / validation data: 0.03678 / 0.06393\n",
      "validate on 10 steps, mse on train / validation data: 0.03618 / 0.06301\n",
      "validate on 20 steps, mse on train / validation data: 0.03513 / 0.06105\n",
      "validate on 30 steps, mse on train / validation data: 0.05573 / 0.09788\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02589, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.03315, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02589 to 0.02352, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02352 to 0.00620, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00620 to 0.00426, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00472, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00426 to 0.00334, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00334 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00201 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00142 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00120 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00108 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00097 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00089 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00078 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00075 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00072 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00070 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00063 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00061 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00058 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00058 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00056 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00054 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00056, did not improve\n",
      "Epoch 00104: early stopping\n",
      "Using epoch 00034 with val_loss: 0.00054\n",
      "validate on 5 steps, mse on train / validation data: 0.04268 / 0.03428\n",
      "validate on 10 steps, mse on train / validation data: 0.04122 / 0.03310\n",
      "validate on 20 steps, mse on train / validation data: 0.02830 / 0.02259\n",
      "validate on 30 steps, mse on train / validation data: 0.07370 / 0.05921\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train on nextstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05688, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.06073, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05688 to 0.02991, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02991 to 0.01288, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01288 to 0.00606, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00606 to 0.00370, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00370 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00220 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00158 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00134 to 0.00117, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss improved from 0.00117 to 0.00109, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00109 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00107 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00099 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00096 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00089 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00085 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00079 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00073 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00063 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00060 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00055 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00053 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00052 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00050 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00049 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00049 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00048 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00044, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00130: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00047, did not improve\n",
      "Epoch 00200: early stopping\n",
      "Using epoch 00125 with val_loss: 0.00042\n",
      "validate on 5 steps, mse on train / validation data: 0.03702 / 0.02668\n",
      "validate on 10 steps, mse on train / validation data: 0.03432 / 0.02501\n",
      "validate on 20 steps, mse on train / validation data: 0.04954 / 0.03747\n",
      "validate on 30 steps, mse on train / validation data: 0.08313 / 0.05717\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04163  0.04037  0.04037  0.07142] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.06393  0.06301  0.06105  0.09788]\n",
      " [ 0.03428  0.0331   0.02259  0.05921]\n",
      " [ 0.02668  0.02501  0.03747  0.05717]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.03882  0.03724  0.03766  0.07086] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.03678  0.03618  0.03513  0.05573]\n",
      " [ 0.04268  0.04122  0.0283   0.0737 ]\n",
      " [ 0.03702  0.03432  0.04954  0.08313]]\n",
      "mse over all validation data 0.0417128187686\n",
      "cross validate 1000 epochs, train on 10 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02700, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.02911, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02700 to 0.01662, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01662 to 0.01296, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01296 to 0.00999, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00999 to 0.00681, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00681 to 0.00260, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00260 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00229 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00179 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00142 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00116 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00107 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00107 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00105 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00104 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00086 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00072 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00066 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00062 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00059 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00056 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00052 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00050 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00049 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00074, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00055: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00068, did not improve\n",
      "Epoch 00112: early stopping\n",
      "Using epoch 00039 with val_loss: 0.00047\n",
      "validate on 5 steps, mse on train / validation data: 0.04494 / 0.07442\n",
      "validate on 10 steps, mse on train / validation data: 0.04512 / 0.07480\n",
      "validate on 20 steps, mse on train / validation data: 0.04242 / 0.07009\n",
      "validate on 30 steps, mse on train / validation data: 0.01981 / 0.03091\n",
      "train fold 2 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08473, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08473 to 0.05859, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05859 to 0.03176, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03176 to 0.01476, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01476 to 0.01150, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01150 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00222 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00138 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00117 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00057 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00037 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00034 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00043, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00089: val_loss is 0.00043, did not improve\n",
      "Epoch 00089: early stopping\n",
      "Using epoch 00014 with val_loss: 0.00031\n",
      "validate on 5 steps, mse on train / validation data: 0.04378 / 0.03667\n",
      "validate on 10 steps, mse on train / validation data: 0.57215 / 0.46554\n",
      "validate on 20 steps, mse on train / validation data: 0.21907 / 0.19990\n",
      "validate on 30 steps, mse on train / validation data: 0.01453 / 0.01357\n",
      "train fold 3 on 10 steps, validation on 10 steps\n",
      "train on nextstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20228, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20228 to 0.05469, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05469 to 0.01029, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.02629, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01029 to 0.00850, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00850 to 0.00353, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00353 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00158 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00079 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00075 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00037 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00036 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00035 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00034 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00034 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00033 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00030 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00029 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00028 to 0.00028, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00110: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00028 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00030, did not improve\n",
      "Epoch 00185: early stopping\n",
      "Using epoch 00125 with val_loss: 0.00027\n",
      "validate on 5 steps, mse on train / validation data: 0.05310 / 0.03295\n",
      "validate on 10 steps, mse on train / validation data: 0.05314 / 0.03264\n",
      "validate on 20 steps, mse on train / validation data: 0.05576 / 0.03396\n",
      "validate on 30 steps, mse on train / validation data: 0.03334 / 0.02003\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04801  0.19099  0.10132  0.0215 ] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.07442  0.0748   0.07009  0.03091]\n",
      " [ 0.03667  0.46554  0.1999   0.01357]\n",
      " [ 0.03295  0.03264  0.03396  0.02003]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04727  0.22347  0.10575  0.02256] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.04494  0.04512  0.04242  0.01981]\n",
      " [ 0.04378  0.57215  0.21907  0.01453]\n",
      " [ 0.0531   0.05314  0.05576  0.03334]]\n",
      "mse over all validation data 0.048112381203\n",
      "cross validate 1000 epochs, train on 20 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04050, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04050 to 0.01561, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01561 to 0.00609, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00609 to 0.00281, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.00499, did not improve\n",
      "\n",
      "Epoch 00006: val_loss is 0.00290, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00281 to 0.00109, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00109 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00097 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00089 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00072 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00095, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00064 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00060 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00057 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00054 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00052 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00051 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00047 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00042 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00040, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00208: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00039, did not improve\n",
      "Epoch 00212: early stopping\n",
      "Using epoch 00137 with val_loss: 0.00038\n",
      "validate on 5 steps, mse on train / validation data: 0.02881 / 0.03179\n",
      "validate on 10 steps, mse on train / validation data: 0.01279 / 0.01417\n",
      "validate on 20 steps, mse on train / validation data: 0.00608 / 0.00506\n",
      "validate on 30 steps, mse on train / validation data: 0.00197 / 0.00161\n",
      "train fold 2 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07372, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07372 to 0.03704, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03704 to 0.01551, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01551 to 0.00685, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00685 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00180 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00150 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00216, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00098 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00064 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00041 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00034 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00032, did not improve\n",
      "Epoch 00096: early stopping\n",
      "Using epoch 00044 with val_loss: 0.00030\n",
      "validate on 5 steps, mse on train / validation data: 0.00885 / 0.00764\n",
      "validate on 10 steps, mse on train / validation data: 0.00240 / 0.00274\n",
      "validate on 20 steps, mse on train / validation data: 0.00297 / 0.00369\n",
      "validate on 30 steps, mse on train / validation data: 0.00143 / 0.00151\n",
      "train fold 3 on 20 steps, validation on 20 steps\n",
      "train on nextstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06087, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06087 to 0.03003, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03003 to 0.01326, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01326 to 0.00638, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00638 to 0.00320, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00320 to 0.00128, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00128 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00069 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00058 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00056 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00050 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00050 to 0.00050, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00048 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00048 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00046 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00046 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00045 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00044 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00044 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00043 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00042 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00041 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00038 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00037 to 0.00037, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00138: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00037 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00037, did not improve\n",
      "Epoch 00213: early stopping\n",
      "Using epoch 00149 with val_loss: 0.00037\n",
      "validate on 5 steps, mse on train / validation data: 0.11840 / 0.10535\n",
      "validate on 10 steps, mse on train / validation data: 0.04972 / 0.03776\n",
      "validate on 20 steps, mse on train / validation data: 0.00290 / 0.00274\n",
      "validate on 30 steps, mse on train / validation data: 0.00074 / 0.00089\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.04826  0.01823  0.00383  0.00134] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03179  0.01417  0.00506  0.00161]\n",
      " [ 0.00764  0.00274  0.00369  0.00151]\n",
      " [ 0.10535  0.03776  0.00274  0.00089]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.05202  0.02164  0.00398  0.00138] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02881  0.01279  0.00608  0.00197]\n",
      " [ 0.00885  0.0024   0.00297  0.00143]\n",
      " [ 0.1184   0.04972  0.0029   0.00074]]\n",
      "mse over all validation data 0.048198652182\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train on nextstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02917, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.03013, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02917 to 0.00950, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00950 to 0.00452, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00452 to 0.00286, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00286 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00197, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00187 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00152 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00129 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00199, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00245, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00192, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00123 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00089 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00251, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00197, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00082 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00069 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00057 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00190, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00051: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00202, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00291, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00285, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00053 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00291, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00282, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00050 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00043 to 0.00043, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00043 to 0.00041, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00041 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00040 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00041, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00209: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00059, did not improve\n",
      "Epoch 00267: early stopping\n",
      "Using epoch 00192 with val_loss: 0.00035\n",
      "validate on 5 steps, mse on train / validation data: 1.67110 / 1.68997\n",
      "validate on 10 steps, mse on train / validation data: 1.39958 / 1.49843\n",
      "validate on 20 steps, mse on train / validation data: 0.14926 / 0.04802\n",
      "validate on 30 steps, mse on train / validation data: 0.00533 / 0.00379\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train on nextstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15735, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15735 to 0.06568, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06568 to 0.01930, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01930 to 0.01436, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01436 to 0.00721, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00721 to 0.00500, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00500 to 0.00344, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00344 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00201, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00141 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00107 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00083 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00057 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00051 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00051 to 0.00036, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00036 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00035 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00030 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00028 to 0.00024, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00042, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00085: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00024 to 0.00018, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00028, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00027, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00036, did not improve\n",
      "Epoch 00163: early stopping\n",
      "Using epoch 00088 with val_loss: 0.00018\n",
      "validate on 5 steps, mse on train / validation data: 0.30328 / 0.23316\n",
      "validate on 10 steps, mse on train / validation data: 0.18824 / 0.21108\n",
      "validate on 20 steps, mse on train / validation data: 0.02106 / 0.02609\n",
      "validate on 30 steps, mse on train / validation data: 0.00290 / 0.00335\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "train on nextstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.17776, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.17776 to 0.07077, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.07077 to 0.01854, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01854 to 0.00415, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.00440, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00415 to 0.00139, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00139 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00103 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00093 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00045 to 0.00034, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00040, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00069: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00034 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00028 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00031, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00030, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00062, did not improve\n",
      "Epoch 00178: early stopping\n",
      "Using epoch 00103 with val_loss: 0.00026\n",
      "validate on 5 steps, mse on train / validation data: 0.78670 / 0.75063\n",
      "validate on 10 steps, mse on train / validation data: 0.96466 / 0.55230\n",
      "validate on 20 steps, mse on train / validation data: 0.06822 / 0.03191\n",
      "validate on 30 steps, mse on train / validation data: 0.00416 / 0.00345\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.89125  0.75394  0.03534  0.00353] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 1.68997  1.49843  0.04802  0.00379]\n",
      " [ 0.23316  0.21108  0.02609  0.00335]\n",
      " [ 0.75063  0.5523   0.03191  0.00345]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.92036  0.85082  0.07951  0.00413] ***\n",
      "Results training data of all Folds: \n",
      "[[ 1.6711   1.39958  0.14926  0.00533]\n",
      " [ 0.30328  0.18824  0.02106  0.0029 ]\n",
      " [ 0.7867   0.96466  0.06822  0.00416]]\n",
      "mse over all validation data 0.894266560734\n",
      "cross validate 1000 epochs, train on 5 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train on finalstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06183, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06183 to 0.03056, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03056 to 0.02724, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02724 to 0.02007, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02007 to 0.01511, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01511 to 0.01443, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01443 to 0.01076, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01076 to 0.01047, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01047 to 0.01022, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01022 to 0.00984, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00998, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00984 to 0.00922, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00948, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00922 to 0.00906, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00925, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00906 to 0.00887, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.00900, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00891, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00913, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00930, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00960, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_loss is 0.00971, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00965, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00924, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00887 to 0.00878, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00878 to 0.00835, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00835 to 0.00816, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00816 to 0.00816, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00816 to 0.00789, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00789 to 0.00720, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00720 to 0.00683, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00683 to 0.00681, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00681 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00668 to 0.00593, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00593 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00551 to 0.00550, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00550 to 0.00516, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00516 to 0.00470, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00470 to 0.00457, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.00470, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00486, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00478, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00457 to 0.00445, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00445 to 0.00412, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00412 to 0.00400, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00406, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00414, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00407, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00400 to 0.00385, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00385 to 0.00365, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00365 to 0.00358, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00361, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00361, did not improve\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00358 to 0.00351, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00351 to 0.00336, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00336 to 0.00325, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00325 to 0.00323, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00323 to 0.00321, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00321 to 0.00315, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00315 to 0.00303, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00303 to 0.00291, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00291 to 0.00282, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00282 to 0.00277, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00277 to 0.00274, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00274 to 0.00268, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00268 to 0.00259, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00259 to 0.00251, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00251 to 0.00245, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00245 to 0.00241, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00241 to 0.00236, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00236 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00229 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00222 to 0.00219, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00219 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00212 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00204 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00200 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00192 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00186 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00179 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00173 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00165 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00159 to 0.00155, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00155 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00151 to 0.00148, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00148 to 0.00147, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00147 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00143 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00140 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00140 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00138 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00138 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00137 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00132 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00127 to 0.00125, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00249, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00404, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00441, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00433, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00334, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00309, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00210, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00207, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00199, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00192, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00155: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00185, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00180, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00179, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00181, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00146, did not improve\n",
      "Epoch 00208: early stopping\n",
      "Using epoch 00133 with val_loss: 0.00125\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00129 / 0.00125\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.01069 / 0.01907\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.03512 / 0.06764\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.04695 / 0.09167\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train on finalstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12103, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12103 to 0.03794, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03794 to 0.01839, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01839 to 0.01414, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.01731, did not improve\n",
      "\n",
      "Epoch 00006: val_loss is 0.01870, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01414 to 0.00935, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00935 to 0.00627, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00627 to 0.00534, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00534 to 0.00490, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00490 to 0.00466, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00466 to 0.00461, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00501, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00461 to 0.00351, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00351 to 0.00264, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00264 to 0.00246, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.00328, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00246 to 0.00245, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00245 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00196 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00214, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00340, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00510, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00285, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00182 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00160 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00239, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00345, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00454, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00340, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00144 to 0.00125, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00196, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00357, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00125 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00288, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00201, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00238, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00209, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00195, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00138, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00130, did not improve\n",
      "Epoch 00123: early stopping\n",
      "Using epoch 00048 with val_loss: 0.00117\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00164 / 0.00117\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00694 / 0.00559\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00760 / 0.00632\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00847 / 0.00694\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train on finalstep considering 5 epochs, eval during training with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.14638, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.14638 to 0.05223, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05223 to 0.02116, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02116 to 0.01973, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01973 to 0.00650, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.00749, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00650 to 0.00616, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00616 to 0.00538, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00538 to 0.00507, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00512, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00507 to 0.00468, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00468 to 0.00385, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00385 to 0.00381, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.00430, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00479, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00470, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00381 to 0.00374, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00374 to 0.00308, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.00319, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00368, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00413, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00376, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00308 to 0.00297, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00297 to 0.00262, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss is 0.00283, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00330, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00369, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00293, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00262 to 0.00251, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00251 to 0.00240, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.00265, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00314, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00305, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00248, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00240 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00231, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00296, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00227 to 0.00225, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00225 to 0.00218, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00229, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00262, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00253, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00223, did not improve\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00218 to 0.00213, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss is 0.00215, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00213 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00212 to 0.00209, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss is 0.00217, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00231, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00213, did not improve\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00209 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.00210, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00219, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00220, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00213, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00208, did not improve\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00207 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00214, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00207, did not improve\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00207 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss is 0.00208, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00209, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00208, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00206 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00206 to 0.00205, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00205 to 0.00205, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00205 to 0.00204, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00092: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00204 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00204 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00203 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00203 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00203 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00203 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00202 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00202 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00202 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00202 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00201 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00201 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00201 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00201 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00200 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00200 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00200 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00200 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00199 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00199 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00199 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00199 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00198 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00197 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00197 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00197 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00197 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00196 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00196 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00196 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00196 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00196 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00195 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00195 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00195 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00195 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00195 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00194 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00193 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00192 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00192 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00192 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00192 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00192 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00191 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00190 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00190 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00190 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00190 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00190 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00189 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00189 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00189 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00189 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00189 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00188 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00188 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00188 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00188 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00188 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00187 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00187 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00187 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00187 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00187 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00186 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00185 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00184 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00183 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00183 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00183 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00183 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00183 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00182 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00182 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00182 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00182 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00182 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00181 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00181 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00181 to 0.00181, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00204: val_loss improved from 0.00181 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00181 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00180 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.00180 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00180 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00180 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00180 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00179 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00179 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00179 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00179 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00179 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00178 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00177 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00177 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00177 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00177 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.00177 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.00176 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00175 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00175 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.00175 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00235: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00175 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00175 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00174 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00174 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00173 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00173 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00172 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00172 to 0.00171, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00171 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00169 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00164 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00162 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00156 to 0.00155, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00155 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00281: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00179, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.00152 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00331: val_loss is 0.00186, did not improve\n",
      "\n",
      "Epoch 00332: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00337: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00338: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00150, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00344: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.00144 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00353: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.00143 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00373: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.00142 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00377: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00186, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00216, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00193, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00433: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00447: val_loss is 0.00169, did not improve\n",
      "Epoch 00447: early stopping\n",
      "Using epoch 00376 with val_loss: 0.00141\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00063 / 0.00141\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00088 / 0.00111\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00310 / 0.00315\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00609 / 0.00691\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00128  0.00859  0.02571  0.03517] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00125  0.01907  0.06764  0.09167]\n",
      " [ 0.00117  0.00559  0.00632  0.00694]\n",
      " [ 0.00141  0.00111  0.00315  0.00691]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00118  0.00617  0.01528  0.0205 ] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00129  0.01069  0.03512  0.04695]\n",
      " [ 0.00164  0.00694  0.0076   0.00847]\n",
      " [ 0.00063  0.00088  0.0031   0.00609]]\n",
      "mse over all validation data 0.00128039351097\n",
      "cross validate 1000 epochs, train on 10 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 10 steps, validation on 10 steps\n",
      "train on finalstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02434, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02434 to 0.01472, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01472 to 0.01133, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01133 to 0.00699, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00699 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00556 to 0.00537, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00537 to 0.00460, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00460 to 0.00409, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00534, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00533, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00503, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00505, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00487, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00484, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00490, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00485, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00484, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00023: val_loss is 0.00472, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00466, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00454, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00444, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00436, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00428, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00421, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00413, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00409 to 0.00404, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00404 to 0.00394, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00394 to 0.00383, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00383 to 0.00372, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00372 to 0.00360, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00360 to 0.00348, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00348 to 0.00336, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00336 to 0.00323, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00323 to 0.00311, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00311 to 0.00299, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00299 to 0.00287, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00287 to 0.00274, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00274 to 0.00263, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00263 to 0.00251, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00251 to 0.00239, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00239 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00227 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00216 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00204 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00193 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00181 to 0.00170, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00170 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00159 to 0.00149, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00149 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00138 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00129 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00121 to 0.00115, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00115 to 0.00110, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00110 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00107 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00213, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00261, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00297, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00306, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00288, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00179, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00184, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00197, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00202, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00106 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00106 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00104 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00103 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00103 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00098 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00089 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00082 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00076 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00072 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00066 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00082, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00162: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00151, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00090, did not improve\n",
      "Epoch 00230: early stopping\n",
      "Using epoch 00155 with val_loss: 0.00066\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.01259 / 0.01481\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00069 / 0.00066\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00162 / 0.00202\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00260 / 0.00297\n",
      "train fold 2 on 10 steps, validation on 10 steps\n",
      "train on finalstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02652, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02652 to 0.01662, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01662 to 0.00415, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.01097, did not improve\n",
      "\n",
      "Epoch 00005: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00006: val_loss is 0.01365, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.01284, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00415 to 0.00411, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00411 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00180 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00178 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00143 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00120 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00117 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00181, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00241, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00303, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00258, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00102 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00096 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00082 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00079 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00077 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00073 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00067 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00063 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00060 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00107, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00057 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00056 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00054 to 0.00051, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00051 to 0.00050, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00050 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00049 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00048 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00059, did not improve\n",
      "Epoch 00201: early stopping\n",
      "Using epoch 00126 with val_loss: 0.00046\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00731 / 0.00548\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00070 / 0.00046\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00175 / 0.00193\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00316 / 0.00313\n",
      "train fold 3 on 10 steps, validation on 10 steps\n",
      "train on finalstep considering 10 epochs, eval during training with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10276, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10276 to 0.03699, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03699 to 0.02008, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss improved from 0.02008 to 0.00558, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00558 to 0.00425, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00425 to 0.00285, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00285 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00169 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00207, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00293, did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00159 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00133 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00133 to 0.00119, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00159, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00119 to 0.00115, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00115 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00106 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00096 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00095 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00095 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00093 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00093 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00092 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00091 to 0.00091, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00135: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00091 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00090 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00089 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00220: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00087 to 0.00087, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00247: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.00087 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00288: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00289: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00293: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00296: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00304: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00309: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00311: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00313: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00315: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00319: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00323: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00326: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00328: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00333: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00338: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00340: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00343: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00345: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00347: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00349: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00370: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00372: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.00085 to 0.00085, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00374: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00379: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00380: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00382: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00389: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00391: val_loss improved from 0.00085 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00392: val_loss improved from 0.00085 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00393: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00396: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00397: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00398: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00399: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00400: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00401: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00402: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00404: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00405: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00406: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00410: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.00083 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00428: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.00083 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00431: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00433: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00434: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00438: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00441: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00444: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00445: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00446: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.00080 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00448: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00449: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00452: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00458: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00460: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00463: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00464: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00465: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00466: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00479: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00480: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00486: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00487: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00488: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00489: val_loss improved from 0.00076 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00490: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00491: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00498: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00501: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00504: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00505: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00514: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00515: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.00076, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00519: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00520: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00521: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00530: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00531: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00547: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00552: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00553: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00554: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00555: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00556: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00557: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00558: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00568: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00569: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00570: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00571: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00572: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00573: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00574: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00575: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00576: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00577: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00578: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00579: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00581: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00582: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00588: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00589: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00590: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00591: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00592: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00593: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00594: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00595: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00596: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00597: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00598: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00599: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00600: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00601: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00602: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00603: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00604: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00605: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00606: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00607: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00608: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00609: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00610: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00611: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00612: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00613: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00614: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00615: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00616: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00617: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00618: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00619: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00620: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00621: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00622: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00623: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00624: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00625: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00626: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00627: val_loss is 0.00080, did not improve\n",
      "Epoch 00627: early stopping\n",
      "Using epoch 00554 with val_loss: 0.00074\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.01470 / 0.01651\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00036 / 0.00074\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00100 / 0.00115\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00257 / 0.00257\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.01227  0.00062  0.0017   0.00289] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01481  0.00066  0.00202  0.00297]\n",
      " [ 0.00548  0.00046  0.00193  0.00313]\n",
      " [ 0.01651  0.00074  0.00115  0.00257]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.01154  0.00058  0.00145  0.00278] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01259  0.00069  0.00162  0.0026 ]\n",
      " [ 0.00731  0.0007   0.00175  0.00316]\n",
      " [ 0.0147   0.00036  0.001    0.00257]]\n",
      "mse over all validation data 0.0122754472262\n",
      "cross validate 1000 epochs, train on 20 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 20 steps, validation on 20 steps\n",
      "train on finalstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07938, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07938 to 0.01862, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01862 to 0.01029, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01029 to 0.00370, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00370 to 0.00288, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00288 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00212 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00153, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00164, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00100 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00100 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00098 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00097 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00096 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00096 to 0.00094, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00094 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00091 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00086 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00082 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00077 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00073 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00070 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00067 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00063 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00057 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00052 to 0.00049, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00049 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00047 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00047 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00046 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00042 to 0.00042, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00065, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00168: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00056, did not improve\n",
      "Epoch 00216: early stopping\n",
      "Using epoch 00143 with val_loss: 0.00042\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.02813 / 0.02763\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.01690 / 0.02214\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00041 / 0.00042\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00062 / 0.00063\n",
      "train fold 2 on 20 steps, validation on 20 steps\n",
      "train on finalstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00965, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.04867, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 0.02499, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 0.01200, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00965 to 0.00741, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00741 to 0.00313, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00313 to 0.00253, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00253 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00152 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00069 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00039 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00035 to 0.00035, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00035 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00035, did not improve\n",
      "Epoch 00089: early stopping\n",
      "Using epoch 00014 with val_loss: 0.00031\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.02318 / 0.02422\n",
      "evaluate lstm with consideration of configs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00739 / 0.00588\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00054 / 0.00031\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00058 / 0.00045\n",
      "train fold 3 on 20 steps, validation on 20 steps\n",
      "train on finalstep considering 20 epochs, eval during training with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03717, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03717 to 0.01672, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01672 to 0.01205, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01205 to 0.00682, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00682 to 0.00299, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00299 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.00226, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 0.00202, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00202, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00164 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00144 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00117 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00097 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00088 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00084 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00081 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00078 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00072 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00068 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00067 to 0.00067, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00067 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00066 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00066 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00065 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00065 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00064 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00064 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00064 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00063 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00063 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00061 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00061 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00060 to 0.00060, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00060 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00059 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00059 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00058 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00058 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00057 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00057 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00057 to 0.00057, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00057 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00056 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00055 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00056, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00059, did not improve\n",
      "Epoch 00158: early stopping\n",
      "Using epoch 00092 with val_loss: 0.00055\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.03258 / 0.03222\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00885 / 0.00923\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00040 / 0.00055\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00091 / 0.00116\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.02802  0.01242  0.00043  0.00075] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02763  0.02214  0.00042  0.00063]\n",
      " [ 0.02422  0.00588  0.00031  0.00045]\n",
      " [ 0.03222  0.00923  0.00055  0.00116]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.02796  0.01105  0.00045  0.0007 ] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02813  0.0169   0.00041  0.00062]\n",
      " [ 0.02318  0.00739  0.00054  0.00058]\n",
      " [ 0.03258  0.00885  0.0004   0.00091]]\n",
      "mse over all validation data 0.0280209583798\n",
      "cross validate 1000 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 20, 'lr': 0.002}\n",
      "evaluating with early stopping\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03373, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03373 to 0.01372, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01372 to 0.01258, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.01419, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01258 to 0.00952, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00952 to 0.00869, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00869 to 0.00449, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00449 to 0.00369, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00493, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.00863, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.00449, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00400, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00628, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00430, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00535, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00815, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00536, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00402, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00373, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00369 to 0.00338, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00338 to 0.00231, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss is 0.00307, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00278, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00347, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00302, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00233, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00370, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00248, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00418, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00350, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00903, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00424, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00231 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00195 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00177, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00269, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00354, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00305, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00265, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00173 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00196, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00272, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00200, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00462, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00272, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00319, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00397, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00286, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00253, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00321, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00301, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00364, did not improve\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00160 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss is 0.00218, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00250, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00249, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00417, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00179, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00152 to 0.00128, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00260, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00282, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00203, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00128 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00222, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00249, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00137, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00082: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00300, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00221, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00263, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00316, did not improve\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00127 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss is 0.00601, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00227, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00210, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00100 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00264, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00415, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00196, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00235, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00265, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00205, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00248, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00200, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00095 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00091 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00213, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00215, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00245, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00250, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00087 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00056 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00203, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00203, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00327, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00182, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00144, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00240: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00211, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00175, did not improve\n",
      "Epoch 00251: early stopping\n",
      "Using epoch 00176 with val_loss: 0.00052\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00171 / 0.00181\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00075 / 0.00055\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00056 / 0.00048\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00107 / 0.00081\n",
      "train fold 2 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09866, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09866 to 0.03749, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03749 to 0.03127, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03127 to 0.01241, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01241 to 0.00890, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00890 to 0.00443, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00443 to 0.00381, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00381 to 0.00283, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.00286, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00283 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00278, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00175 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00377, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00586, did not improve\n",
      "\n",
      "Epoch 00016: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00198, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00332, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00180, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00185, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00165, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00214, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00180, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00149, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00160, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00158, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00157, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00080 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00077 to 0.00064, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00187, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00195, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00064 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00055 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00054, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00126: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00052 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00045 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00044 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00039 to 0.00037, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00050, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00285: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00061, did not improve\n",
      "Epoch 00308: early stopping\n",
      "Using epoch 00233 with val_loss: 0.00037\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00173 / 0.00087\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00070 / 0.00055\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00042 / 0.00033\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00068 / 0.00046\n",
      "train fold 3 on 0 steps, validation on 0 steps\n",
      "train on finalstep with random nr. of epochs, eval during training with 0 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.07467, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.07467 to 0.03938, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03938 to 0.03119, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03119 to 0.01042, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01042 to 0.00477, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00477 to 0.00365, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00365 to 0.00259, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00259 to 0.00238, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00238 to 0.00208, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00404, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00208 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00250, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00243, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00350, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00205, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00271, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00248, did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00186 to 0.00163, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00217, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00413, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00230, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00163 to 0.00110, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.00224, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00176, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00199, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00190, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00223, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00206, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00225, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00168, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00259, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00236, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00110 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00163, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00191, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00169, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00167, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00175, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00105 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00142, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00188, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00092 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00154, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00178, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00156, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00085, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00107, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00115: val_loss is 0.00150, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00152, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00082 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00174, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00079, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00098, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00161, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00102, did not improve\n",
      "Epoch 00198: early stopping\n",
      "Using epoch 00123 with val_loss: 0.00075\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 5 steps, mse on train / validation data: 0.00165 / 0.00278\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 10 steps, mse on train / validation data: 0.00053 / 0.00098\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 20 steps, mse on train / validation data: 0.00042 / 0.00059\n",
      "evaluate lstm with consideration of configs\n",
      "evaluate lstm with consideration of configs\n",
      "validate on 30 steps, mse on train / validation data: 0.00067 / 0.00099\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.00182  0.0007   0.00047  0.00076] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00181  0.00055  0.00048  0.00081]\n",
      " [ 0.00087  0.00055  0.00033  0.00046]\n",
      " [ 0.00278  0.00098  0.00059  0.00099]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.0017   0.00066  0.00047  0.00081] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00171  0.00075  0.00056  0.00107]\n",
      " [ 0.00173  0.0007   0.00042  0.00068]\n",
      " [ 0.00165  0.00053  0.00042  0.00067]]\n",
      "mse over all validation data 0.00182137785973\n",
      "cross validate 0 epochs, train on 0 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'gamma': 0.007833441242813044, 'lr': 0.08119864140758115, 'subsample': 0.7946631901813815, 'cols_bt': 0.9376450587145334, 'maxdepth': 10, 'n_estimators': 1000}\n",
      "train fold 1 on 0 steps, validation on 0 steps\n",
      "train on new epoch 5 true value for curve no. 13 (example) 0.584156378552\n",
      "train on new epoch 6 true value for curve no. 13 (example) 0.578395060919\n",
      "train on new epoch 7 true value for curve no. 13 (example) 0.527057613488\n",
      "train on new epoch 8 true value for curve no. 13 (example) 0.500720170913\n",
      "train on new epoch 9 true value for curve no. 13 (example) 0.494855966833\n",
      "train on new epoch 10 true value for curve no. 13 (example) 0.454835391707\n",
      "train on new epoch 11 true value for curve no. 13 (example) 0.458230453509\n",
      "train on new epoch 12 true value for curve no. 13 (example) 0.465432094203\n",
      "train on new epoch 13 true value for curve no. 13 (example) 0.472633742624\n",
      "train on new epoch 14 true value for curve no. 13 (example) 0.44094650061\n",
      "train on new epoch 15 true value for curve no. 13 (example) 0.398662551686\n",
      "train on new epoch 16 true value for curve no. 13 (example) 0.417901235598\n",
      "train on new epoch 17 true value for curve no. 13 (example) 0.432510285466\n",
      "train on new epoch 18 true value for curve no. 13 (example) 0.37952675422\n",
      "train on new epoch 19 true value for curve no. 13 (example) 0.399382723702\n",
      "train on new epoch 20 true value for curve no. 13 (example) 0.371913578775\n",
      "train on new epoch 21 true value for curve no. 13 (example) 0.374074074957\n",
      "train on new epoch 22 true value for curve no. 13 (example) 0.378189303257\n",
      "train on new epoch 23 true value for curve no. 13 (example) 0.351543205756\n",
      "train on new epoch 24 true value for curve no. 13 (example) 0.330349789725\n",
      "train on new epoch 25 true value for curve no. 13 (example) 0.318209884343\n",
      "train on new epoch 26 true value for curve no. 13 (example) 0.36121398652\n",
      "train on new epoch 27 true value for curve no. 13 (example) 0.320370373902\n",
      "train on new epoch 28 true value for curve no. 13 (example) 0.34917695434\n",
      "train on new epoch 29 true value for curve no. 13 (example) 0.318004115864\n",
      "train on new epoch 30 true value for curve no. 13 (example) 0.313580245883\n",
      "train on new epoch 31 true value for curve no. 13 (example) 0.321296292323\n",
      "train on new epoch 32 true value for curve no. 13 (example) 0.32448559558\n",
      "train on new epoch 33 true value for curve no. 13 (example) 0.34002057049\n",
      "train on new epoch 34 true value for curve no. 13 (example) 0.311934159862\n",
      "train on new epoch 35 true value for curve no. 13 (example) 0.339094645447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on new epoch 36 true value for curve no. 13 (example) 0.330349800763\n",
      "train on new epoch 37 true value for curve no. 13 (example) 0.306172834502\n",
      "train on new epoch 38 true value for curve no. 13 (example) 0.32294238276\n",
      "train on new epoch 39 true value for curve no. 13 (example) 0.302572014155\n",
      "train on new epoch 40 true value for curve no. 13 (example) 0.330041154667\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.4387324   0.34678068  0.33108651  0.33480885  0.29798793  0.27665996\n",
      "  0.2750503   0.2889336   0.27525151  0.3110664   0.25764588  0.26348088\n",
      "  0.28239437  0.24537224  0.2527163   0.24617706  0.23571428  0.26448692\n",
      "  0.25331992  0.2304829   0.22706237  0.23279678  0.22736418  0.22947686\n",
      "  0.22957746  0.24839035  0.24235412  0.24356137  0.22173038  0.21549295\n",
      "  0.21961771  0.23521127  0.23038229  0.22756538  0.22404426  0.33179075\n",
      "  0.2469819   0.21408451  0.2140845   0.20503018]\n",
      "step nr. 5 prediction / true value for lc number 13 0.328041 / 0.276659959129\n",
      "step nr. 6 prediction / true value for lc number 13 0.319333 / 0.275050303766\n",
      "step nr. 7 prediction / true value for lc number 13 0.323845 / 0.288933598569\n",
      "step nr. 8 prediction / true value for lc number 13 0.307771 / 0.275251509888\n",
      "step nr. 9 prediction / true value for lc number 13 0.32238 / 0.311066399728\n",
      "step nr. 10 prediction / true value for lc number 13 0.307232 / 0.257645875216\n",
      "step nr. 11 prediction / true value for lc number 13 0.312327 / 0.26348088256\n",
      "step nr. 12 prediction / true value for lc number 13 0.302676 / 0.282394366605\n",
      "step nr. 13 prediction / true value for lc number 13 0.305282 / 0.245372237904\n",
      "step nr. 14 prediction / true value for lc number 13 0.300237 / 0.252716300743\n",
      "step nr. 15 prediction / true value for lc number 13 0.296431 / 0.246177060263\n",
      "step nr. 16 prediction / true value for lc number 13 0.295153 / 0.235714284437\n",
      "step nr. 17 prediction / true value for lc number 13 0.291875 / 0.264486921685\n",
      "step nr. 18 prediction / true value for lc number 13 0.291875 / 0.253319919109\n",
      "step nr. 19 prediction / true value for lc number 13 0.286506 / 0.230482899717\n",
      "step nr. 20 prediction / true value for lc number 13 0.286506 / 0.227062367967\n",
      "step nr. 21 prediction / true value for lc number 13 0.286506 / 0.232796779701\n",
      "step nr. 22 prediction / true value for lc number 13 0.286506 / 0.227364180343\n",
      "step nr. 23 prediction / true value for lc number 13 0.285248 / 0.229476860591\n",
      "step nr. 24 prediction / true value for lc number 13 0.285248 / 0.229577464717\n",
      "step nr. 25 prediction / true value for lc number 13 0.285248 / 0.248390346766\n",
      "step nr. 26 prediction / true value for lc number 13 0.285248 / 0.242354122656\n",
      "step nr. 27 prediction / true value for lc number 13 0.285248 / 0.243561365775\n",
      "step nr. 28 prediction / true value for lc number 13 0.285248 / 0.22173038125\n",
      "step nr. 29 prediction / true value for lc number 13 0.285248 / 0.215492953147\n",
      "step nr. 30 prediction / true value for lc number 13 0.285248 / 0.219617709517\n",
      "step nr. 31 prediction / true value for lc number 13 0.285248 / 0.235211265939\n",
      "step nr. 32 prediction / true value for lc number 13 0.285248 / 0.230382293463\n",
      "step nr. 33 prediction / true value for lc number 13 0.285248 / 0.227565382208\n",
      "step nr. 34 prediction / true value for lc number 13 0.285248 / 0.224044261234\n",
      "step nr. 35 prediction / true value for lc number 13 0.285248 / 0.331790747387\n",
      "step nr. 36 prediction / true value for lc number 13 0.285248 / 0.246981897524\n",
      "step nr. 37 prediction / true value for lc number 13 0.285248 / 0.214084506035\n",
      "step nr. 38 prediction / true value for lc number 13 0.285248 / 0.214084501777\n",
      "step nr. 39 prediction / true value for lc number 13 0.285248 / 0.205030181578\n",
      "\n",
      "eval_xgb starting at step 5\n",
      "lcs [ 0.79588478  0.74742798  0.65154321  0.61779835  0.58415638  0.57839506\n",
      "  0.52705761  0.50072017  0.49485597  0.45483539  0.45823045  0.46543209\n",
      "  0.47263374  0.4409465   0.39866255  0.41790124  0.43251029  0.37952675\n",
      "  0.39938272  0.37191358  0.37407407  0.3781893   0.35154321  0.33034979\n",
      "  0.31820988  0.36121399  0.32037037  0.34917695  0.31800412  0.31358025\n",
      "  0.32129629  0.3244856   0.34002057  0.31193416  0.33909465  0.3303498\n",
      "  0.30617283  0.32294238  0.30257201  0.33004115]\n",
      "step nr. 5 prediction / true value for lc number 13 0.829519 / 0.578395060919\n",
      "step nr. 6 prediction / true value for lc number 13 0.790915 / 0.527057613488\n",
      "step nr. 7 prediction / true value for lc number 13 0.714749 / 0.500720170913\n",
      "step nr. 8 prediction / true value for lc number 13 0.743645 / 0.494855966833\n",
      "step nr. 9 prediction / true value for lc number 13 0.874133 / 0.454835391707\n",
      "step nr. 10 prediction / true value for lc number 13 0.844852 / 0.458230453509\n",
      "step nr. 11 prediction / true value for lc number 13 0.819811 / 0.465432094203\n",
      "step nr. 12 prediction / true value for lc number 13 0.840803 / 0.472633742624\n",
      "step nr. 13 prediction / true value for lc number 13 0.874133 / 0.44094650061\n",
      "step nr. 14 prediction / true value for lc number 13 0.874133 / 0.398662551686\n",
      "step nr. 15 prediction / true value for lc number 13 0.874133 / 0.417901235598\n",
      "step nr. 16 prediction / true value for lc number 13 0.874133 / 0.432510285466\n",
      "step nr. 17 prediction / true value for lc number 13 0.874133 / 0.37952675422\n",
      "step nr. 18 prediction / true value for lc number 13 0.874133 / 0.399382723702\n",
      "step nr. 19 prediction / true value for lc number 13 0.874133 / 0.371913578775\n",
      "step nr. 20 prediction / true value for lc number 13 0.874133 / 0.374074074957\n",
      "step nr. 21 prediction / true value for lc number 13 0.874133 / 0.378189303257\n",
      "step nr. 22 prediction / true value for lc number 13 0.874133 / 0.351543205756\n",
      "step nr. 23 prediction / true value for lc number 13 0.874133 / 0.330349789725\n",
      "step nr. 24 prediction / true value for lc number 13 0.874133 / 0.318209884343\n",
      "step nr. 25 prediction / true value for lc number 13 0.874133 / 0.36121398652\n",
      "step nr. 26 prediction / true value for lc number 13 0.874133 / 0.320370373902\n",
      "step nr. 27 prediction / true value for lc number 13 0.874133 / 0.34917695434\n",
      "step nr. 28 prediction / true value for lc number 13 0.874133 / 0.318004115864\n",
      "step nr. 29 prediction / true value for lc number 13 0.874133 / 0.313580245883\n",
      "step nr. 30 prediction / true value for lc number 13 0.874133 / 0.321296292323\n",
      "step nr. 31 prediction / true value for lc number 13 0.874133 / 0.32448559558\n",
      "step nr. 32 prediction / true value for lc number 13 0.874133 / 0.34002057049\n",
      "step nr. 33 prediction / true value for lc number 13 0.874133 / 0.311934159862\n",
      "step nr. 34 prediction / true value for lc number 13 0.874133 / 0.339094645447\n",
      "step nr. 35 prediction / true value for lc number 13 0.874133 / 0.330349800763\n",
      "step nr. 36 prediction / true value for lc number 13 0.874133 / 0.306172834502\n",
      "step nr. 37 prediction / true value for lc number 13 0.874133 / 0.32294238276\n",
      "step nr. 38 prediction / true value for lc number 13 0.874133 / 0.302572014155\n",
      "step nr. 39 prediction / true value for lc number 13 0.874133 / 0.330041154667\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fa8460c89607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m cfg = {'maxdepth': 10, 'lr': 0.08119864140758115, 'gamma': 0.007833441242813044, 'cols_bt': 0.9376450587145334, \n\u001b[1;32m     38\u001b[0m        'n_estimators': 1000, 'subsample': 0.7946631901813815}\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb_next'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlcs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'res_xgb_next'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL Theory/project/models.py\u001b[0m in \u001b[0;36meval_cv\u001b[0;34m(model_type, X, Y, steps, cfg, epochs, splits, lr_exp_decay, earlystop, dropout, L1L2, mode)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0mval_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pred_xgb_stepwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mtrn_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pred_xgb_stepwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'finalstep'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "cfg = {'batch_size': 20, 'lr': 0.002}\n",
    "res_train, res_val = np.zeros((3,4)), np.zeros((3,4))\n",
    "res_lstm_nextstep = []   # evaluating with next steps\n",
    "for i, train_steps in enumerate([5,10,20]):\n",
    "    res = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                    steps=(train_steps,[5,10,20,30]), \n",
    "                    cfg=cfg, epochs=1000, earlystop=True, mode='nextstep')\n",
    "    res_lstm_nextstep.append(res)\n",
    "t.pickle_to_file(res_lstm_nextstep, 'res_lstm_nextstep')    \n",
    "\n",
    "# 3.3 train with random lenghts\n",
    "cfg = {'batch_size': 20, 'lr': 0.002}\n",
    "res = m.eval_cv('multi_lstm', [configs, lcs], Y, steps=(0,[5,10,20,30]), \n",
    "                cfg=cfg, epochs=1000, earlystop=True, mode='nextstep')\n",
    "t.pickle_to_file(res, 'res_lstm_nextstep_random')\n",
    "\n",
    "# task 3.3 base line training with fixed lenghts (on final epoch)\n",
    "cfg = {'batch_size': 20, 'lr': 0.002}\n",
    "res_train, res_val = np.zeros((3,4)), np.zeros((3,4))\n",
    "res_lstm_finalstep = []   # evaluating directly on final steps\n",
    "for i, train_steps in enumerate([5,10,20]):\n",
    "    res = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                     steps=(train_steps,[5,10,20,30]), \n",
    "                     cfg=cfg, epochs=1000, earlystop=True, \n",
    "                     mode='finalstep')\n",
    "    res_train[i], res_val[i] = res['trn_means'], res['val_means']\n",
    "    res_lstm_finalstep.append(res)    \n",
    "t.pickle_to_file(res_lstm_finalstep, 'res_lstm_finalstep')\n",
    "\n",
    "\n",
    "# 3.3 train train using final points with random lenghts\n",
    "res = m.eval_cv('multi_lstm', [configs, lcs], Y, steps=(0,[5,10,20,30]), \n",
    "                cfg=cfg, epochs=1000, earlystop=True, mode='finalstep')\n",
    "t.pickle_to_file(res, 'res_lstm_finalstep_random')\n",
    "\n",
    "# task 3.4 \n",
    "cfg = {'maxdepth': 10, 'lr': 0.08119864140758115, 'gamma': 0.007833441242813044, 'cols_bt': 0.9376450587145334, \n",
    "       'n_estimators': 1000, 'subsample': 0.7946631901813815}\n",
    "res = m.eval_cv('xgb_next', [configs, lcs], Y, steps=(0,[5,10,20,30]), cfg=cfg)\n",
    "t.pickle_to_file(res, 'res_xgb_next')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.2378107 ,  0.34378031,  0.24267757,  0.87413275,  0.69131762,\n",
      "        0.69131762,  0.28524768,  0.47180626,  0.33312452,  0.33312452,\n",
      "        0.87413275,  0.27171901,  0.27171901,  0.28524768,  0.87413275,\n",
      "        0.27171901,  0.51169223,  0.87413275,  0.28524768,  0.69131762,\n",
      "        0.28524768,  0.87413275,  0.69131762,  0.3486748 ,  0.69131762,\n",
      "        0.87413275,  0.3486748 ,  0.47180626,  0.27171901,  0.87413275,\n",
      "        0.47180626,  0.28524768,  0.69131762,  0.87413275,  0.87413275,\n",
      "        0.87413275,  0.87413275,  0.27171901,  0.3486748 ,  0.87413275,\n",
      "        0.28524768,  0.2378107 ,  0.28524768,  0.26240456,  0.34378031,\n",
      "        0.58625638,  0.28524768,  0.87413275,  0.47180626,  0.58625638,\n",
      "        0.28524768,  0.3486748 ,  0.33312452,  0.87413275,  0.87413275,\n",
      "        0.28524768,  0.87413275,  0.87413275,  0.66242188,  0.28524768,\n",
      "        0.26240456,  0.28524768,  0.27171901,  0.3486748 ,  0.28524768,\n",
      "        0.86212778,  0.28524768,  0.27171901,  0.3486748 ,  0.28524768,\n",
      "        0.47180626,  0.39525521,  0.50287592,  0.39525521,  0.28524768,\n",
      "        0.3486748 ,  0.46063739,  0.33312452,  0.87413275,  0.34378031,\n",
      "        0.33312452,  0.87413275,  0.87413275,  0.28524768,  0.27171901,\n",
      "        0.87413275,  0.3486748 ,  0.47180626,  0.26240456,  0.34043393,\n",
      "        0.30652297,  0.30652297,  0.4729549 ,  0.46169966,  0.43106872,\n",
      "        0.69172424,  0.87920594,  0.30652297,  0.34043393,  0.34043393,\n",
      "        0.30652297,  0.34043393,  0.87920594,  0.34043393,  0.6429975 ,\n",
      "        0.63411283,  0.87920594,  0.50840509,  0.85505164,  0.3366034 ,\n",
      "        0.34043393,  0.87920594,  0.4729549 ,  0.48080721,  0.34043393,\n",
      "        0.87920594,  0.34043393,  0.87920594,  0.27173233,  0.30187929,\n",
      "        0.87920594,  0.48080721,  0.30652297,  0.34043393,  0.30652297,\n",
      "        0.34043393,  0.48080721,  0.34043393,  0.28759301,  0.30187929,\n",
      "        0.34043393,  0.65761477,  0.34043393,  0.34043393,  0.34043393,\n",
      "        0.22891951,  0.27173233,  0.30652297,  0.85505164,  0.70699394,\n",
      "        0.4729549 ,  0.34043393,  0.83518541,  0.30652297,  0.87920594,\n",
      "        0.30187929,  0.48080721,  0.85505164,  0.85505164,  0.87920594,\n",
      "        0.68283957,  0.48080721,  0.30652297,  0.30652297,  0.34043393,\n",
      "        0.30652297,  0.30652297,  0.30187929,  0.30652297,  0.28759301,\n",
      "        0.25348228,  0.30652297,  0.27173233,  0.87920594,  0.46169966,\n",
      "        0.6429975 ,  0.87920594,  0.34043393,  0.30652297,  0.30652297,\n",
      "        0.34043393,  0.30652297,  0.34043393,  0.87920594,  0.87920594,\n",
      "        0.34043393,  0.85505164,  0.44599783,  0.88002437,  0.85370159,\n",
      "        0.340974  ,  0.44599783,  0.27476174,  0.27476174,  0.340974  ,\n",
      "        0.340974  ,  0.44599783,  0.340974  ,  0.340974  ,  0.27476174,\n",
      "        0.39665261,  0.85370159,  0.25630426,  0.44599783,  0.27476174,\n",
      "        0.88002437,  0.27476174,  0.27476174,  0.44599783,  0.27476174,\n",
      "        0.27476174,  0.27476174,  0.27476174,  0.74292231,  0.63675761,\n",
      "        0.340974  ,  0.44599783,  0.85370159,  0.39665261,  0.340974  ,\n",
      "        0.88002437,  0.27476174,  0.27476174,  0.340974  ,  0.88002437,\n",
      "        0.88002437,  0.27476174,  0.39665261,  0.85370159,  0.27476174,\n",
      "        0.88002437,  0.27476174,  0.39665261,  0.88002437,  0.340974  ,\n",
      "        0.340974  ,  0.340974  ,  0.25630426,  0.88002437,  0.340974  ,\n",
      "        0.340974  ,  0.39665261,  0.88002437,  0.340974  ,  0.340974  ,\n",
      "        0.27476174,  0.27476174,  0.44599783,  0.340974  ,  0.340974  ,\n",
      "        0.69596994,  0.27476174,  0.25630426,  0.340974  ,  0.88002437,\n",
      "        0.88002437,  0.27476174,  0.27476174,  0.27476174,  0.27476174,\n",
      "        0.39665261,  0.27476174,  0.340974  ,  0.27476174,  0.39665261,\n",
      "        0.340974  ,  0.27476174,  0.88002437,  0.39665261,  0.340974  ,\n",
      "        0.340974  ,  0.340974  ,  0.27476174,  0.66377175,  0.340974  ]), array([ 0.21452314,  0.28524768,  0.2378107 ,  0.87413275,  0.58625638,\n",
      "        0.58625638,  0.2378107 ,  0.3486748 ,  0.26240456,  0.28524768,\n",
      "        0.87413275,  0.2378107 ,  0.2378107 ,  0.27171901,  0.87413275,\n",
      "        0.2566148 ,  0.47180626,  0.42806965,  0.27171901,  0.69131762,\n",
      "        0.27171901,  0.87413275,  0.58625638,  0.28524768,  0.58625638,\n",
      "        0.87413275,  0.28524768,  0.3486748 ,  0.2378107 ,  0.34378031,\n",
      "        0.47180626,  0.28524768,  0.69131762,  0.33761159,  0.87413275,\n",
      "        0.87413275,  0.87413275,  0.2378107 ,  0.28524768,  0.79496002,\n",
      "        0.26240456,  0.21452314,  0.2378107 ,  0.23412678,  0.27171901,\n",
      "        0.47180626,  0.23412678,  0.39525521,  0.39525521,  0.47180626,\n",
      "        0.2378107 ,  0.28524768,  0.27171901,  0.39525521,  0.33761159,\n",
      "        0.28524768,  0.87413275,  0.87413275,  0.58625638,  0.2378107 ,\n",
      "        0.2378107 ,  0.21452314,  0.2378107 ,  0.3486748 ,  0.23412678,\n",
      "        0.86212778,  0.28524768,  0.2378107 ,  0.33761159,  0.26240456,\n",
      "        0.39525521,  0.2566148 ,  0.27171901,  0.34378031,  0.2378107 ,\n",
      "        0.34378031,  0.3486748 ,  0.27171901,  0.87413275,  0.2378107 ,\n",
      "        0.28524768,  0.39525521,  0.87413275,  0.23412678,  0.24267757,\n",
      "        0.87413275,  0.2378107 ,  0.39525521,  0.2378107 ,  0.34043393,\n",
      "        0.28144908,  0.27173233,  0.34043393,  0.30187929,  0.34043393,\n",
      "        0.69172424,  0.87920594,  0.22891951,  0.30652297,  0.30187929,\n",
      "        0.25348228,  0.30652297,  0.4729549 ,  0.34043393,  0.56472808,\n",
      "        0.4729549 ,  0.87920594,  0.4729549 ,  0.4729549 ,  0.28144908,\n",
      "        0.34043393,  0.30652297,  0.34043393,  0.22891951,  0.25348228,\n",
      "        0.4729549 ,  0.34043393,  0.4729549 ,  0.20824772,  0.22891951,\n",
      "        0.4729549 ,  0.41754416,  0.25348228,  0.30652297,  0.25348228,\n",
      "        0.30652297,  0.22891951,  0.31035349,  0.20824772,  0.22891951,\n",
      "        0.30187929,  0.6429975 ,  0.30652297,  0.30187929,  0.30652297,\n",
      "        0.20824772,  0.20824772,  0.28759301,  0.85505164,  0.63411283,\n",
      "        0.30652297,  0.31035349,  0.34043393,  0.28144908,  0.87920594,\n",
      "        0.22891951,  0.28759301,  0.34043393,  0.78960997,  0.31035349,\n",
      "        0.60995835,  0.34043393,  0.25348228,  0.22891951,  0.34043393,\n",
      "        0.28144908,  0.22891951,  0.20824772,  0.25348228,  0.22891951,\n",
      "        0.22891951,  0.27173233,  0.20824772,  0.31035349,  0.34043393,\n",
      "        0.56472808,  0.87920594,  0.26703709,  0.28144908,  0.22891951,\n",
      "        0.30652297,  0.25348228,  0.30652297,  0.87920594,  0.87920594,\n",
      "        0.30652297,  0.85505164,  0.39665261,  0.88002437,  0.85370159,\n",
      "        0.340974  ,  0.39665261,  0.23483148,  0.25630426,  0.27476174,\n",
      "        0.25630426,  0.39665261,  0.340974  ,  0.27476174,  0.27476174,\n",
      "        0.340974  ,  0.85370159,  0.21092033,  0.39665261,  0.25630426,\n",
      "        0.55095595,  0.22004855,  0.24064258,  0.39665261,  0.25630426,\n",
      "        0.27476174,  0.25630426,  0.27476174,  0.39665261,  0.39665261,\n",
      "        0.25630426,  0.39665261,  0.85370159,  0.340974  ,  0.27476174,\n",
      "        0.39665261,  0.23483148,  0.25630426,  0.340974  ,  0.88002437,\n",
      "        0.88002437,  0.25630426,  0.39665261,  0.83307195,  0.25630426,\n",
      "        0.4125365 ,  0.25630426,  0.340974  ,  0.4192788 ,  0.27476174,\n",
      "        0.25630426,  0.27476174,  0.22786665,  0.88002437,  0.340974  ,\n",
      "        0.27476174,  0.340974  ,  0.88002437,  0.25630426,  0.27476174,\n",
      "        0.25630426,  0.25630426,  0.39665261,  0.27476174,  0.27476174,\n",
      "        0.69596994,  0.21092033,  0.25630426,  0.27476174,  0.39665261,\n",
      "        0.48313314,  0.22786665,  0.27476174,  0.25630426,  0.27476174,\n",
      "        0.39665261,  0.27476174,  0.27476174,  0.27476174,  0.340974  ,\n",
      "        0.27476174,  0.24064258,  0.340974  ,  0.340974  ,  0.25630426,\n",
      "        0.340974  ,  0.27476174,  0.25630426,  0.39665261,  0.25630426]), array([ 0.18251127,  0.27171901,  0.21452314,  0.87413275,  0.47180626,\n",
      "        0.47180626,  0.21452314,  0.34378031,  0.21452314,  0.26240456,\n",
      "        0.87413275,  0.2378107 ,  0.21452314,  0.2378107 ,  0.46063739,\n",
      "        0.20849678,  0.3486748 ,  0.28650552,  0.2378107 ,  0.69131762,\n",
      "        0.27171901,  0.87413275,  0.5162921 ,  0.28524768,  0.47180626,\n",
      "        0.3486748 ,  0.28524768,  0.3486748 ,  0.18251127,  0.27171901,\n",
      "        0.39525521,  0.2378107 ,  0.58625638,  0.28524768,  0.87413275,\n",
      "        0.87413275,  0.87413275,  0.21452314,  0.27171901,  0.39525521,\n",
      "        0.2378107 ,  0.23412678,  0.22610053,  0.21452314,  0.2378107 ,\n",
      "        0.47180626,  0.21452314,  0.33312452,  0.3486748 ,  0.39525521,\n",
      "        0.24796268,  0.26240456,  0.22610053,  0.35133439,  0.27171901,\n",
      "        0.26240456,  0.87413275,  0.74364501,  0.47180626,  0.21452314,\n",
      "        0.23412678,  0.18251127,  0.22610053,  0.28524768,  0.21452314,\n",
      "        0.86212778,  0.27171901,  0.23412678,  0.28524768,  0.2378107 ,\n",
      "        0.3486748 ,  0.20849678,  0.23412678,  0.28524768,  0.2378107 ,\n",
      "        0.28524768,  0.34378031,  0.26240456,  0.87413275,  0.21452314,\n",
      "        0.26240456,  0.3486748 ,  0.87413275,  0.18251127,  0.23412678,\n",
      "        0.87413275,  0.2378107 ,  0.3486748 ,  0.18251127,  0.30652297,\n",
      "        0.28759301,  0.20824772,  0.34043393,  0.22891951,  0.30652297,\n",
      "        0.60097754,  0.87920594,  0.20824772,  0.30187929,  0.20824772,\n",
      "        0.20824772,  0.30187929,  0.34833324,  0.30652297,  0.4729549 ,\n",
      "        0.44248027,  0.87920594,  0.34833324,  0.34833324,  0.22891951,\n",
      "        0.30652297,  0.22891951,  0.34043393,  0.20824772,  0.22891951,\n",
      "        0.30652297,  0.30652297,  0.30187929,  0.20824772,  0.20824772,\n",
      "        0.30187929,  0.34043393,  0.22891951,  0.30187929,  0.20824772,\n",
      "        0.28759301,  0.20824772,  0.28759301,  0.20824772,  0.20824772,\n",
      "        0.25348228,  0.4729549 ,  0.30187929,  0.25348228,  0.30187929,\n",
      "        0.20824772,  0.20824772,  0.25348228,  0.85505164,  0.50055277,\n",
      "        0.28759301,  0.30187929,  0.30187929,  0.25348228,  0.87920594,\n",
      "        0.20824772,  0.20824772,  0.30652297,  0.4729549 ,  0.22891951,\n",
      "        0.60097754,  0.30187929,  0.22891951,  0.25348228,  0.30652297,\n",
      "        0.20824772,  0.20824772,  0.18076879,  0.18076879,  0.22891951,\n",
      "        0.22891951,  0.22891951,  0.20824772,  0.27173233,  0.30652297,\n",
      "        0.4729549 ,  0.46169966,  0.22891951,  0.20824772,  0.20824772,\n",
      "        0.30187929,  0.27173233,  0.28144908,  0.4729549 ,  0.87920594,\n",
      "        0.30187929,  0.85505164,  0.39367509,  0.88002437,  0.85370159,\n",
      "        0.27476174,  0.39665261,  0.22004855,  0.21092033,  0.26331627,\n",
      "        0.24064258,  0.39367509,  0.27476174,  0.26750448,  0.21092033,\n",
      "        0.340974  ,  0.69596994,  0.22004855,  0.39665261,  0.25630426,\n",
      "        0.39665261,  0.21092033,  0.25630426,  0.39367509,  0.25630426,\n",
      "        0.27476174,  0.21092033,  0.23483148,  0.340974  ,  0.340974  ,\n",
      "        0.21092033,  0.340974  ,  0.69596994,  0.340974  ,  0.25630426,\n",
      "        0.340974  ,  0.21092033,  0.24064258,  0.27476174,  0.88002437,\n",
      "        0.88002437,  0.25630426,  0.340974  ,  0.69596994,  0.25630426,\n",
      "        0.340974  ,  0.21092033,  0.27824485,  0.340974  ,  0.25630426,\n",
      "        0.21092033,  0.22004855,  0.22004855,  0.52578032,  0.27476174,\n",
      "        0.27476174,  0.340974  ,  0.88002437,  0.21092033,  0.27476174,\n",
      "        0.23483148,  0.21092033,  0.39665261,  0.27476174,  0.27476174,\n",
      "        0.47459248,  0.22004855,  0.22786665,  0.27476174,  0.340974  ,\n",
      "        0.39665261,  0.21092033,  0.23483148,  0.21092033,  0.25630426,\n",
      "        0.340974  ,  0.25630426,  0.25630426,  0.21092033,  0.340974  ,\n",
      "        0.272396  ,  0.21092033,  0.27476174,  0.2770521 ,  0.21092033,\n",
      "        0.2770521 ,  0.27476174,  0.21092033,  0.39665261,  0.25630426]), array([ 0.18251127,  0.27171901,  0.20849678,  0.87413275,  0.47180626,\n",
      "        0.47180626,  0.20849678,  0.30723205,  0.20849678,  0.26046538,\n",
      "        0.87413275,  0.2378107 ,  0.18251127,  0.21452314,  0.39525521,\n",
      "        0.20849678,  0.3486748 ,  0.28524768,  0.23412678,  0.69131762,\n",
      "        0.24267757,  0.81981122,  0.50564605,  0.28524768,  0.47180626,\n",
      "        0.34378031,  0.27171901,  0.33761159,  0.18251127,  0.28524768,\n",
      "        0.39525521,  0.24267757,  0.58112532,  0.27171901,  0.87413275,\n",
      "        0.87413275,  0.87413275,  0.18251127,  0.27171901,  0.36393499,\n",
      "        0.2378107 ,  0.18251127,  0.21452314,  0.22610053,  0.25844097,\n",
      "        0.39525521,  0.18251127,  0.29643101,  0.33761159,  0.39525521,\n",
      "        0.2378107 ,  0.24309579,  0.22610053,  0.36393499,  0.27171901,\n",
      "        0.2378107 ,  0.87413275,  0.47180626,  0.47180626,  0.18251127,\n",
      "        0.21452314,  0.18251127,  0.21452314,  0.28650552,  0.18251127,\n",
      "        0.86212778,  0.26240456,  0.24267757,  0.28524768,  0.2378107 ,\n",
      "        0.34378031,  0.18251127,  0.22610053,  0.28650552,  0.23412678,\n",
      "        0.28524768,  0.30023712,  0.26240456,  0.87413275,  0.21452314,\n",
      "        0.2378107 ,  0.3486748 ,  0.87413275,  0.18251127,  0.2378107 ,\n",
      "        0.87413275,  0.20336598,  0.3486748 ,  0.21452314,  0.30652297,\n",
      "        0.28759301,  0.21230111,  0.30652297,  0.23232666,  0.30187929,\n",
      "        0.55687571,  0.87920594,  0.20824772,  0.27173233,  0.21034935,\n",
      "        0.21741953,  0.30187929,  0.30652297,  0.30652297,  0.43469834,\n",
      "        0.37299889,  0.87920594,  0.35971993,  0.36780697,  0.22891951,\n",
      "        0.30187929,  0.21034935,  0.3288061 ,  0.20824772,  0.22891951,\n",
      "        0.30652297,  0.30187929,  0.26449898,  0.18076879,  0.21034935,\n",
      "        0.28759301,  0.34043393,  0.21230111,  0.28759301,  0.20824772,\n",
      "        0.28759301,  0.20824772,  0.28759301,  0.18076879,  0.20824772,\n",
      "        0.23232666,  0.4729549 ,  0.27173233,  0.29251313,  0.27173233,\n",
      "        0.20824772,  0.20824772,  0.25348228,  0.85505164,  0.48181176,\n",
      "        0.30187929,  0.28759301,  0.30187929,  0.22891951,  0.87920594,\n",
      "        0.20824772,  0.21515107,  0.30652297,  0.43106872,  0.22891951,\n",
      "        0.50055277,  0.30652297,  0.22891951,  0.22891951,  0.32720137,\n",
      "        0.20824772,  0.18076879,  0.18076879,  0.18076879,  0.22891951,\n",
      "        0.22891951,  0.20824772,  0.20824772,  0.22891951,  0.30652297,\n",
      "        0.43469834,  0.36433673,  0.22891951,  0.20824772,  0.20824772,\n",
      "        0.30652297,  0.20824772,  0.26017734,  0.46169966,  0.87920594,\n",
      "        0.30187929,  0.85505164,  0.340974  ,  0.88002437,  0.85370159,\n",
      "        0.28964049,  0.34615681,  0.21092033,  0.21092033,  0.272396  ,\n",
      "        0.22786665,  0.340974  ,  0.27476174,  0.26987022,  0.21092033,\n",
      "        0.29611298,  0.69596994,  0.21092033,  0.340974  ,  0.25630426,\n",
      "        0.39665261,  0.21092033,  0.23483148,  0.340974  ,  0.24064258,\n",
      "        0.25630426,  0.21092033,  0.24064258,  0.340974  ,  0.340974  ,\n",
      "        0.21092033,  0.340974  ,  0.69596994,  0.29296777,  0.2770521 ,\n",
      "        0.340974  ,  0.21092033,  0.24064258,  0.27476174,  0.88002437,\n",
      "        0.88002437,  0.23483148,  0.340974  ,  0.5052458 ,  0.26750448,\n",
      "        0.28964049,  0.21092033,  0.28290874,  0.340974  ,  0.25630426,\n",
      "        0.21092033,  0.21092033,  0.21092033,  0.4192788 ,  0.27824485,\n",
      "        0.27476174,  0.28964049,  0.88002437,  0.21092033,  0.25630426,\n",
      "        0.23483148,  0.21092033,  0.39665261,  0.28171599,  0.26750448,\n",
      "        0.43457991,  0.21092033,  0.21092033,  0.25630426,  0.29611298,\n",
      "        0.40116704,  0.21092033,  0.22004855,  0.21092033,  0.25630426,\n",
      "        0.340974  ,  0.25630426,  0.26331627,  0.21092033,  0.29296777,\n",
      "        0.27476174,  0.21092033,  0.28964049,  0.340974  ,  0.21092033,\n",
      "        0.28964049,  0.27476174,  0.21092033,  0.39665261,  0.25630426])]\n"
     ]
    }
   ],
   "source": [
    "gaga = t.pickle_from_file('res_xgb_next')\n",
    "print(gaga['y_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9616f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9616f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b96a66ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b96b36f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9acb0160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ba37fada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9d199940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9d0a5e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b942b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9a8cf080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b99c28fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# res_lstm_finalstep = t.pickle_from_file('res_xgb_next')\n",
    "t.box_plot(Y, (5,5), [t.pickle_from_file('res_lstm_nextstep_random')],\n",
    "            ['5 steps', '10 steps', '20 steps', '30 steps'], 'lstm stepwise random input length')\n",
    "\n",
    "t.box_plot(Y, (5,5), [t.pickle_from_file('res_lstm_finalstep_random')],\n",
    "            ['5 steps', '10 steps', '20 steps', '30 steps'], 'lstm trained on final point random input length')\n",
    "\n",
    "\n",
    "t.box_plot(Y, (5,5), [t.pickle_from_file('res_xgb_next')],\n",
    "            ['5 steps', '10 steps', '20 steps', '30 steps'], 'XGB stepwise until final step')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b97644978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b97867f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b977925c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b987ea978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98e63198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98081080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b98f8b940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b988c6588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b972bfb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot all scatterplot for rnns\n",
    "t.scatter_plot_multi(Y, (20,4), t.pickle_from_file('res_lstm_nextstep_random'), \n",
    "                     'rnn trained stepwise random \\npredict from', steps=[5,10,20,30])\n",
    "\n",
    "t.scatter_plot_multi(Y, (20,4), t.pickle_from_file('res_lstm_finalstep_random'), \n",
    "                     'rnn trained on final point random \\npredict from', steps=[5,10,20,30])\n",
    "\n",
    "t.scatter_plot_multi(Y, (20,4), t.pickle_from_file('res_xgb_next'), \n",
    "                     'xgb trained stepwise random \\npredict from', steps=[5,10,20,30])\n",
    "\n",
    "for i,s in enumerate([5,10,20]):\n",
    "    t.scatter_plot_multi(Y, (20,4), t.pickle_from_file('res_lstm_nextstep')[i], \n",
    "                         'rnn trained stepwise on '+str(s)+' steps \\npredict from', steps=[5,10,20,30])\n",
    "\n",
    "for i,s in enumerate([5,10,20]):\n",
    "    t.scatter_plot_multi(Y, (20,4), t.pickle_from_file('res_lstm_finalstep')[i], \n",
    "                         'rnn trained on final point on '+str(s)+' steps \\npredict from', steps=[5,10,20,30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ba2a0a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b992caf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.box_plot(Y, (15,4), t.pickle_from_file('res_lstm_nextstep'),\n",
    "            ['5 steps', '10 steps', '20 steps', '30 steps'], 'lstm trained stepwise \\n at input length: ', steps = [5,10,20])\n",
    "t.box_plot(Y, (15,4), t.pickle_from_file('res_lstm_finalstep'),\n",
    "            ['5 steps', '10 steps', '20 steps', '30 steps'], 'lstm trained on final step \\n at input length: ', steps = [5,10,20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mses [[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "mses [[  4.17128188e-02   4.04564586e-02   4.04458238e-02   7.15193738e-02]\n",
      " [  4.81123812e-02   1.90555527e-01   1.01201490e-01   2.15394736e-02]\n",
      " [  4.81986522e-02   1.82114042e-02   3.83503424e-03   1.34141349e-03]\n",
      " [  8.94266561e-01   7.56749991e-01   3.53889073e-02   3.53210140e-03]\n",
      " [  4.83067392e-02   1.15198954e-02   2.04126966e-03   1.12658018e-03]\n",
      " [  1.28039351e-03   8.63054703e-03   2.58635281e-02   3.53853100e-02]\n",
      " [  1.22754472e-02   6.19568682e-04   1.70244309e-03   2.89102025e-03]\n",
      " [  2.80209584e-02   1.24531721e-02   4.25402222e-04   7.47715737e-04]\n",
      " [  1.82137786e-03   6.94467597e-04   4.66306242e-04   7.55971088e-04]]\n",
      "table [['0.04', '0.04', '0.04', '0.07'], ['0.05', '0.19', '0.10', '0.02'], ['0.05', '0.02', '0.00', '0.00'], ['0.89', '0.76', '0.04', '0.00'], ['0.05', '0.01', '0.00', '0.00'], ['0.00', '0.01', '0.03', '0.04'], ['0.01', '0.00', '0.00', '0.00'], ['0.03', '0.01', '0.00', '0.00'], ['0.00', '0.00', '0.00', '0.00']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b96c9a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_all = t.pickle_from_file('res_lstm_nextstep')\n",
    "# steps_random = [t.pickle_from_file('res_lstm_nextstep_random')]\n",
    "steps_all.extend([t.pickle_from_file('res_lstm_nextstep_random')])\n",
    "steps_all.extend([t.pickle_from_file('res_xgb_next')])\n",
    "steps_all.extend(t.pickle_from_file('res_lstm_finalstep'))\n",
    "steps_all.extend([t.pickle_from_file('res_lstm_finalstep_random')])\n",
    "\n",
    "t.table_plot(Y, (10,4), steps_all, ['5 steps', '10 steps', '20 steps', '30 steps'], \n",
    "             'table_plot_steps', \n",
    "             steps = ['nextstep  5','nextstep 10','nextstep 20','nextstep rand 5-20','xbn_next',\n",
    "                      'finalstep 5','finalstep 10','finalstep 20','finalstep rand 5-20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path plots/lstm trained stepwise \n",
      " at input length: _sct.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/.local/lib/python3.5/site-packages/matplotlib/figure.py:418: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path plots/lstm trained on final step \n",
      " at input length: _sct.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ba2d327f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ba2bbecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_all = t.pickle_from_file('res_lstm_nextstep')\n",
    "steps_random = [t.pickle_from_file('res_lstm_nextstep_random')]\n",
    "steps_all.extend(steps_random)\n",
    "t.box_plot(Y, (17,4), steps_all, ['5 steps', '10 steps', '20 steps', '30 steps'], \n",
    "           'lstm trained stepwise \\n at input length: ', steps = [5,10,20,'random'])\n",
    "\n",
    "steps_all = t.pickle_from_file('res_lstm_finalstep')\n",
    "steps_random = [t.pickle_from_file('res_lstm_finalstep_random')]\n",
    "steps_all.extend(steps_random)\n",
    "t.box_plot(Y, (17,4), steps_all, ['5 steps', '10 steps', '20 steps', '30 steps'], \n",
    "           'lstm trained on final step \\n at input length: ', steps = [5,10,20,'random 5-20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcs: (265, 40, 1) configs: (265, 5) Y (265, 1)\n",
      "train on nextstep with random nr. of epochs, eval during training with 10 epochs\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.2677 - mean_squared_error: 0.2677 - val_loss: 0.1189 - val_mean_squared_error: 0.1189\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.0657 - mean_squared_error: 0.0657 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 2s 226ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 3s 258ms/step - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 7.2558e-04 - val_mean_squared_error: 7.2558e-04\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 3.2328e-04 - val_mean_squared_error: 3.2328e-04\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 3s 263ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 5.5489e-04 - val_mean_squared_error: 5.5489e-04\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 9.8342e-04 - mean_squared_error: 9.8342e-04 - val_loss: 9.9435e-04 - val_mean_squared_error: 9.9435e-04\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 5.6449e-04 - val_mean_squared_error: 5.6449e-04\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 9.1478e-04 - mean_squared_error: 9.1478e-04 - val_loss: 4.8298e-04 - val_mean_squared_error: 4.8298e-04\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 3s 253ms/step - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 4.3040e-04 - val_mean_squared_error: 4.3040e-04\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 8.4271e-04 - mean_squared_error: 8.4271e-04 - val_loss: 6.8523e-04 - val_mean_squared_error: 6.8523e-04\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 8.5349e-04 - mean_squared_error: 8.5349e-04 - val_loss: 6.5483e-04 - val_mean_squared_error: 6.5483e-04\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 8.1040e-04 - mean_squared_error: 8.1040e-04 - val_loss: 4.7894e-04 - val_mean_squared_error: 4.7894e-04\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 8.5674e-04 - mean_squared_error: 8.5674e-04 - val_loss: 6.3991e-04 - val_mean_squared_error: 6.3991e-04\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 9.7111e-04 - mean_squared_error: 9.7111e-04 - val_loss: 5.7937e-04 - val_mean_squared_error: 5.7937e-04\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 6.1920e-04 - mean_squared_error: 6.1920e-04 - val_loss: 4.1696e-04 - val_mean_squared_error: 4.1696e-04\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 6.1831e-04 - mean_squared_error: 6.1831e-04 - val_loss: 5.7226e-04 - val_mean_squared_error: 5.7226e-04\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 7.3211e-04 - mean_squared_error: 7.3211e-04 - val_loss: 5.6635e-04 - val_mean_squared_error: 5.6635e-04\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 9.9284e-04 - mean_squared_error: 9.9284e-04 - val_loss: 7.5279e-04 - val_mean_squared_error: 7.5279e-04\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 6.1958e-04 - mean_squared_error: 6.1958e-04 - val_loss: 5.7829e-04 - val_mean_squared_error: 5.7829e-04\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 6.5177e-04 - val_mean_squared_error: 6.5177e-04\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 7.6505e-04 - mean_squared_error: 7.6505e-04 - val_loss: 2.9133e-04 - val_mean_squared_error: 2.9133e-04\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 9.4444e-04 - mean_squared_error: 9.4444e-04 - val_loss: 5.5077e-04 - val_mean_squared_error: 5.5077e-04\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 9.3621e-04 - mean_squared_error: 9.3621e-04 - val_loss: 3.3229e-04 - val_mean_squared_error: 3.3229e-04\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 6.2082e-04 - val_mean_squared_error: 6.2082e-04\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 8.9834e-04 - val_mean_squared_error: 8.9834e-04\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 9.0161e-04 - mean_squared_error: 9.0161e-04 - val_loss: 7.1962e-04 - val_mean_squared_error: 7.1962e-04\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 7.5927e-04 - val_mean_squared_error: 7.5927e-04\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.5128e-04 - val_mean_squared_error: 7.5128e-04\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 9.9579e-04 - mean_squared_error: 9.9579e-04 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 3.8782e-04 - val_mean_squared_error: 3.8782e-04\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 7.3315e-04 - mean_squared_error: 7.3315e-04 - val_loss: 6.9188e-04 - val_mean_squared_error: 6.9188e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "10/10 [==============================] - 2s 186ms/step - loss: 7.4697e-04 - mean_squared_error: 7.4697e-04 - val_loss: 6.3821e-04 - val_mean_squared_error: 6.3821e-04\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 6.3978e-04 - mean_squared_error: 6.3978e-04 - val_loss: 4.2315e-04 - val_mean_squared_error: 4.2315e-04\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 6.0573e-04 - mean_squared_error: 6.0573e-04 - val_loss: 9.8216e-04 - val_mean_squared_error: 9.8216e-04\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 6.0173e-04 - val_mean_squared_error: 6.0173e-04\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 6.7619e-04 - mean_squared_error: 6.7619e-04 - val_loss: 2.8773e-04 - val_mean_squared_error: 2.8773e-04\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 5.0470e-04 - mean_squared_error: 5.0470e-04 - val_loss: 3.6429e-04 - val_mean_squared_error: 3.6429e-04\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 4.2885e-04 - mean_squared_error: 4.2885e-04 - val_loss: 2.7515e-04 - val_mean_squared_error: 2.7515e-04\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 4.4325e-04 - mean_squared_error: 4.4325e-04 - val_loss: 3.2190e-04 - val_mean_squared_error: 3.2190e-04\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 6.8719e-04 - mean_squared_error: 6.8719e-04 - val_loss: 5.5208e-04 - val_mean_squared_error: 5.5208e-04\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 6.2382e-04 - mean_squared_error: 6.2382e-04 - val_loss: 5.4480e-04 - val_mean_squared_error: 5.4480e-04\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 2s 220ms/step - loss: 7.1586e-04 - mean_squared_error: 7.1586e-04 - val_loss: 5.8267e-04 - val_mean_squared_error: 5.8267e-04\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 5.4358e-04 - mean_squared_error: 5.4358e-04 - val_loss: 3.9913e-04 - val_mean_squared_error: 3.9913e-04\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 6.9030e-04 - mean_squared_error: 6.9030e-04 - val_loss: 7.5315e-04 - val_mean_squared_error: 7.5315e-04\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.6369e-04 - val_mean_squared_error: 7.6369e-04\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 4.8403e-04 - val_mean_squared_error: 4.8403e-04\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 5.1300e-04 - val_mean_squared_error: 5.1300e-04\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 6.3297e-04 - mean_squared_error: 6.3297e-04 - val_loss: 8.1896e-04 - val_mean_squared_error: 8.1896e-04\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 3s 299ms/step - loss: 9.4704e-04 - mean_squared_error: 9.4704e-04 - val_loss: 5.6224e-04 - val_mean_squared_error: 5.6224e-04\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 6.7777e-04 - mean_squared_error: 6.7777e-04 - val_loss: 4.4723e-04 - val_mean_squared_error: 4.4723e-04\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 8.8174e-04 - mean_squared_error: 8.8174e-04 - val_loss: 5.7607e-04 - val_mean_squared_error: 5.7607e-04\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 3s 330ms/step - loss: 6.3664e-04 - mean_squared_error: 6.3664e-04 - val_loss: 4.8697e-04 - val_mean_squared_error: 4.8697e-04\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 8.1914e-04 - mean_squared_error: 8.1914e-04 - val_loss: 4.1844e-04 - val_mean_squared_error: 4.1844e-04\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 4s 355ms/step - loss: 6.6559e-04 - mean_squared_error: 6.6559e-04 - val_loss: 3.8216e-04 - val_mean_squared_error: 3.8216e-04\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 9.2012e-04 - mean_squared_error: 9.2012e-04 - val_loss: 3.2450e-04 - val_mean_squared_error: 3.2450e-04\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 3s 304ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 8.0235e-04 - val_mean_squared_error: 8.0235e-04\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 7.0622e-04 - val_mean_squared_error: 7.0622e-04\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 3s 316ms/step - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 3s 262ms/step - loss: 7.3145e-04 - mean_squared_error: 7.3145e-04 - val_loss: 4.1746e-04 - val_mean_squared_error: 4.1746e-04\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 3s 347ms/step - loss: 5.0436e-04 - mean_squared_error: 5.0436e-04 - val_loss: 3.5677e-04 - val_mean_squared_error: 3.5677e-04\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 4.3261e-04 - mean_squared_error: 4.3261e-04 - val_loss: 3.7334e-04 - val_mean_squared_error: 3.7334e-04\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 2s 249ms/step - loss: 5.7427e-04 - mean_squared_error: 5.7427e-04 - val_loss: 3.8443e-04 - val_mean_squared_error: 3.8443e-04\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 6.6750e-04 - mean_squared_error: 6.6750e-04 - val_loss: 7.4328e-04 - val_mean_squared_error: 7.4328e-04\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 8.0254e-04 - mean_squared_error: 8.0254e-04 - val_loss: 4.7521e-04 - val_mean_squared_error: 4.7521e-04\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 6.5363e-04 - mean_squared_error: 6.5363e-04 - val_loss: 3.5910e-04 - val_mean_squared_error: 3.5910e-04\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 7.0975e-04 - mean_squared_error: 7.0975e-04 - val_loss: 7.3365e-04 - val_mean_squared_error: 7.3365e-04\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 8.4199e-04 - mean_squared_error: 8.4199e-04 - val_loss: 7.9077e-04 - val_mean_squared_error: 7.9077e-04\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 9.9959e-04 - mean_squared_error: 9.9959e-04 - val_loss: 5.9070e-04 - val_mean_squared_error: 5.9070e-04\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 7.3680e-04 - mean_squared_error: 7.3680e-04 - val_loss: 5.6848e-04 - val_mean_squared_error: 5.6848e-04\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 9.4644e-04 - mean_squared_error: 9.4644e-04 - val_loss: 5.4518e-04 - val_mean_squared_error: 5.4518e-04\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 2s 227ms/step - loss: 6.0675e-04 - mean_squared_error: 6.0675e-04 - val_loss: 2.9774e-04 - val_mean_squared_error: 2.9774e-04\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 3s 275ms/step - loss: 4.9387e-04 - mean_squared_error: 4.9387e-04 - val_loss: 3.5953e-04 - val_mean_squared_error: 3.5953e-04\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 3s 256ms/step - loss: 5.8143e-04 - mean_squared_error: 5.8143e-04 - val_loss: 5.5019e-04 - val_mean_squared_error: 5.5019e-04\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 6.0874e-04 - mean_squared_error: 6.0874e-04 - val_loss: 7.4660e-04 - val_mean_squared_error: 7.4660e-04\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 9.2169e-04 - mean_squared_error: 9.2169e-04 - val_loss: 7.8406e-04 - val_mean_squared_error: 7.8406e-04\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 8.3199e-04 - mean_squared_error: 8.3199e-04 - val_loss: 4.9757e-04 - val_mean_squared_error: 4.9757e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 6.0742e-04 - mean_squared_error: 6.0742e-04 - val_loss: 6.2993e-04 - val_mean_squared_error: 6.2993e-04\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 5.2974e-04 - mean_squared_error: 5.2974e-04 - val_loss: 7.5643e-04 - val_mean_squared_error: 7.5643e-04\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 5.3518e-04 - mean_squared_error: 5.3518e-04 - val_loss: 7.3252e-04 - val_mean_squared_error: 7.3252e-04\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 6.7280e-04 - mean_squared_error: 6.7280e-04 - val_loss: 4.5125e-04 - val_mean_squared_error: 4.5125e-04\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 5.2560e-04 - mean_squared_error: 5.2560e-04 - val_loss: 3.9228e-04 - val_mean_squared_error: 3.9228e-04\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 5.2590e-04 - mean_squared_error: 5.2590e-04 - val_loss: 4.2387e-04 - val_mean_squared_error: 4.2387e-04\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 3.6496e-04 - mean_squared_error: 3.6496e-04 - val_loss: 3.3556e-04 - val_mean_squared_error: 3.3556e-04\n",
      "mse train: 0.04489, mse validation 0.02855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.044886408606220826, 0.02854901651727049)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrapolation learning curves\n",
    "# train rnn on random step lenghts\n",
    "model = m.multi_lstm()\n",
    "split = 200\n",
    "print(\"lcs:\", lcs.shape, \"configs:\", configs.shape, \"Y\", Y.shape)\n",
    "# m.train_lstm(model, [configs,lcs], steps=(0,5), split=200, batch_size=20, epochs=20, mode = 'finalstep')\n",
    "m.train_lstm(model, [configs,lcs], steps=(0,10), split=split, batch_size=20, \n",
    "             epochs=100, mode='nextstep', verbose=1)\n",
    "m.eval_lstm_stepwise(model, [configs,lcs], Y, steps=10, split=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b380860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b3482b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b31cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b3f49e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b34c470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b297f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b2dbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b188710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b9b1f9438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 20   # predict from step onwards\n",
    "val_idx = np.arange(split,Y.shape[0])\n",
    "_, lc_preds = m._pred_lstm_stepwise(model, [configs,lcs], step, val_idx)    # predict from step 10 onwards\n",
    "\n",
    "t.pickle_to_file(lc_preds, 'extrapolations')\n",
    "lc_preds = t.pickle_from_file('extrapolations')\n",
    "\n",
    "for idx in np.arange(3,12):\n",
    "#   sel_id = 8   # select curve, nr. sel id after split\n",
    "    lc_pred = lc_preds[idx]\n",
    "    lc_true = lcs[split+idx]\n",
    "    t.extrapol_plot(lc_true, lc_pred, step, idx, 'extrapolate')\n",
    "\n",
    "# print(lc_pred[:15])\n",
    "# print(lc_true[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    running hyperparameter optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139861376198400\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.07063600373860912, 'cols_bt': 0.9217170129716793, 'lr': 0.1050934646426613, 'n_estimators': 279, 'maxdepth': 3, 'subsample': 0.34897607207545855}\n",
      "MSE on validation data on [5] steps: means over folds: *** 0.00975 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.01163 -0.00698 -0.01064]\n",
      "hyperband obj crossval results 0.00975\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.31305732316547696, 'cols_bt': 0.6343377810392044, 'lr': 0.0012906266637879222, 'n_estimators': 192, 'maxdepth': 9, 'subsample': 0.7704980400242586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data on [5] steps: means over folds: *** 0.04739 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.0518  -0.04517 -0.0452 ]\n",
      "hyperband obj crossval results 0.04739\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.856382480028685, 'cols_bt': 0.3850090031280587, 'lr': 0.0012115364873114829, 'n_estimators': 49, 'maxdepth': 3, 'subsample': 0.5221361806440016}\n",
      "MSE on validation data on [5] steps: means over folds: *** 0.0611 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.06532 -0.05967 -0.0583 ]\n",
      "hyperband obj crossval results 0.0611\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.495817992217395, 'cols_bt': 0.23061156444509176, 'lr': 0.09241553780580979, 'n_estimators': 171, 'maxdepth': 7, 'subsample': 0.14650611279360481}\n",
      "MSE on validation data on [5] steps: means over folds: *** 0.0221 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.03018 -0.01989 -0.01623]\n",
      "hyperband obj crossval results 0.0221\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.7207615034783531, 'cols_bt': 0.7812935702980904, 'lr': 0.07416811991915133, 'n_estimators': 151, 'maxdepth': 4, 'subsample': 0.7113184460373105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data on [5] steps: means over folds: *** 0.01826 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.02461 -0.01537 -0.0148 ]\n",
      "hyperband obj crossval results 0.01826\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.31305732316547696, 'cols_bt': 0.6343377810392044, 'lr': 0.0012906266637879222, 'n_estimators': 192, 'maxdepth': 9, 'subsample': 0.7704980400242586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data on [5] steps: means over folds: *** 0.04739 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.0518  -0.04517 -0.0452 ]\n",
      "hyperband obj crossval results 0.04739\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.856382480028685, 'cols_bt': 0.3850090031280587, 'lr': 0.0012115364873114829, 'n_estimators': 49, 'maxdepth': 3, 'subsample': 0.5221361806440016}\n",
      "MSE on validation data on [5] steps: means over folds: *** 0.0611 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.06532 -0.05967 -0.0583 ]\n",
      "hyperband obj crossval results 0.0611\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.7589483101395147, 'cols_bt': 0.9768386904658107, 'lr': 0.7304905829910666, 'n_estimators': 182, 'maxdepth': 9, 'subsample': 0.3177857840924941}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "/home/jochen/tensorflow/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data on [5] steps: means over folds: *** 0.01885 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.02477 -0.01592 -0.01586]\n",
      "hyperband obj crossval results 0.01885\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.856382480028685, 'cols_bt': 0.3850090031280587, 'lr': 0.0012115364873114829, 'n_estimators': 49, 'maxdepth': 3, 'subsample': 0.5221361806440016}\n",
      "MSE on validation data on [5] steps: means over folds: *** 0.0611 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.06532 -0.05967 -0.0583 ]\n",
      "hyperband obj crossval results 0.0611\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'gamma': 0.7589483101395147, 'cols_bt': 0.9768386904658107, 'lr': 0.7304905829910666, 'n_estimators': 182, 'maxdepth': 9, 'subsample': 0.3177857840924941}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data on [5] steps: means over folds: *** 0.01885 ***\n",
      "Results validation data of all Folds: \n",
      "[-0.02477 -0.01592 -0.01586]\n",
      "hyperband obj crossval results 0.01885\n",
      "traj {'losses': [-0.00975, -0.04739, -0.0611], 'budgets': [10.0, 10.0, 10.0], 'config_ids': [(0, 0, 0), (0, 0, 1), (0, 0, 2)], 'time_finished': [0.1408522129058838, 0.5603299140930176, 0.603823184967041]}\n",
      "best_cfg_id (0, 0, 2)\n",
      "all_configs {(0, 0, 0): {'config_info': {}, 'config': {'gamma': 0.07063600373860912, 'cols_bt': 0.9217170129716793, 'lr': 0.1050934646426613, 'n_estimators': 279, 'maxdepth': 3, 'subsample': 0.34897607207545855}}, (0, 0, 2): {'config_info': {}, 'config': {'gamma': 0.856382480028685, 'cols_bt': 0.3850090031280587, 'lr': 0.0012115364873114829, 'n_estimators': 49, 'maxdepth': 3, 'subsample': 0.5221361806440016}}, (1, 0, 0): {'config_info': {}, 'config': {'gamma': 0.7207615034783531, 'cols_bt': 0.7812935702980904, 'lr': 0.07416811991915133, 'n_estimators': 151, 'maxdepth': 4, 'subsample': 0.7113184460373105}}, (0, 0, 1): {'config_info': {}, 'config': {'gamma': 0.31305732316547696, 'cols_bt': 0.6343377810392044, 'lr': 0.0012906266637879222, 'n_estimators': 192, 'maxdepth': 9, 'subsample': 0.7704980400242586}}, (0, 0, 3): {'config_info': {}, 'config': {'gamma': 0.495817992217395, 'cols_bt': 0.23061156444509176, 'lr': 0.09241553780580979, 'n_estimators': 171, 'maxdepth': 7, 'subsample': 0.14650611279360481}}, (1, 0, 1): {'config_info': {}, 'config': {'gamma': 0.7589483101395147, 'cols_bt': 0.9768386904658107, 'lr': 0.7304905829910666, 'n_estimators': 182, 'maxdepth': 9, 'subsample': 0.3177857840924941}}}\n",
      "return best config:  {'gamma': 0.856382480028685, 'cols_bt': 0.3850090031280587, 'lr': 0.0012115364873114829, 'n_estimators': 49, 'maxdepth': 3, 'subsample': 0.5221361806440016}\n"
     ]
    }
   ],
   "source": [
    "best_cfg = hp.optimize(configs,Y,model_type='xgb', min_budget = 10, max_budget=40, run_name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140187071411968\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.008436577394848653, 'batch_size': 19}\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.0015971832060604426, 'batch_size': 25}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 169us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 138us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 215us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.08455] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.10933]\n",
      " [ 0.07648]\n",
      " [ 0.06783]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.08455\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.37364476899503524, 'batch_size': 48}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 108us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 168us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 168us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02906] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04199]\n",
      " [ 0.02392]\n",
      " [ 0.02129]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02906\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.016073094701798084, 'batch_size': 19}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 193us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 191us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 167us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03437] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04792]\n",
      " [ 0.02945]\n",
      " [ 0.02575]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03437\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.009586457136379657, 'batch_size': 27}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 184us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 176us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 238us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03834] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.05514]\n",
      " [ 0.03206]\n",
      " [ 0.02784]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03834\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.06945643081756749, 'batch_size': 42}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 153us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 217us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 186us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03485] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04871]\n",
      " [ 0.02974]\n",
      " [ 0.02609]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03485\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07388122579837485, 'batch_size': 33}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 168us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 166us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 193us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03232] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04512]\n",
      " [ 0.02714]\n",
      " [ 0.02468]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03232\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.021337462797969355, 'batch_size': 40}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 110us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 141us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 299us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03407] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04797]\n",
      " [ 0.02893]\n",
      " [ 0.02531]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03407\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07769230011012973, 'batch_size': 41}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 175us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 463us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 98us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02954] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04222]\n",
      " [ 0.02424]\n",
      " [ 0.02215]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02954\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.021337462797969355, 'batch_size': 40}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 164us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 116us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 156us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03475] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04788]\n",
      " [ 0.02994]\n",
      " [ 0.02643]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03475\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.37364476899503524, 'batch_size': 48}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 116us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 142us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 115us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01829] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02596]\n",
      " [ 0.01484]\n",
      " [ 0.01408]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.01829\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07388122579837485, 'batch_size': 33}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 132us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 152us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 175us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03005] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0427 ]\n",
      " [ 0.02536]\n",
      " [ 0.0221 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03005\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.016073094701798084, 'batch_size': 19}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 143us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 144us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 179us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03387] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04688]\n",
      " [ 0.0292 ]\n",
      " [ 0.02552]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03387\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.0013227285301914478, 'batch_size': 23}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 180us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 149us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 174us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0697] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.09383]\n",
      " [ 0.06129]\n",
      " [ 0.05398]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.0697\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.37364476899503524, 'batch_size': 48}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 159us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 123us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 122us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00868] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00941]\n",
      " [ 0.00721]\n",
      " [ 0.00941]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.00868\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07388122579837485, 'batch_size': 33}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 142us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 150us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 149us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02134] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03079]\n",
      " [ 0.01677]\n",
      " [ 0.01646]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02134\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.04580026289754379, 'batch_size': 43}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 141us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 189us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 146us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0307] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0426 ]\n",
      " [ 0.02644]\n",
      " [ 0.02307]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.0307\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.37364476899503524, 'batch_size': 48}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 110us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 111us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 122us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00712] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00811]\n",
      " [ 0.007  ]\n",
      " [ 0.00624]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.00712\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.0013453747549283328, 'batch_size': 54}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 89us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 142us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 140us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.09446] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.12028]\n",
      " [ 0.08502]\n",
      " [ 0.07807]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.09446\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.164477508973482, 'batch_size': 30}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 167us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 136us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 146us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00976] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01218]\n",
      " [ 0.00842]\n",
      " [ 0.00868]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.00976\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07769230011012973, 'batch_size': 41}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 155us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 145us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 132us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02208] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03183]\n",
      " [ 0.01757]\n",
      " [ 0.01684]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02208\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.04580026289754379, 'batch_size': 43}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 126us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 180us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 155us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02839] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0411 ]\n",
      " [ 0.02349]\n",
      " [ 0.02059]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02839\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07673276670965525, 'batch_size': 62}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 100us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 124us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 89us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03028] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04305]\n",
      " [ 0.02544]\n",
      " [ 0.02235]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.03028\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07769230011012973, 'batch_size': 41}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 161us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 194us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 137us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01432] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02139]\n",
      " [ 0.01098]\n",
      " [ 0.0106 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.01432\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.0015944533862384857, 'batch_size': 42}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 184us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 160us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 130us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.05398] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.07588]\n",
      " [ 0.046  ]\n",
      " [ 0.04005]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.05398\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.002410925627224085, 'batch_size': 52}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 278us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 128us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 190us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.04653] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.06616]\n",
      " [ 0.03931]\n",
      " [ 0.03413]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.04653\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.164477508973482, 'batch_size': 30}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 122us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 118us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 181us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00712] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00846]\n",
      " [ 0.00592]\n",
      " [ 0.00698]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.00712\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.07673276670965525, 'batch_size': 62}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "89/89 [==============================] - 0s 329us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 246us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "88/88 [==============================] - 0s 218us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02235] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03238]\n",
      " [ 0.01768]\n",
      " [ 0.01699]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n",
      "hyperband obj crossval results 0.02235\n",
      "traj {'time_finished': [2.2007694244384766, 3.744567394256592, 21.17214035987854, 31.383424997329712, 38.972952127456665], 'budgets': [12.5, 12.5, 25.0, 50.0, 100.0], 'losses': [0.08455, 0.02906, 0.01829, 0.00868, 0.00712], 'config_ids': [(0, 0, 1), (0, 0, 2), (0, 0, 2), (0, 0, 2), (0, 0, 2)]}\n",
      "best_cfg_id (0, 0, 2)\n",
      "all_configs {(1, 0, 3): {'config': {'lr': 0.0013453747549283328, 'batch_size': 54}, 'config_info': {}}, (0, 0, 7): {'config': {'lr': 0.021337462797969355, 'batch_size': 40}, 'config_info': {}}, (2, 0, 3): {'config': {'lr': 0.002410925627224085, 'batch_size': 52}, 'config_info': {}}, (0, 0, 2): {'config': {'lr': 0.37364476899503524, 'batch_size': 48}, 'config_info': {}}, (1, 0, 0): {'config': {'lr': 0.07769230011012973, 'batch_size': 41}, 'config_info': {}}, (0, 0, 6): {'config': {'lr': 0.07388122579837485, 'batch_size': 33}, 'config_info': {}}, (2, 0, 2): {'config': {'lr': 0.0015944533862384857, 'batch_size': 42}, 'config_info': {}}, (0, 0, 1): {'config': {'lr': 0.0015971832060604426, 'batch_size': 25}, 'config_info': {}}, (1, 0, 1): {'config': {'lr': 0.0013227285301914478, 'batch_size': 23}, 'config_info': {}}, (0, 0, 5): {'config': {'lr': 0.06945643081756749, 'batch_size': 42}, 'config_info': {}}, (0, 0, 0): {'config': {'lr': 0.008436577394848653, 'batch_size': 19}, 'config_info': {}}, (2, 0, 1): {'config': {'lr': 0.07673276670965525, 'batch_size': 62}, 'config_info': {}}, (0, 0, 4): {'config': {'lr': 0.009586457136379657, 'batch_size': 27}, 'config_info': {}}, (1, 0, 2): {'config': {'lr': 0.04580026289754379, 'batch_size': 43}, 'config_info': {}}, (2, 0, 0): {'config': {'lr': 0.164477508973482, 'batch_size': 30}, 'config_info': {}}, (0, 0, 3): {'config': {'lr': 0.016073094701798084, 'batch_size': 19}, 'config_info': {}}}\n",
      "return best config:  {'lr': 0.37364476899503524, 'batch_size': 48}\n"
     ]
    }
   ],
   "source": [
    "best_cfg = hp.optimize(configs,Y,model_type='mlp', min_budget = 10, max_budget=100, \n",
    "                       run_name='', earlystop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'lr': 0.37364476899503524, 'batch_size': 48}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05283, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05283 to 0.04822, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04822 to 0.04465, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.04470, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04465 to 0.04354, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04354 to 0.04342, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 0.04631, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04342 to 0.04184, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04184 to 0.03921, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.04097, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03921 to 0.03690, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03690 to 0.03614, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03614 to 0.03320, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03320 to 0.03232, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03232 to 0.03137, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03137 to 0.02900, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.03021, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02900 to 0.02758, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02758 to 0.02378, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02378 to 0.02372, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02372 to 0.02174, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02174 to 0.02093, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02093 to 0.01898, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01898 to 0.01830, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.02128, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01830 to 0.01674, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01674 to 0.01596, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.01726, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01596 to 0.01556, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss is 0.01675, did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.01556 to 0.01350, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.01493, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01350 to 0.01340, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01340 to 0.01316, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01316 to 0.01282, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss is 0.01392, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.01335, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01282 to 0.01170, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01170 to 0.01109, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss is 0.01383, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.01208, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.01155, did not improve\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01109 to 0.00966, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss is 0.01021, did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00966 to 0.00964, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss is 0.00969, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.01048, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00964 to 0.00926, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00926 to 0.00921, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss is 0.01064, did not improve\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00921 to 0.00887, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00887 to 0.00854, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00944, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00854 to 0.00832, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.01001, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.01047, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00989, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00857, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00832 to 0.00812, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00862, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00862, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00812 to 0.00790, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00790 to 0.00775, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00804, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00856, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00835, did not improve\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00775 to 0.00770, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00829, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00792, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00770 to 0.00767, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss is 0.00903, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00793, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00767 to 0.00758, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss is 0.00767, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00793, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00952, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00893, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00829, did not improve\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00758 to 0.00753, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00753 to 0.00753, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss is 0.00776, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00941, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00813, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00949, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00865, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00753 to 0.00753, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00890, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00851, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00772, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00753 to 0.00751, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00987, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00810, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00822, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00836, did not improve\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00751 to 0.00745, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00745 to 0.00742, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00139: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00742 to 0.00741, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00940, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00815, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00741 to 0.00740, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss is 0.00751, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00740 to 0.00733, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00733 to 0.00733, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.00733 to 0.00732, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00732 to 0.00728, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00885, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00754, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.01038, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00737, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00762, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.01099, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00804, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00796, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.01269, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00764, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00831, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00728 to 0.00727, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00727 to 0.00724, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00988, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00791, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00746, did not improve\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00724 to 0.00719, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00719 to 0.00715, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00715 to 0.00709, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00709 to 0.00709, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00742, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00721, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00869, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00841, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00726, did not improve\n",
      "\n",
      "Epoch 00247: val_loss is 0.00935, did not improve\n",
      "\n",
      "Epoch 00248: val_loss is 0.00823, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00953, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.00709 to 0.00700, storing weights.\n",
      "\n",
      "Epoch 00256: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.00700 to 0.00699, storing weights.\n",
      "\n",
      "Epoch 00269: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.00699 to 0.00699, storing weights.\n",
      "\n",
      "Epoch 00279: val_loss is 0.00771, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00759, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00780, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.01133, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.00699 to 0.00696, storing weights.\n",
      "\n",
      "Epoch 00294: val_loss is 0.00703, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00295: val_loss is 0.00723, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00733, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.00696 to 0.00695, storing weights.\n",
      "\n",
      "Epoch 00299: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.00695 to 0.00689, storing weights.\n",
      "\n",
      "Epoch 00302: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00773, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00911, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00766, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00895, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00858, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.00689 to 0.00689, storing weights.\n",
      "\n",
      "Epoch 00322: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00323: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00324: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00325: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00326: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00327: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00328: val_loss is 0.00755, did not improve\n",
      "\n",
      "Epoch 00329: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00330: val_loss is 0.00725, did not improve\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.00689 to 0.00680, storing weights.\n",
      "\n",
      "Epoch 00332: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00333: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00334: val_loss is 0.00774, did not improve\n",
      "\n",
      "Epoch 00335: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00336: val_loss is 0.00756, did not improve\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.00680 to 0.00679, storing weights.\n",
      "\n",
      "Epoch 00338: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00339: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00340: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00341: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00342: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00343: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00344: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00345: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00346: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00347: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00348: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00349: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00350: val_loss is 0.00921, did not improve\n",
      "\n",
      "Epoch 00351: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00352: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00353: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00354: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00355: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00356: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00357: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00358: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00359: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00360: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00361: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00362: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00363: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00364: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00365: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00366: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00367: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00368: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00369: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00370: val_loss is 0.00858, did not improve\n",
      "\n",
      "Epoch 00371: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.00679 to 0.00679, storing weights.\n",
      "\n",
      "Epoch 00373: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00374: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00375: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00376: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00377: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00378: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.00679 to 0.00669, storing weights.\n",
      "\n",
      "Epoch 00380: val_loss is 0.00689, did not improve\n",
      "\n",
      "Epoch 00381: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00382: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00383: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00674, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00757, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00678, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00825, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00706, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00707, did not improve\n",
      "\n",
      "Epoch 00405: val_loss is 0.00722, did not improve\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.00669 to 0.00666, storing weights.\n",
      "\n",
      "Epoch 00407: val_loss is 0.00775, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.00666 to 0.00664, storing weights.\n",
      "\n",
      "Epoch 00413: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00417: val_loss improved from 0.00664 to 0.00658, storing weights.\n",
      "\n",
      "Epoch 00418: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00423: val_loss improved from 0.00658 to 0.00657, storing weights.\n",
      "\n",
      "Epoch 00424: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00669, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.00657 to 0.00652, storing weights.\n",
      "\n",
      "Epoch 00428: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.00652 to 0.00647, storing weights.\n",
      "\n",
      "Epoch 00431: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.00647 to 0.00645, storing weights.\n",
      "\n",
      "Epoch 00433: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00434: val_loss is 0.00720, did not improve\n",
      "\n",
      "Epoch 00435: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00436: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00437: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00438: val_loss is 0.00681, did not improve\n",
      "\n",
      "Epoch 00439: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00440: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00441: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00442: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00443: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00444: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00445: val_loss is 0.00838, did not improve\n",
      "\n",
      "Epoch 00446: val_loss improved from 0.00645 to 0.00642, storing weights.\n",
      "\n",
      "Epoch 00447: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00448: val_loss improved from 0.00642 to 0.00638, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00449: val_loss is 0.00826, did not improve\n",
      "\n",
      "Epoch 00450: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00451: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00452: val_loss is 0.00788, did not improve\n",
      "\n",
      "Epoch 00453: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00454: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00455: val_loss is 0.00682, did not improve\n",
      "\n",
      "Epoch 00456: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00457: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00458: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00459: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00460: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00461: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00462: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00463: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00464: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00465: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00466: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00467: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00468: val_loss is 0.00665, did not improve\n",
      "\n",
      "Epoch 00469: val_loss is 0.00881, did not improve\n",
      "\n",
      "Epoch 00470: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00471: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00472: val_loss is 0.00699, did not improve\n",
      "\n",
      "Epoch 00473: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00474: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00475: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00476: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00477: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00478: val_loss is 0.00743, did not improve\n",
      "\n",
      "Epoch 00479: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00480: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00481: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00482: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00483: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00484: val_loss is 0.00691, did not improve\n",
      "\n",
      "Epoch 00485: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00486: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00487: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00488: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00489: val_loss improved from 0.00638 to 0.00634, storing weights.\n",
      "\n",
      "Epoch 00490: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00491: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00492: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00493: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00494: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00495: val_loss is 0.00758, did not improve\n",
      "\n",
      "Epoch 00496: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00497: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00498: val_loss is 0.00752, did not improve\n",
      "\n",
      "Epoch 00499: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00500: val_loss is 0.00685, did not improve\n",
      "\n",
      "Epoch 00501: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00502: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00503: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00504: val_loss improved from 0.00634 to 0.00624, storing weights.\n",
      "\n",
      "Epoch 00505: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00506: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00507: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00508: val_loss is 0.00750, did not improve\n",
      "\n",
      "Epoch 00509: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00510: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00511: val_loss is 0.00675, did not improve\n",
      "\n",
      "Epoch 00512: val_loss is 0.00625, did not improve\n",
      "\n",
      "Epoch 00513: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00514: val_loss improved from 0.00624 to 0.00623, storing weights.\n",
      "\n",
      "Epoch 00515: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00516: val_loss is 0.00705, did not improve\n",
      "\n",
      "Epoch 00517: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00518: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00519: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00520: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00521: val_loss is 0.00664, did not improve\n",
      "\n",
      "Epoch 00522: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00523: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00524: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00525: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00526: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00527: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00528: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00529: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00530: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00531: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00532: val_loss is 0.00714, did not improve\n",
      "\n",
      "Epoch 00533: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00534: val_loss is 0.00710, did not improve\n",
      "\n",
      "Epoch 00535: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00536: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00537: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00538: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00539: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00540: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00541: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00542: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00543: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00544: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00545: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00546: val_loss is 0.00635, did not improve\n",
      "\n",
      "Epoch 00547: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00548: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00549: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00550: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00551: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00552: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00553: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00554: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00555: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00556: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00557: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00558: val_loss is 0.00680, did not improve\n",
      "\n",
      "Epoch 00559: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00560: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00561: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00562: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00563: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00564: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00565: val_loss is 0.00626, did not improve\n",
      "\n",
      "Epoch 00566: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00567: val_loss is 0.00694, did not improve\n",
      "\n",
      "Epoch 00568: val_loss improved from 0.00623 to 0.00620, storing weights.\n",
      "\n",
      "Epoch 00569: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00570: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00571: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00572: val_loss improved from 0.00620 to 0.00618, storing weights.\n",
      "\n",
      "Epoch 00573: val_loss improved from 0.00618 to 0.00617, storing weights.\n",
      "\n",
      "Epoch 00574: val_loss is 0.00629, did not improve\n",
      "\n",
      "Epoch 00575: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00576: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00577: val_loss is 0.00837, did not improve\n",
      "\n",
      "Epoch 00578: val_loss is 0.00638, did not improve\n",
      "\n",
      "Epoch 00579: val_loss is 0.00656, did not improve\n",
      "\n",
      "Epoch 00580: val_loss is 0.00647, did not improve\n",
      "\n",
      "Epoch 00581: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00582: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00583: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00584: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00585: val_loss is 0.00728, did not improve\n",
      "\n",
      "Epoch 00586: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00587: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00588: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00589: val_loss is 0.00713, did not improve\n",
      "Epoch 00589: early stopping\n",
      "Using epoch 00573 with val_loss: 0.00617\n",
      "89/89 [==============================] - 0s 147us/step\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03010, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.03055, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03010 to 0.02792, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02792 to 0.02726, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.02965, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02726 to 0.02655, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02655 to 0.02478, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02478 to 0.02292, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02292 to 0.02190, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02190 to 0.02047, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02047 to 0.02037, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss improved from 0.02037 to 0.01899, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01899 to 0.01775, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01775 to 0.01697, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01697 to 0.01573, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.01636, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01573 to 0.01439, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.01468, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01439 to 0.01316, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.01386, did not improve\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01316 to 0.01254, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01254 to 0.01225, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01225 to 0.01106, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01106 to 0.01068, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01068 to 0.01052, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01052 to 0.01034, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01034 to 0.00997, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00997 to 0.00945, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00945 to 0.00922, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00922 to 0.00892, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00892 to 0.00824, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00824 to 0.00786, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00789, did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00786 to 0.00732, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00732 to 0.00731, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00731 to 0.00727, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00731, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00727 to 0.00697, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00979, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00697 to 0.00668, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00712, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00668 to 0.00634, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss is 0.01095, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00634 to 0.00626, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00695, did not improve\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00626 to 0.00612, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00612 to 0.00589, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.01025, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00747, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00679, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00954, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00592, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00589 to 0.00582, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00606, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00582 to 0.00569, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00623, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00608, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00612, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00655, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00700, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00569 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00556 to 0.00551, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00570, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00551 to 0.00549, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00806, did not improve\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00549 to 0.00547, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss is 0.00811, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00637, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00547 to 0.00539, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00579, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00653, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00539 to 0.00539, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00558, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00595, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00768, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00583, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00580, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00560, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00556, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00651, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00553, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00631, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00821, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00844, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00540, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00548, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00634, did not improve\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00539 to 0.00533, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00692, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00538, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00169: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00632, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00547, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00781, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00578, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.01005, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00565, did not improve\n",
      "Epoch 00179: early stopping\n",
      "Using epoch 00164 with val_loss: 0.00533\n",
      "88/88 [==============================] - 0s 133us/step\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02599, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02599 to 0.02511, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 0.02629, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 0.02653, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02511 to 0.02334, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02334 to 0.02258, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02258 to 0.02167, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02167 to 0.02067, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02067 to 0.01985, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01985 to 0.01933, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01933 to 0.01810, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01810 to 0.01763, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01763 to 0.01690, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.01720, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01690 to 0.01602, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.01670, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01602 to 0.01461, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01461 to 0.01421, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.01462, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01421 to 0.01341, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01341 to 0.01294, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01294 to 0.01205, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01205 to 0.01202, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01202 to 0.01154, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss is 0.01522, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01154 to 0.01115, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01115 to 0.01074, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss is 0.01362, did not improve\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01074 to 0.01013, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01013 to 0.00966, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.01408, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.01051, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00966 to 0.00914, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00914 to 0.00879, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00879 to 0.00853, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00898, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00853 to 0.00821, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00924, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00856, did not improve\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00821 to 0.00762, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss is 0.00960, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00945, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00926, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00782, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00797, did not improve\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00762 to 0.00724, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss is 0.00871, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00748, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00816, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00763, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00761, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00913, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.01037, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00855, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00939, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00860, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00736, did not improve\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00724 to 0.00684, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00845, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00701, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00995, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00913, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00784, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.01107, did not improve\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00684 to 0.00680, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss is 0.00741, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00680 to 0.00661, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss is 0.00713, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.01168, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00790, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00807, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00715, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00711, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00778, did not improve\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00661 to 0.00655, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss is 0.00666, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00849, did not improve\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00655 to 0.00642, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.01441, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.01015, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00779, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00819, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00745, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.01430, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.01199, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00868, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00828, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00830, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00648, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00985, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00663, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00683, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00642 to 0.00636, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss is 0.00973, did not improve\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00636 to 0.00618, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00661, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00730, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00704, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00734, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00618 to 0.00609, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss is 0.00800, did not improve\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00609 to 0.00600, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00614, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.01702, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00600 to 0.00599, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00609, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00804, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00611, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00650, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00794, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00132: val_loss improved from 0.00599 to 0.00558, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss is 0.00633, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00686, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00841, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00619, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00645, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00597, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00709, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00558 to 0.00556, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00610, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00556 to 0.00548, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss is 0.00738, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00552, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00853, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00568, did not improve\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00548 to 0.00534, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00644, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00886, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00740, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00880, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00673, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00684, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00660, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00575, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00571, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00587, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00719, did not improve\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00534 to 0.00517, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00591, did not improve\n",
      "\n",
      "Epoch 00185: val_loss is 0.00716, did not improve\n",
      "\n",
      "Epoch 00186: val_loss is 0.00877, did not improve\n",
      "\n",
      "Epoch 00187: val_loss is 0.00798, did not improve\n",
      "\n",
      "Epoch 00188: val_loss is 0.00910, did not improve\n",
      "\n",
      "Epoch 00189: val_loss is 0.00760, did not improve\n",
      "\n",
      "Epoch 00190: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00191: val_loss is 0.00794, did not improve\n",
      "\n",
      "Epoch 00192: val_loss is 0.00641, did not improve\n",
      "\n",
      "Epoch 00193: val_loss is 0.00642, did not improve\n",
      "\n",
      "Epoch 00194: val_loss is 0.00708, did not improve\n",
      "\n",
      "Epoch 00195: val_loss is 0.00573, did not improve\n",
      "\n",
      "Epoch 00196: val_loss is 0.00809, did not improve\n",
      "\n",
      "Epoch 00197: val_loss is 0.00732, did not improve\n",
      "\n",
      "Epoch 00198: val_loss is 0.00967, did not improve\n",
      "\n",
      "Epoch 00199: val_loss is 0.00698, did not improve\n",
      "\n",
      "Epoch 00200: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00201: val_loss is 0.00727, did not improve\n",
      "\n",
      "Epoch 00202: val_loss is 0.00589, did not improve\n",
      "\n",
      "Epoch 00203: val_loss is 0.00785, did not improve\n",
      "\n",
      "Epoch 00204: val_loss is 0.00603, did not improve\n",
      "\n",
      "Epoch 00205: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00206: val_loss is 0.00598, did not improve\n",
      "\n",
      "Epoch 00207: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00208: val_loss is 0.00662, did not improve\n",
      "\n",
      "Epoch 00209: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00210: val_loss is 0.00572, did not improve\n",
      "\n",
      "Epoch 00211: val_loss is 0.00658, did not improve\n",
      "\n",
      "Epoch 00212: val_loss is 0.00627, did not improve\n",
      "\n",
      "Epoch 00213: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00214: val_loss is 0.00690, did not improve\n",
      "\n",
      "Epoch 00215: val_loss is 0.00519, did not improve\n",
      "\n",
      "Epoch 00216: val_loss is 0.00729, did not improve\n",
      "\n",
      "Epoch 00217: val_loss is 0.00667, did not improve\n",
      "\n",
      "Epoch 00218: val_loss is 0.00649, did not improve\n",
      "\n",
      "Epoch 00219: val_loss is 0.00839, did not improve\n",
      "\n",
      "Epoch 00220: val_loss is 0.00676, did not improve\n",
      "\n",
      "Epoch 00221: val_loss is 0.00799, did not improve\n",
      "\n",
      "Epoch 00222: val_loss is 0.00539, did not improve\n",
      "\n",
      "Epoch 00223: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00224: val_loss is 0.00615, did not improve\n",
      "\n",
      "Epoch 00225: val_loss is 0.00820, did not improve\n",
      "\n",
      "Epoch 00226: val_loss is 0.00657, did not improve\n",
      "\n",
      "Epoch 00227: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00228: val_loss is 0.00780, did not improve\n",
      "\n",
      "Epoch 00229: val_loss is 0.00677, did not improve\n",
      "\n",
      "Epoch 00230: val_loss is 0.00687, did not improve\n",
      "\n",
      "Epoch 00231: val_loss is 0.00565, did not improve\n",
      "\n",
      "Epoch 00232: val_loss is 0.00717, did not improve\n",
      "\n",
      "Epoch 00233: val_loss is 0.00992, did not improve\n",
      "\n",
      "Epoch 00234: val_loss is 0.00787, did not improve\n",
      "\n",
      "Epoch 00235: val_loss is 0.00542, did not improve\n",
      "\n",
      "Epoch 00236: val_loss is 0.00541, did not improve\n",
      "\n",
      "Epoch 00237: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00238: val_loss is 0.00693, did not improve\n",
      "\n",
      "Epoch 00239: val_loss is 0.00584, did not improve\n",
      "\n",
      "Epoch 00240: val_loss is 0.00724, did not improve\n",
      "\n",
      "Epoch 00241: val_loss is 0.00703, did not improve\n",
      "\n",
      "Epoch 00242: val_loss is 0.00744, did not improve\n",
      "\n",
      "Epoch 00243: val_loss is 0.00607, did not improve\n",
      "\n",
      "Epoch 00244: val_loss is 0.00753, did not improve\n",
      "\n",
      "Epoch 00245: val_loss is 0.00643, did not improve\n",
      "\n",
      "Epoch 00246: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00517 to 0.00492, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss is 0.00718, did not improve\n",
      "\n",
      "Epoch 00249: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00250: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00545, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00546, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00621, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00812, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00659, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00636, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00834, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00576, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00564, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00616, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00555, did not improve\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.00492 to 0.00490, storing weights.\n",
      "\n",
      "Epoch 00263: val_loss is 0.00562, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00596, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00858, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00599, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00961, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00846, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00550, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00557, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00735, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00696, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00544, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00500, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00508, did not improve\n",
      "\n",
      "Epoch 00279: val_loss is 0.00668, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00702, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00620, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00613, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00770, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00551, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00554, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00618, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00588, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00739, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00574, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00585, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00543, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00529, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00652, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00600, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00511, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00516, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00658, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00298: val_loss is 0.00582, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00639, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00630, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00525, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00569, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00527, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00590, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00988, did not improve\n",
      "\n",
      "Epoch 00306: val_loss is 0.00496, did not improve\n",
      "\n",
      "Epoch 00307: val_loss is 0.00986, did not improve\n",
      "\n",
      "Epoch 00308: val_loss is 0.00955, did not improve\n",
      "\n",
      "Epoch 00309: val_loss is 0.00561, did not improve\n",
      "\n",
      "Epoch 00310: val_loss is 0.00605, did not improve\n",
      "\n",
      "Epoch 00311: val_loss is 0.00531, did not improve\n",
      "\n",
      "Epoch 00312: val_loss is 0.00594, did not improve\n",
      "\n",
      "Epoch 00313: val_loss is 0.00624, did not improve\n",
      "\n",
      "Epoch 00314: val_loss is 0.00646, did not improve\n",
      "\n",
      "Epoch 00315: val_loss is 0.00559, did not improve\n",
      "\n",
      "Epoch 00316: val_loss is 0.00688, did not improve\n",
      "\n",
      "Epoch 00317: val_loss is 0.00640, did not improve\n",
      "\n",
      "Epoch 00318: val_loss is 0.00697, did not improve\n",
      "\n",
      "Epoch 00319: val_loss is 0.00566, did not improve\n",
      "\n",
      "Epoch 00320: val_loss is 0.00769, did not improve\n",
      "\n",
      "Epoch 00321: val_loss is 0.00563, did not improve\n",
      "\n",
      "Epoch 00322: val_loss is 0.00578, did not improve\n",
      "Epoch 00322: early stopping\n",
      "Using epoch 00262 with val_loss: 0.00490\n",
      "88/88 [==============================] - 0s 154us/step\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00547] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00617]\n",
      " [ 0.00533]\n",
      " [ 0.0049 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [] ***\n",
      "Results training data of all Folds: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# best solution for MLP\n",
    "best_config = {'lr': 0.37364476899503524, 'batch_size': 48}\n",
    "results = m.eval_cv('mlp', configs, Y, cfg=best_cfg, epochs=1000, splits = 3, earlystop=True, \n",
    "                    dropout=False, lr_exp_decay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139639964378880\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 30, 'lr': 0.05958020697008728, 'l2': 0.00012441938511358324, 'l1': 0.0010959499184547534}\n",
      "create mlp using L1L2 regularisation\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.12169705572542237, 'l2': 0.002212816444365411, 'l1': 0.0003982270934210315}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0283] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04038]\n",
      " [ 0.02392]\n",
      " [ 0.0206 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02514] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02384]\n",
      " [ 0.02672]\n",
      " [ 0.02486]]\n",
      "hyperband obj crossval results 0.0283\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 19, 'lr': 0.05982392470292955, 'l2': 0.0035279467257703485, 'l1': 0.000599326734940943}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03408] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04816]\n",
      " [ 0.02858]\n",
      " [ 0.02548]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03285] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02735]\n",
      " [ 0.03488]\n",
      " [ 0.03633]]\n",
      "hyperband obj crossval results 0.03408\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.15506329149467196, 'l2': 0.00012810555119458335, 'l1': 0.0021306501327552265}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03306] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0468 ]\n",
      " [ 0.02793]\n",
      " [ 0.02445]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03256] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02721]\n",
      " [ 0.0342 ]\n",
      " [ 0.03628]]\n",
      "hyperband obj crossval results 0.03306\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.05782109870299804, 'l2': 0.0023711269546917556, 'l1': 0.001003613674878896}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03322] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04637]\n",
      " [ 0.02843]\n",
      " [ 0.02487]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03257] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02728]\n",
      " [ 0.03458]\n",
      " [ 0.03585]]\n",
      "hyperband obj crossval results 0.03322\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.1327865384217142, 'l2': 0.00015323570193598286, 'l1': 0.0009965813801526037}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03233] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04368]\n",
      " [ 0.02953]\n",
      " [ 0.02378]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03104] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02667]\n",
      " [ 0.03428]\n",
      " [ 0.03216]]\n",
      "hyperband obj crossval results 0.03233\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.08263898892757952, 'l2': 0.00016048093286362305, 'l1': 0.001139678041440414}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03315] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04689]\n",
      " [ 0.02798]\n",
      " [ 0.02458]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03212] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.0267 ]\n",
      " [ 0.03415]\n",
      " [ 0.03552]]\n",
      "hyperband obj crossval results 0.03315\n",
      "cross validate 12 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 27, 'lr': 0.08456542078923197, 'l2': 0.00046986297806195807, 'l1': 0.0022887938499136415}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.034] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04703]\n",
      " [ 0.0295 ]\n",
      " [ 0.02548]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03349] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02753]\n",
      " [ 0.03564]\n",
      " [ 0.03729]]\n",
      "hyperband obj crossval results 0.034\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 30, 'lr': 0.0810961569129174, 'l2': 0.00018096665106352795, 'l1': 0.0017700232139460103}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03147] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04471]\n",
      " [ 0.0264 ]\n",
      " [ 0.0233 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03007] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02607]\n",
      " [ 0.03159]\n",
      " [ 0.03254]]\n",
      "hyperband obj crossval results 0.03147\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.1327865384217142, 'l2': 0.00015323570193598286, 'l1': 0.0009965813801526037}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02576] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0388 ]\n",
      " [ 0.01976]\n",
      " [ 0.01873]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02189] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02362]\n",
      " [ 0.02112]\n",
      " [ 0.02093]]\n",
      "hyperband obj crossval results 0.02576\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.08263898892757952, 'l2': 0.00016048093286362305, 'l1': 0.001139678041440414}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02796] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04167]\n",
      " [ 0.02221]\n",
      " [ 0.02001]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02512] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02429]\n",
      " [ 0.02589]\n",
      " [ 0.02517]]\n",
      "hyperband obj crossval results 0.02796\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.12169705572542237, 'l2': 0.002212816444365411, 'l1': 0.0003982270934210315}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02099] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.03013]\n",
      " [ 0.01709]\n",
      " [ 0.01576]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.01721] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01898]\n",
      " [ 0.01703]\n",
      " [ 0.01562]]\n",
      "hyperband obj crossval results 0.02099\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.15506329149467196, 'l2': 0.00012810555119458335, 'l1': 0.0021306501327552265}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02784] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04454]\n",
      " [ 0.01868]\n",
      " [ 0.02031]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.0232] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02624]\n",
      " [ 0.0218 ]\n",
      " [ 0.02154]]\n",
      "hyperband obj crossval results 0.02784\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.14261112072023766, 'l2': 0.0011797921871477292, 'l1': 0.0017107551612273232}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02776] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04287]\n",
      " [ 0.02069]\n",
      " [ 0.01971]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02463] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02577]\n",
      " [ 0.02562]\n",
      " [ 0.0225 ]]\n",
      "hyperband obj crossval results 0.02776\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.1327865384217142, 'l2': 0.00015323570193598286, 'l1': 0.0009965813801526037}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01785] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02822]\n",
      " [ 0.0116 ]\n",
      " [ 0.01372]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.01427] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01813]\n",
      " [ 0.01192]\n",
      " [ 0.01274]]\n",
      "hyperband obj crossval results 0.01785\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.12169705572542237, 'l2': 0.002212816444365411, 'l1': 0.0003982270934210315}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01044] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01458]\n",
      " [ 0.00804]\n",
      " [ 0.00869]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.00851] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00939]\n",
      " [ 0.00818]\n",
      " [ 0.00794]]\n",
      "hyperband obj crossval results 0.01044\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.026071750020129045, 'l2': 0.0001408448332681315, 'l1': 0.0003860780520028507}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03257] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04531]\n",
      " [ 0.02806]\n",
      " [ 0.02435]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03181] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02647]\n",
      " [ 0.03368]\n",
      " [ 0.03528]]\n",
      "hyperband obj crossval results 0.03257\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.12169705572542237, 'l2': 0.002212816444365411, 'l1': 0.0003982270934210315}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0093] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01171]\n",
      " [ 0.00781]\n",
      " [ 0.00837]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.00723] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00752]\n",
      " [ 0.00776]\n",
      " [ 0.00641]]\n",
      "hyperband obj crossval results 0.0093\n",
      "cross validate 25 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 27, 'lr': 0.05899350466011258, 'l2': 0.0029782618629786476, 'l1': 0.001283047465048529}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03304] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04585]\n",
      " [ 0.02838]\n",
      " [ 0.02489]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03202] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02692]\n",
      " [ 0.03408]\n",
      " [ 0.03508]]\n",
      "hyperband obj crossval results 0.03304\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.02153014369878981, 'l2': 0.0010743591528754566, 'l1': 0.0011507205935786594}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03252] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04585]\n",
      " [ 0.02745]\n",
      " [ 0.02426]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03147] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02674]\n",
      " [ 0.03322]\n",
      " [ 0.03446]]\n",
      "hyperband obj crossval results 0.03252\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 30, 'lr': 0.0810961569129174, 'l2': 0.00018096665106352795, 'l1': 0.0017700232139460103}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.02784] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04247]\n",
      " [ 0.02155]\n",
      " [ 0.01952]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02452] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02496]\n",
      " [ 0.02532]\n",
      " [ 0.0233 ]]\n",
      "hyperband obj crossval results 0.02784\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.14261112072023766, 'l2': 0.0011797921871477292, 'l1': 0.0017107551612273232}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0264] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0488 ]\n",
      " [ 0.01395]\n",
      " [ 0.01645]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.0193] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.0285 ]\n",
      " [ 0.01448]\n",
      " [ 0.01492]]\n",
      "hyperband obj crossval results 0.0264\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 32, 'lr': 0.17860301697331735, 'l2': 0.0023637164687333153, 'l1': 0.00171003574458352}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.0312] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04851]\n",
      " [ 0.02492]\n",
      " [ 0.02016]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.02561] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02845]\n",
      " [ 0.02678]\n",
      " [ 0.02161]]\n",
      "hyperband obj crossval results 0.0312\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.14261112072023766, 'l2': 0.0011797921871477292, 'l1': 0.0017107551612273232}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01633] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.01849]\n",
      " [ 0.00755]\n",
      " [ 0.02295]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.01757] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01465]\n",
      " [ 0.00937]\n",
      " [ 0.02869]]\n",
      "hyperband obj crossval results 0.01633\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00989] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.0129 ]\n",
      " [ 0.00807]\n",
      " [ 0.00871]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.0076] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00845]\n",
      " [ 0.00759]\n",
      " [ 0.00676]]\n",
      "hyperband obj crossval results 0.00989\n",
      "cross validate 50 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 29, 'lr': 0.08513416180024498, 'l2': 0.0022384130227352055, 'l1': 0.0027488065028525646}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.03834] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04963]\n",
      " [ 0.03753]\n",
      " [ 0.02785]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.03648] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02869]\n",
      " [ 0.04216]\n",
      " [ 0.03859]]\n",
      "hyperband obj crossval results 0.03834\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.00746] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.00891]\n",
      " [ 0.0066 ]\n",
      " [ 0.00687]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.00542] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.00572]\n",
      " [ 0.00564]\n",
      " [ 0.0049 ]]\n",
      "hyperband obj crossval results 0.00746\n",
      "cross validate 100 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 32, 'lr': 0.17860301697331735, 'l2': 0.0023637164687333153, 'l1': 0.00171003574458352}\n",
      "create mlp using L1L2 regularisation\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.01425] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.02365]\n",
      " [ 0.00897]\n",
      " [ 0.01013]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.01207] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.01722]\n",
      " [ 0.01023]\n",
      " [ 0.00875]]\n",
      "hyperband obj crossval results 0.01425\n",
      "traj {'time_finished': [1.991438388824463, 12.025814056396484, 15.350425481796265, 20.988491535186768, 23.55812168121338, 32.916274309158325, 61.148550033569336], 'losses': [0.0283, 0.02576, 0.02099, 0.01785, 0.01044, 0.0093, 0.00746], 'budgets': [12.5, 25.0, 25.0, 50.0, 50.0, 100.0, 100.0], 'config_ids': [(0, 0, 1), (0, 0, 5), (0, 0, 1), (0, 0, 5), (0, 0, 1), (0, 0, 1), (2, 0, 2)]}\n",
      "best_cfg_id (2, 0, 2)\n",
      "all_configs {(1, 0, 3): {'config_info': {}, 'config': {'batch_size': 27, 'lr': 0.05899350466011258, 'l2': 0.0029782618629786476, 'l1': 0.001283047465048529}}, (0, 0, 7): {'config_info': {}, 'config': {'batch_size': 27, 'lr': 0.08456542078923197, 'l2': 0.00046986297806195807, 'l1': 0.0022887938499136415}}, (2, 0, 3): {'config_info': {}, 'config': {'batch_size': 29, 'lr': 0.08513416180024498, 'l2': 0.0022384130227352055, 'l1': 0.0027488065028525646}}, (0, 0, 2): {'config_info': {}, 'config': {'batch_size': 19, 'lr': 0.05982392470292955, 'l2': 0.0035279467257703485, 'l1': 0.000599326734940943}}, (1, 0, 0): {'config_info': {}, 'config': {'batch_size': 30, 'lr': 0.0810961569129174, 'l2': 0.00018096665106352795, 'l1': 0.0017700232139460103}}, (0, 0, 6): {'config_info': {}, 'config': {'batch_size': 17, 'lr': 0.08263898892757952, 'l2': 0.00016048093286362305, 'l1': 0.001139678041440414}}, (2, 0, 2): {'config_info': {}, 'config': {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}}, (0, 0, 1): {'config_info': {}, 'config': {'batch_size': 17, 'lr': 0.12169705572542237, 'l2': 0.002212816444365411, 'l1': 0.0003982270934210315}}, (1, 0, 1): {'config_info': {}, 'config': {'batch_size': 16, 'lr': 0.14261112072023766, 'l2': 0.0011797921871477292, 'l1': 0.0017107551612273232}}, (0, 0, 5): {'config_info': {}, 'config': {'batch_size': 21, 'lr': 0.1327865384217142, 'l2': 0.00015323570193598286, 'l1': 0.0009965813801526037}}, (0, 0, 0): {'config_info': {}, 'config': {'batch_size': 30, 'lr': 0.05958020697008728, 'l2': 0.00012441938511358324, 'l1': 0.0010959499184547534}}, (2, 0, 1): {'config_info': {}, 'config': {'batch_size': 32, 'lr': 0.17860301697331735, 'l2': 0.0023637164687333153, 'l1': 0.00171003574458352}}, (0, 0, 4): {'config_info': {}, 'config': {'batch_size': 16, 'lr': 0.05782109870299804, 'l2': 0.0023711269546917556, 'l1': 0.001003613674878896}}, (1, 0, 2): {'config_info': {}, 'config': {'batch_size': 17, 'lr': 0.026071750020129045, 'l2': 0.0001408448332681315, 'l1': 0.0003860780520028507}}, (2, 0, 0): {'config_info': {}, 'config': {'batch_size': 16, 'lr': 0.02153014369878981, 'l2': 0.0010743591528754566, 'l1': 0.0011507205935786594}}, (0, 0, 3): {'config_info': {}, 'config': {'batch_size': 16, 'lr': 0.15506329149467196, 'l2': 0.00012810555119458335, 'l1': 0.0021306501327552265}}}\n",
      "return best config:  {'batch_size': 16, 'lr': 0.0987192471380652, 'l2': 0.0008048349801333865, 'l1': 0.00016294967259595808}\n"
     ]
    }
   ],
   "source": [
    "best_cfg = hp.optimize(configs,Y,model_type='mlp', min_budget = 10, max_budget=100, \n",
    "                       run_name='', earlystop=False, L1L2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139639964378880\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 36, 'lr': 0.1874018718283377}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 57305.17739 / 49320.43900\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.35682 / 1.32998\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.63600 / 1.60417\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 16441.12438] ***\n",
      "Results validation data of all Folds: \n",
      "[[  4.93204390e+04]\n",
      " [  1.32998000e+00]\n",
      " [  1.60417000e+00]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 19102.7234] ***\n",
      "Results training data of all Folds: \n",
      "[[  5.73051774e+04]\n",
      " [  1.35682000e+00]\n",
      " [  1.63600000e+00]]\n",
      "hyperband obj crossval results 16441.12438\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.007725817805663781}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 6.58379 / 6.78356\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.17556 / 1.32706\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 5.66769 / 5.89443\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 4.66835] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 6.78356]\n",
      " [ 1.32706]\n",
      " [ 5.89443]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 4.47568] ***\n",
      "Results training data of all Folds: \n",
      "[[ 6.58379]\n",
      " [ 1.17556]\n",
      " [ 5.66769]]\n",
      "hyperband obj crossval results 4.66835\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.0076099528036695455}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.06374 / 0.08929\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.94452 / 2.82466\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.88062 / 3.28236\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 2.06544] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.08929]\n",
      " [ 2.82466]\n",
      " [ 3.28236]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 1.96296] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.06374]\n",
      " [ 2.94452]\n",
      " [ 2.88062]]\n",
      "hyperband obj crossval results 2.06544\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.001921554114714757}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 39.15438 / 36.29156\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.85508 / 2.74689\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.94695 / 0.96315\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 13.33386] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 36.29156]\n",
      " [  2.74689]\n",
      " [  0.96315]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 14.3188] ***\n",
      "Results training data of all Folds: \n",
      "[[ 39.15438]\n",
      " [  2.85508]\n",
      " [  0.94695]]\n",
      "hyperband obj crossval results 13.33386\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 25, 'lr': 0.3835397084896682}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 173541.34126 / 202132.37460\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1651.36476 / 1902.48543\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 6.59737 / 6.48495\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 68013.78166] ***\n",
      "Results validation data of all Folds: \n",
      "[[  2.02132375e+05]\n",
      " [  1.90248543e+03]\n",
      " [  6.48495000e+00]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 58399.7678] ***\n",
      "Results training data of all Folds: \n",
      "[[  1.73541341e+05]\n",
      " [  1.65136476e+03]\n",
      " [  6.59737000e+00]]\n",
      "hyperband obj crossval results 68013.78166\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 23, 'lr': 0.17632548175046464}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1985.91012 / 1775.64284\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 34.40116 / 34.60897\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.14322 / 0.18056\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 603.47746] ***\n",
      "Results validation data of all Folds: \n",
      "[[  1.77564284e+03]\n",
      " [  3.46089700e+01]\n",
      " [  1.80560000e-01]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 673.48483] ***\n",
      "Results training data of all Folds: \n",
      "[[  1.98591012e+03]\n",
      " [  3.44011600e+01]\n",
      " [  1.43220000e-01]]\n",
      "hyperband obj crossval results 603.47746\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 22, 'lr': 0.0010424757895254506}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.45587 / 2.55588\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 6.94175 / 6.95478\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 3.55024 / 3.54978\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 4.35348] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 2.55588]\n",
      " [ 6.95478]\n",
      " [ 3.54978]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 4.31595] ***\n",
      "Results training data of all Folds: \n",
      "[[ 2.45587]\n",
      " [ 6.94175]\n",
      " [ 3.55024]]\n",
      "hyperband obj crossval results 4.35348\n",
      "cross validate 5 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 19, 'lr': 0.003469030372105559}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 13.83829 / 16.07803\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 8.03017 / 5.83519\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 25.34513 / 25.21779\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 15.71033] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 16.07803]\n",
      " [  5.83519]\n",
      " [ 25.21779]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 15.73786] ***\n",
      "Results training data of all Folds: \n",
      "[[ 13.83829]\n",
      " [  8.03017]\n",
      " [ 25.34513]]\n",
      "hyperband obj crossval results 15.71033\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 23, 'lr': 0.28430749054335513}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 3472.04396 / 3523.06327\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate on 5 steps, mse on train / validation data: 0.63654 / 0.69261\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.49294 / 0.53654\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1174.76414] ***\n",
      "Results validation data of all Folds: \n",
      "[[  3.52306327e+03]\n",
      " [  6.92610000e-01]\n",
      " [  5.36540000e-01]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 1157.72448] ***\n",
      "Results training data of all Folds: \n",
      "[[  3.47204396e+03]\n",
      " [  6.36540000e-01]\n",
      " [  4.92940000e-01]]\n",
      "hyperband obj crossval results 1174.76414\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.0076099528036695455}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 3.07994 / 5.19139\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.98066 / 1.25787\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.47991 / 2.00694\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 2.81873] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 5.19139]\n",
      " [ 1.25787]\n",
      " [ 2.00694]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 2.51351] ***\n",
      "Results training data of all Folds: \n",
      "[[ 3.07994]\n",
      " [ 1.98066]\n",
      " [ 2.47991]]\n",
      "hyperband obj crossval results 2.81873\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 22, 'lr': 0.0010424757895254506}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 53.63178 / 49.70385\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 27.54559 / 24.83507\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.28858 / 1.20521\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 25.24804] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 49.70385]\n",
      " [ 24.83507]\n",
      " [  1.20521]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 27.48865] ***\n",
      "Results training data of all Folds: \n",
      "[[ 53.63178]\n",
      " [ 27.54559]\n",
      " [  1.28858]]\n",
      "hyperband obj crossval results 25.24804\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.007725817805663781}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.78026 / 2.92213\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.05201 / 0.04299\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.33999 / 1.72137\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1.56216] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 2.92213]\n",
      " [ 0.04299]\n",
      " [ 1.72137]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 1.39075] ***\n",
      "Results training data of all Folds: \n",
      "[[ 1.78026]\n",
      " [ 0.05201]\n",
      " [ 2.33999]]\n",
      "hyperband obj crossval results 1.56216\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.001921554114714757}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 37.93051 / 35.21599\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 14.08750 / 11.14776\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 10.54999 / 8.86799\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 18.41058] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 35.21599]\n",
      " [ 11.14776]\n",
      " [  8.86799]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 20.856] ***\n",
      "Results training data of all Folds: \n",
      "[[ 37.93051]\n",
      " [ 14.0875 ]\n",
      " [ 10.54999]]\n",
      "hyperband obj crossval results 18.41058\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 44, 'lr': 0.4913996332060787}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1575585.33856 / 1698166.62906\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1294.57183 / 1544.12482\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.51372 / 2.53258\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 566571.09549] ***\n",
      "Results validation data of all Folds: \n",
      "[[  1.69816663e+06]\n",
      " [  1.54412482e+03]\n",
      " [  2.53258000e+00]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 525627.4747] ***\n",
      "Results training data of all Folds: \n",
      "[[  1.57558534e+06]\n",
      " [  1.29457183e+03]\n",
      " [  2.51372000e+00]]\n",
      "hyperband obj crossval results 566571.09549\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.0076099528036695455}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.95017 / 1.32579\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04080 / 0.03309\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04376 / 0.02759\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.46215] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 1.32579]\n",
      " [ 0.03309]\n",
      " [ 0.02759]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.34491] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.95017]\n",
      " [ 0.0408 ]\n",
      " [ 0.04376]]\n",
      "hyperband obj crossval results 0.46215\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.007725817805663781}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.62112 / 4.18508\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04926 / 0.04060\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04391 / 0.02767\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1.41778] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 4.18508]\n",
      " [ 0.0406 ]\n",
      " [ 0.02767]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.90476] ***\n",
      "Results training data of all Folds: \n",
      "[[ 2.62112]\n",
      " [ 0.04926]\n",
      " [ 0.04391]]\n",
      "hyperband obj crossval results 1.41778\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 40, 'lr': 0.002370731368911436}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 16.30579 / 17.29121\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 11.52870 / 9.34835\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 13.08090 / 13.25739\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 13.29898] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 17.29121]\n",
      " [  9.34835]\n",
      " [ 13.25739]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 13.63846] ***\n",
      "Results training data of all Folds: \n",
      "[[ 16.30579]\n",
      " [ 11.5287 ]\n",
      " [ 13.0809 ]]\n",
      "hyperband obj crossval results 13.29898\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 18, 'lr': 0.0076099528036695455}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.37079 / 0.41493\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04794 / 0.03834\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 5.68127 / 4.39918\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1.61748] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.41493]\n",
      " [ 0.03834]\n",
      " [ 4.39918]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 2.03333] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.37079]\n",
      " [ 0.04794]\n",
      " [ 5.68127]]\n",
      "hyperband obj crossval results 1.61748\n",
      "cross validate 10 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 26, 'lr': 0.1579507660887153}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 853.34644 / 905.47774\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.08386 / 0.08086\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.05171 / 0.05630\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 301.87164] ***\n",
      "Results validation data of all Folds: \n",
      "[[  9.05477740e+02]\n",
      " [  8.08600000e-02]\n",
      " [  5.63000000e-02]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 284.494] ***\n",
      "Results training data of all Folds: \n",
      "[[  8.53346440e+02]\n",
      " [  8.38600000e-02]\n",
      " [  5.17100000e-02]]\n",
      "hyperband obj crossval results 301.87164\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.023123758972112808}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.45195 / 0.61088\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04009 / 0.03219\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.13532 / 0.25532\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.29946] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.61088]\n",
      " [ 0.03219]\n",
      " [ 0.25532]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.20912] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.45195]\n",
      " [ 0.04009]\n",
      " [ 0.13532]]\n",
      "hyperband obj crossval results 0.29946\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 26, 'lr': 0.1579507660887153}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 5.79849 / 5.19062\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04337 / 0.04290\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.04351 / 0.04174\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1.75842] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 5.19062]\n",
      " [ 0.0429 ]\n",
      " [ 0.04174]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 1.96179] ***\n",
      "Results training data of all Folds: \n",
      "[[ 5.79849]\n",
      " [ 0.04337]\n",
      " [ 0.04351]]\n",
      "hyperband obj crossval results 1.75842\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 40, 'lr': 0.002370731368911436}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 16.55753 / 20.22860\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 8.72184 / 6.69817\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 6.85380 / 4.63014\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 10.51897] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 20.2286 ]\n",
      " [  6.69817]\n",
      " [  4.63014]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 10.71106] ***\n",
      "Results training data of all Folds: \n",
      "[[ 16.55753]\n",
      " [  8.72184]\n",
      " [  6.8538 ]]\n",
      "hyperband obj crossval results 10.51897\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 17, 'lr': 0.0012756729206255175}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 88.28766 / 88.52939\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 9.23875 / 6.21818\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 15.96105 / 11.43095\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 35.39284] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 88.52939]\n",
      " [  6.21818]\n",
      " [ 11.43095]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 37.82915] ***\n",
      "Results training data of all Folds: \n",
      "[[ 88.28766]\n",
      " [  9.23875]\n",
      " [ 15.96105]]\n",
      "hyperband obj crossval results 35.39284\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 26, 'lr': 0.1579507660887153}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 38.78400 / 41.18006\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 2.46152 / 2.47339\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 4.26055 / 4.35291\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 16.00212] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 41.18006]\n",
      " [  2.47339]\n",
      " [  4.35291]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 15.16869] ***\n",
      "Results training data of all Folds: \n",
      "[[ 38.784  ]\n",
      " [  2.46152]\n",
      " [  4.26055]]\n",
      "hyperband obj crossval results 16.00212\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.001051445164047007}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 50.41666 / 48.16330\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 13.99796 / 9.56694\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 11.71480 / 8.87737\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 22.20254] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 48.1633 ]\n",
      " [  9.56694]\n",
      " [  8.87737]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 25.37647] ***\n",
      "Results training data of all Folds: \n",
      "[[ 50.41666]\n",
      " [ 13.99796]\n",
      " [ 11.7148 ]]\n",
      "hyperband obj crossval results 22.20254\n",
      "cross validate 20 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 36, 'lr': 0.06641032495399549}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.84544 / 1.95491\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.26675 / 0.27446\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate on 5 steps, mse on train / validation data: 1.42394 / 1.42303\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 1.21747] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 1.95491]\n",
      " [ 0.27446]\n",
      " [ 1.42303]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 1.17871] ***\n",
      "Results training data of all Folds: \n",
      "[[ 1.84544]\n",
      " [ 0.26675]\n",
      " [ 1.42394]]\n",
      "hyperband obj crossval results 1.21747\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 36, 'lr': 0.06641032495399549}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 1.98941 / 1.91761\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 6.48118 / 6.42872\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 18.31786 / 18.51387\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 8.9534] ***\n",
      "Results validation data of all Folds: \n",
      "[[  1.91761]\n",
      " [  6.42872]\n",
      " [ 18.51387]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 8.92948] ***\n",
      "Results training data of all Folds: \n",
      "[[  1.98941]\n",
      " [  6.48118]\n",
      " [ 18.31786]]\n",
      "hyperband obj crossval results 8.9534\n",
      "cross validate 40 epochs, train on 5 steps, validate on [5] steps\n",
      "config {'batch_size': 21, 'lr': 0.023123758972112808}\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.80275 / 1.05999\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.05447 / 0.04670\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "validate on 5 steps, mse on train / validation data: 0.19026 / 0.20350\n",
      "MSE on validation data on [5] steps: means over folds: *** [ 0.43673] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 1.05999]\n",
      " [ 0.0467 ]\n",
      " [ 0.2035 ]]\n",
      "MSE on train data on [5] steps: means over folds: *** [ 0.34916] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.80275]\n",
      " [ 0.05447]\n",
      " [ 0.19026]]\n",
      "hyperband obj crossval results 0.43673\n",
      "traj {'time_finished': [22.488330125808716, 60.9959557056427, 91.6520767211914, 313.71562457084656, 390.30302476882935, 627.3354201316833], 'losses': [16441.12438, 4.66835, 2.06544, 1.56216, 0.46215, 0.29946], 'budgets': [5.0, 5.0, 5.0, 10.0, 20.0, 20.0], 'config_ids': [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 0, 1), (0, 0, 2), (2, 0, 0)]}\n",
      "best_cfg_id (2, 0, 0)\n",
      "all_configs {(1, 0, 3): {'config_info': {}, 'config': {'batch_size': 26, 'lr': 0.1579507660887153}}, (0, 0, 7): {'config_info': {}, 'config': {'batch_size': 19, 'lr': 0.003469030372105559}}, (2, 0, 3): {'config_info': {}, 'config': {'batch_size': 36, 'lr': 0.06641032495399549}}, (0, 0, 2): {'config_info': {}, 'config': {'batch_size': 18, 'lr': 0.0076099528036695455}}, (1, 0, 0): {'config_info': {}, 'config': {'batch_size': 23, 'lr': 0.28430749054335513}}, (0, 0, 6): {'config_info': {}, 'config': {'batch_size': 22, 'lr': 0.0010424757895254506}}, (2, 0, 2): {'config_info': {}, 'config': {'batch_size': 21, 'lr': 0.001051445164047007}}, (0, 0, 1): {'config_info': {}, 'config': {'batch_size': 17, 'lr': 0.007725817805663781}}, (1, 0, 1): {'config_info': {}, 'config': {'batch_size': 44, 'lr': 0.4913996332060787}}, (0, 0, 5): {'config_info': {}, 'config': {'batch_size': 23, 'lr': 0.17632548175046464}}, (0, 0, 0): {'config_info': {}, 'config': {'batch_size': 36, 'lr': 0.1874018718283377}}, (2, 0, 1): {'config_info': {}, 'config': {'batch_size': 17, 'lr': 0.0012756729206255175}}, (0, 0, 4): {'config_info': {}, 'config': {'batch_size': 25, 'lr': 0.3835397084896682}}, (1, 0, 2): {'config_info': {}, 'config': {'batch_size': 40, 'lr': 0.002370731368911436}}, (2, 0, 0): {'config_info': {}, 'config': {'batch_size': 21, 'lr': 0.023123758972112808}}, (0, 0, 3): {'config_info': {}, 'config': {'batch_size': 18, 'lr': 0.001921554114714757}}}\n",
      "return best config:  {'batch_size': 21, 'lr': 0.023123758972112808}\n"
     ]
    }
   ],
   "source": [
    "best_cfg = hp.optimize([configs,lcs], Y, model_type='multi_lstm', \n",
    "                       min_budget = 4, max_budget=40, run_name='', earlystop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validate 1000 epochs, train on 5 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 21, 'lr': 0.023123758972112808}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15458, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15458 to 0.09678, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09678 to 0.02604, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss is 0.03820, did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02604 to 0.01416, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01416 to 0.01231, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01231 to 0.00266, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.00400, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 0.00438, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00266 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00301, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00153 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss is 0.00336, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00170, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00143 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00287, did not improve\n",
      "\n",
      "Epoch 00017: val_loss is 0.00330, did not improve\n",
      "\n",
      "Epoch 00018: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00189, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00281, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00298, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00192, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00232, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00246, did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00133 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss is 0.00183, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00204, did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00132 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss is 0.00166, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00126 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00122 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss is 0.00148, did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00116 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00108 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00106 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00105 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00102 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00099 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00095 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00087 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00079 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00073 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00069 to 0.00066, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00066 to 0.00065, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00065 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00062 to 0.00062, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00062 to 0.00061, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00061 to 0.00059, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00059 to 0.00058, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00058 to 0.00056, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00056 to 0.00055, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00055 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00054 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00053 to 0.00053, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00053 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00052 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00048 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00049, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00051, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00059, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00134: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00135: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00064, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00137: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00066, did not improve\n",
      "Epoch 00144: early stopping\n",
      "Using epoch 00086 with val_loss: 0.00045\n",
      "validate on 30 steps, mse on train / validation data: 0.17828 / 0.28994\n",
      "train fold 2 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.90476, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 1361.45895, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 510.44960, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 255.13004, did not improve\n",
      "\n",
      "Epoch 00005: val_loss is 54.13024, did not improve\n",
      "\n",
      "Epoch 00006: val_loss is 21.52839, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.90476 to 4.37317, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.37317 to 1.53281, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.53281 to 0.45816, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45816 to 0.10284, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10284 to 0.10064, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.10064 to 0.03229, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03229 to 0.01450, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01450 to 0.00979, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00979 to 0.00822, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00822 to 0.00662, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00662 to 0.00488, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00488 to 0.00424, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00424 to 0.00388, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00388 to 0.00365, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00365 to 0.00335, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00335 to 0.00313, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00313 to 0.00293, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00293 to 0.00274, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00274 to 0.00257, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00257 to 0.00243, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00243 to 0.00231, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00231 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00220 to 0.00210, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00210 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00201 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00193 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00186 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00179 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00172 to 0.00166, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00166 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00161 to 0.00157, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00157 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00154 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00151 to 0.00148, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00148 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00145 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00143 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00140 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00138 to 0.00136, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00136 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00134 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00132 to 0.00130, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00130 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00129 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00127 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00126 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00124 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00123 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00122 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00121 to 0.00119, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00119 to 0.00118, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00118 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00117 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00116 to 0.00115, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00115 to 0.00114, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00114 to 0.00113, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00113 to 0.00112, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00112 to 0.00111, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00111 to 0.00110, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00110 to 0.00109, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00109 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00108 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00107 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00106 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00105 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00105 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00104 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00103 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00102 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00101 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00100 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00099 to 0.00098, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00098 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00097 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00096 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00095 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00095 to 0.00094, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00094 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00093 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00091 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00091 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00088 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00087 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00086 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00085 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00080 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00080 to 0.00079, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00076 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00072 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00136: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00137: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00138: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00139: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00140: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00141: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00142: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00143: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00144: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00145: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00146: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00147: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00148: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00149: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00150: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00151: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00152: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00153: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00154: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00155: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00156: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00157: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00158: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00159: val_loss is 0.00108, did not improve\n",
      "\n",
      "Epoch 00160: val_loss is 0.00110, did not improve\n",
      "\n",
      "Epoch 00161: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00162: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00163: val_loss is 0.00117, did not improve\n",
      "\n",
      "Epoch 00164: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00165: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00166: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00167: val_loss is 0.00125, did not improve\n",
      "\n",
      "Epoch 00168: val_loss is 0.00127, did not improve\n",
      "\n",
      "Epoch 00169: val_loss is 0.00129, did not improve\n",
      "\n",
      "Epoch 00170: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00171: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00172: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00173: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00174: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00175: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00176: val_loss is 0.00143, did not improve\n",
      "\n",
      "Epoch 00177: val_loss is 0.00145, did not improve\n",
      "\n",
      "Epoch 00178: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00179: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00180: val_loss is 0.00147, did not improve\n",
      "\n",
      "Epoch 00181: val_loss is 0.00146, did not improve\n",
      "\n",
      "Epoch 00182: val_loss is 0.00144, did not improve\n",
      "\n",
      "Epoch 00183: val_loss is 0.00141, did not improve\n",
      "\n",
      "Epoch 00184: val_loss is 0.00136, did not improve\n",
      "Epoch 00184: early stopping\n",
      "Using epoch 00134 with val_loss: 0.00069\n",
      "validate on 30 steps, mse on train / validation data: 1.26030 / 1.59993\n",
      "train fold 3 on 5 steps, validation on 5 steps\n",
      "train considering 5 epochs, evaluate with 5 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03170, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.09429, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 0.03942, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03170 to 0.02370, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.02402, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02370 to 0.02337, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02337 to 0.01970, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01970 to 0.01745, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01745 to 0.01647, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01647 to 0.01517, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01517 to 0.01348, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01348 to 0.01201, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01201 to 0.01066, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01066 to 0.00930, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00930 to 0.00798, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00798 to 0.00680, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00680 to 0.00574, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00574 to 0.00484, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00484 to 0.00409, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00409 to 0.00350, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00350 to 0.00307, storing weights.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00307 to 0.00276, storing weights.\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00276 to 0.00257, storing weights.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00257 to 0.00245, storing weights.\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00245 to 0.00239, storing weights.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00239 to 0.00235, storing weights.\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00235 to 0.00234, storing weights.\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00234 to 0.00234, storing weights.\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00234 to 0.00233, storing weights.\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00233 to 0.00233, storing weights.\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00233 to 0.00233, storing weights.\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00233 to 0.00233, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00233 to 0.00232, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00232 to 0.00232, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00232 to 0.00231, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00231 to 0.00230, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00230 to 0.00230, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00230 to 0.00229, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00229 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00228 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00228 to 0.00227, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00227 to 0.00226, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00226 to 0.00226, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00226 to 0.00225, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00225 to 0.00225, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00225 to 0.00224, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: val_loss improved from 0.00224 to 0.00223, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00223 to 0.00223, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00223 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00222 to 0.00222, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00222 to 0.00221, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00221 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00220 to 0.00220, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00220 to 0.00219, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00219 to 0.00219, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00219 to 0.00218, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00218 to 0.00217, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00217 to 0.00217, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00217 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00216 to 0.00216, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00216 to 0.00215, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00215 to 0.00215, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00215 to 0.00214, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00214 to 0.00214, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00214 to 0.00213, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00213 to 0.00213, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00213 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00212 to 0.00212, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00212 to 0.00211, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00211 to 0.00210, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00210 to 0.00210, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00210 to 0.00209, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00209 to 0.00209, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00209 to 0.00208, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00208 to 0.00208, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00208 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00207 to 0.00207, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00207 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00206 to 0.00206, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00206 to 0.00205, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00205 to 0.00205, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00205 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00204 to 0.00204, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00204 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00203 to 0.00203, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00203 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00202 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00202 to 0.00202, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00202 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00201 to 0.00201, storing weights.\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00201 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00200 to 0.00200, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00200 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00199 to 0.00199, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00199 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00198 to 0.00198, storing weights.\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00198 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00197 to 0.00197, storing weights.\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00197 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00196 to 0.00196, storing weights.\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00196 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00195 to 0.00195, storing weights.\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.00195 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.00194 to 0.00194, storing weights.\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.00194 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.00193 to 0.00193, storing weights.\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.00193 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00192 to 0.00192, storing weights.\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.00192 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.00191 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.00191 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.00190 to 0.00190, storing weights.\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00190 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00189 to 0.00189, storing weights.\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.00189 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00188 to 0.00188, storing weights.\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.00188 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.00187 to 0.00187, storing weights.\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.00187 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00186 to 0.00186, storing weights.\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00186 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00185 to 0.00185, storing weights.\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00185 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00184 to 0.00184, storing weights.\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.00184 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.00183 to 0.00183, storing weights.\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.00183 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00182 to 0.00182, storing weights.\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.00182 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00181 to 0.00181, storing weights.\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.00181 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.00180 to 0.00180, storing weights.\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.00180 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.00179 to 0.00179, storing weights.\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.00179 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.00178 to 0.00178, storing weights.\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.00178 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00177 to 0.00177, storing weights.\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00177 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.00176 to 0.00176, storing weights.\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.00176 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.00175 to 0.00175, storing weights.\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.00175 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.00174 to 0.00174, storing weights.\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.00174 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.00173 to 0.00173, storing weights.\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.00173 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00172 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.00172 to 0.00171, storing weights.\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.00171 to 0.00171, storing weights.\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.00171 to 0.00170, storing weights.\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.00170 to 0.00170, storing weights.\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00170 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00169 to 0.00169, storing weights.\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.00169 to 0.00168, storing weights.\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.00168 to 0.00168, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00159: val_loss improved from 0.00168 to 0.00167, storing weights.\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.00167 to 0.00167, storing weights.\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.00167 to 0.00166, storing weights.\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00166 to 0.00166, storing weights.\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.00166 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.00165 to 0.00165, storing weights.\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.00165 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.00164 to 0.00164, storing weights.\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00164 to 0.00163, storing weights.\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00163 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00162 to 0.00162, storing weights.\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00162 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00161 to 0.00161, storing weights.\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00161 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.00160 to 0.00160, storing weights.\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00160 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00159 to 0.00159, storing weights.\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.00159 to 0.00158, storing weights.\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.00158 to 0.00157, storing weights.\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.00157 to 0.00157, storing weights.\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.00157 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.00156 to 0.00156, storing weights.\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00156 to 0.00155, storing weights.\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00155 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.00154 to 0.00154, storing weights.\n",
      "\n",
      "Epoch 00184: val_loss improved from 0.00154 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.00153 to 0.00153, storing weights.\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.00153 to 0.00152, storing weights.\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.00152 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.00151 to 0.00151, storing weights.\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00151 to 0.00150, storing weights.\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00150 to 0.00149, storing weights.\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.00149 to 0.00149, storing weights.\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00149 to 0.00148, storing weights.\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.00148 to 0.00147, storing weights.\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.00147 to 0.00147, storing weights.\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00147 to 0.00146, storing weights.\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00146 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.00145 to 0.00145, storing weights.\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00145 to 0.00144, storing weights.\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00144 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00143 to 0.00143, storing weights.\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00143 to 0.00142, storing weights.\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.00142 to 0.00141, storing weights.\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.00141 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.00140 to 0.00140, storing weights.\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00140 to 0.00139, storing weights.\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.00139 to 0.00138, storing weights.\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.00138 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.00137 to 0.00137, storing weights.\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.00137 to 0.00136, storing weights.\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.00136 to 0.00135, storing weights.\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.00135 to 0.00134, storing weights.\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00134 to 0.00133, storing weights.\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.00133 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.00132 to 0.00132, storing weights.\n",
      "\n",
      "Epoch 00215: val_loss improved from 0.00132 to 0.00131, storing weights.\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.00131 to 0.00130, storing weights.\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.00130 to 0.00129, storing weights.\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.00129 to 0.00128, storing weights.\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00128 to 0.00127, storing weights.\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00127 to 0.00126, storing weights.\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00126 to 0.00125, storing weights.\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00125 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00124 to 0.00124, storing weights.\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00124 to 0.00123, storing weights.\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.00123 to 0.00122, storing weights.\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.00122 to 0.00121, storing weights.\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.00121 to 0.00120, storing weights.\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.00120 to 0.00119, storing weights.\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.00119 to 0.00118, storing weights.\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.00118 to 0.00117, storing weights.\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.00117 to 0.00116, storing weights.\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.00116 to 0.00114, storing weights.\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.00114 to 0.00113, storing weights.\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.00113 to 0.00112, storing weights.\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.00112 to 0.00111, storing weights.\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00111 to 0.00110, storing weights.\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00110 to 0.00109, storing weights.\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.00109 to 0.00108, storing weights.\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.00108 to 0.00107, storing weights.\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.00107 to 0.00106, storing weights.\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.00106 to 0.00105, storing weights.\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00105 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00104 to 0.00104, storing weights.\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.00104 to 0.00103, storing weights.\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.00103 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.00102 to 0.00102, storing weights.\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.00102 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.00101 to 0.00101, storing weights.\n",
      "\n",
      "Epoch 00250: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00251: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00252: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00253: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00254: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00255: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00256: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00257: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00258: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00259: val_loss is 0.00114, did not improve\n",
      "\n",
      "Epoch 00260: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00261: val_loss is 0.00119, did not improve\n",
      "\n",
      "Epoch 00262: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00263: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00264: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00265: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00266: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00267: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00268: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00269: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00270: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00271: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00272: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00273: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00274: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00275: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00276: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00277: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00278: val_loss is 0.00139, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00279: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00280: val_loss is 0.00139, did not improve\n",
      "\n",
      "Epoch 00281: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00282: val_loss is 0.00138, did not improve\n",
      "\n",
      "Epoch 00283: val_loss is 0.00137, did not improve\n",
      "\n",
      "Epoch 00284: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00285: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00286: val_loss is 0.00134, did not improve\n",
      "\n",
      "Epoch 00287: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00288: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00289: val_loss is 0.00130, did not improve\n",
      "\n",
      "Epoch 00290: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00291: val_loss is 0.00126, did not improve\n",
      "\n",
      "Epoch 00292: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00293: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00294: val_loss is 0.00120, did not improve\n",
      "\n",
      "Epoch 00295: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00296: val_loss is 0.00116, did not improve\n",
      "\n",
      "Epoch 00297: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00298: val_loss is 0.00113, did not improve\n",
      "\n",
      "Epoch 00299: val_loss is 0.00111, did not improve\n",
      "\n",
      "Epoch 00300: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00301: val_loss is 0.00107, did not improve\n",
      "\n",
      "Epoch 00302: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00303: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00304: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00305: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.00101 to 0.00100, storing weights.\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.00100 to 0.00099, storing weights.\n",
      "\n",
      "Epoch 00308: val_loss improved from 0.00099 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.00097 to 0.00096, storing weights.\n",
      "\n",
      "Epoch 00310: val_loss improved from 0.00096 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00311: val_loss improved from 0.00095 to 0.00094, storing weights.\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.00094 to 0.00093, storing weights.\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.00093 to 0.00092, storing weights.\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.00092 to 0.00091, storing weights.\n",
      "\n",
      "Epoch 00315: val_loss improved from 0.00091 to 0.00090, storing weights.\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.00090 to 0.00089, storing weights.\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.00089 to 0.00088, storing weights.\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.00088 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.00087 to 0.00087, storing weights.\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.00087 to 0.00086, storing weights.\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.00086 to 0.00085, storing weights.\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.00085 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.00084 to 0.00084, storing weights.\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.00084 to 0.00083, storing weights.\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.00083 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.00082 to 0.00082, storing weights.\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.00082 to 0.00081, storing weights.\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.00081 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.00080 to 0.00080, storing weights.\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.00080 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.00079 to 0.00079, storing weights.\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.00079 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00333: val_loss improved from 0.00078 to 0.00078, storing weights.\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.00078 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.00077 to 0.00077, storing weights.\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.00077 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.00076 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.00076 to 0.00076, storing weights.\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.00076 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.00075 to 0.00075, storing weights.\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.00075 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00342: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.00074 to 0.00074, storing weights.\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.00074 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.00073 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00348: val_loss improved from 0.00073 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00349: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00350: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.00072 to 0.00072, storing weights.\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.00072 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00354: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00355: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.00071 to 0.00071, storing weights.\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.00071 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.00070 to 0.00070, storing weights.\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.00070 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00366: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00371: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00372: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00376: val_loss improved from 0.00069 to 0.00069, storing weights.\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.00069 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00378: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00382: val_loss improved from 0.00068 to 0.00068, storing weights.\n",
      "\n",
      "Epoch 00383: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00384: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00385: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00386: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00387: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00388: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00389: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00390: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00391: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00392: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00393: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00394: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00395: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00396: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00397: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00398: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00399: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00400: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00401: val_loss is 0.00069, did not improve\n",
      "\n",
      "Epoch 00402: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00403: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00404: val_loss is 0.00070, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00405: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00406: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00407: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00408: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00409: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00410: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00411: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00412: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00413: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00414: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00415: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00416: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00417: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00418: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00419: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00420: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00421: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00422: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00423: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00424: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00425: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00426: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00427: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00428: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00429: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00430: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00431: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00432: val_loss is 0.00077, did not improve\n",
      "Epoch 00432: early stopping\n",
      "Using epoch 00382 with val_loss: 0.00068\n",
      "validate on 30 steps, mse on train / validation data: 0.13800 / 0.08938\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.73713  0.79544  0.92657  0.65975] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.70987  0.61491  0.50921  0.28994]\n",
      " [ 1.45444  1.73461  2.25349  1.59993]\n",
      " [ 0.04709  0.03681  0.01701  0.08938]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.54098  0.66638  0.72073  0.52552] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.52994  0.51729  0.3413   0.17828]\n",
      " [ 1.02344  1.42766  1.79191  1.2603 ]\n",
      " [ 0.06957  0.0542   0.02898  0.138  ]]\n",
      "cross validate 1000 epochs, train on 10 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 21, 'lr': 0.023123758972112808}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11671, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.12661, did not improve\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11671 to 0.05024, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05024 to 0.02909, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 0.03532, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02909 to 0.00954, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00954 to 0.00902, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00902 to 0.00634, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss is 0.01010, did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00634 to 0.00631, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00654, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00672, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00631 to 0.00496, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00522, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00496 to 0.00286, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00286 to 0.00172, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00172 to 0.00073, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00073 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00054 to 0.00052, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00060, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00100, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00121, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00101, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00081, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00115, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00103, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00064, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00084, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00052 to 0.00047, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00092, did not improve\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00047 to 0.00044, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss is 0.00097, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00089, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00136, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00269, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00240, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00386, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00477, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.01023, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.01203, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00506, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00172, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00155, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00061, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00302, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00140, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00194, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00053, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00068, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00046, did not improve\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00044 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00040 to 0.00040, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00040 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00039 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00093: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00038 to 0.00038, storing weights.\n",
      "\n",
      "Epoch 00095: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.00040, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.00039, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.00040, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.00043, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.00042, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.00044, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.00047, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.00052, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.00058, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.00065, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.00095, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.00162, did not improve\n",
      "\n",
      "Epoch 00130: val_loss is 0.00171, did not improve\n",
      "\n",
      "Epoch 00131: val_loss is 0.00416, did not improve\n",
      "\n",
      "Epoch 00132: val_loss is 0.00269, did not improve\n",
      "\n",
      "Epoch 00133: val_loss is 0.00640, did not improve\n",
      "Epoch 00133: early stopping\n",
      "Using epoch 00094 with val_loss: 0.00038\n",
      "validate on 30 steps, mse on train / validation data: 0.01650 / 0.01693\n",
      "train fold 2 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 378.56074, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 378.56074 to 30.09993, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss is 34.44132, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 30.09993 to 3.21959, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss is 4.52868, did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.21959 to 0.70476, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss is 1.93981, did not improve\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.70476 to 0.47590, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.47590 to 0.15103, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15103 to 0.06758, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06758 to 0.05877, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.05877 to 0.03435, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03435 to 0.03089, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03089 to 0.03066, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03066 to 0.02833, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.02988, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02833 to 0.02818, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.02889, did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02818 to 0.02816, storing weights.\n",
      "\n",
      "Epoch 00020: val_loss is 0.02841, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.02824, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.02825, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.02825, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.02825, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.02827, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.02828, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.02829, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.02830, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.02830, did not improve\n",
      "Epoch 00092: early stopping\n",
      "Using epoch 00019 with val_loss: 0.02816\n",
      "validate on 30 steps, mse on train / validation data: 0.03174 / 0.02943\n",
      "train fold 3 on 10 steps, validation on 10 steps\n",
      "train considering 10 epochs, evaluate with 10 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04151, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04151 to 0.01769, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.01769 to 0.00459, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00459 to 0.00235, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00235 to 0.00191, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00191 to 0.00095, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00095 to 0.00046, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00046 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00039 to 0.00039, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00039 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00012: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00013: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00014: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00033 to 0.00033, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00033 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00030 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.00029, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00029, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00029, did not improve\n",
      "Epoch 00085: early stopping\n",
      "Using epoch 00056 with val_loss: 0.00029\n",
      "validate on 30 steps, mse on train / validation data: 0.01208 / 0.00941\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.08369  0.04828  0.03323  0.01859] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.1925   0.08568  0.04499  0.01693]\n",
      " [ 0.02943  0.02943  0.02943  0.02943]\n",
      " [ 0.02916  0.02972  0.02526  0.00941]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.07582  0.05066  0.03704  0.02011] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.14894  0.07332  0.04103  0.0165 ]\n",
      " [ 0.03174  0.03174  0.03174  0.03174]\n",
      " [ 0.04678  0.04693  0.03834  0.01208]]\n",
      "cross validate 1000 epochs, train on 20 steps, validate on [5, 10, 20, 30] steps\n",
      "config {'batch_size': 21, 'lr': 0.023123758972112808}\n",
      "choose min as mode\n",
      "evaluating with early stopping\n",
      "train fold 1 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32145, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32145 to 0.12631, storing weights.\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12631 to 0.10577, storing weights.\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.10577 to 0.06052, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06052 to 0.01204, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss is 0.01487, did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01204 to 0.00730, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss is 0.01194, did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00730 to 0.00228, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss is 0.00380, did not improve\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00228 to 0.00097, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00164, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00097 to 0.00063, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00063 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00016: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00054 to 0.00048, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00062, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00057, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00048, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00055, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00054, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00071, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00056, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00088, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00087, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00105, did not improve\n",
      "\n",
      "Epoch 00035: val_loss is 0.00118, did not improve\n",
      "\n",
      "Epoch 00036: val_loss is 0.00123, did not improve\n",
      "\n",
      "Epoch 00037: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00038: val_loss is 0.00133, did not improve\n",
      "\n",
      "Epoch 00039: val_loss is 0.00131, did not improve\n",
      "\n",
      "Epoch 00040: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00041: val_loss is 0.00124, did not improve\n",
      "\n",
      "Epoch 00042: val_loss is 0.00122, did not improve\n",
      "\n",
      "Epoch 00043: val_loss is 0.00109, did not improve\n",
      "\n",
      "Epoch 00044: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00045: val_loss is 0.00094, did not improve\n",
      "\n",
      "Epoch 00046: val_loss is 0.00091, did not improve\n",
      "\n",
      "Epoch 00047: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00048: val_loss is 0.00082, did not improve\n",
      "\n",
      "Epoch 00049: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00050: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00051: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00052: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00053: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00054: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00055: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00056: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00057: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00058: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00059: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00060: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00061: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00062: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00063: val_loss is 0.00075, did not improve\n",
      "\n",
      "Epoch 00064: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00065: val_loss is 0.00077, did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_loss is 0.00073, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.00080, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.00074, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.00083, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.00086, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.00077, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.00090, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.00093, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.00078, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.00099, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.00076, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.00102, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.00072, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.00104, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.00067, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.00106, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.00063, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.00112, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.00066, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.00128, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.00096, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00173, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00222, did not improve\n",
      "Epoch 00092: early stopping\n",
      "Using epoch 00017 with val_loss: 0.00048\n",
      "validate on 30 steps, mse on train / validation data: 0.00203 / 0.00196\n",
      "train fold 2 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05475, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss is 0.12115, did not improve\n",
      "\n",
      "Epoch 00003: val_loss is 0.08707, did not improve\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05475 to 0.05174, storing weights.\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05174 to 0.04611, storing weights.\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04611 to 0.02661, storing weights.\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02661 to 0.01495, storing weights.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01495 to 0.00808, storing weights.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00808 to 0.00483, storing weights.\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00483 to 0.00260, storing weights.\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00260 to 0.00112, storing weights.\n",
      "\n",
      "Epoch 00012: val_loss is 0.00132, did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00112 to 0.00054, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss is 0.00135, did not improve\n",
      "\n",
      "Epoch 00015: val_loss is 0.00070, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00054 to 0.00045, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00045 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00018: val_loss is 0.00041, did not improve\n",
      "\n",
      "Epoch 00019: val_loss is 0.00050, did not improve\n",
      "\n",
      "Epoch 00020: val_loss is 0.00045, did not improve\n",
      "\n",
      "Epoch 00021: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.00037, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.00038, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.00036, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.00035, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.00034, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00032: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00033: val_loss is 0.00033, did not improve\n",
      "\n",
      "Epoch 00034: val_loss is 0.00032, did not improve\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00032 to 0.00032, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00032 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00031 to 0.00031, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00031 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00030 to 0.00030, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00030 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00029 to 0.00029, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00029 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00028 to 0.00028, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00028 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00027 to 0.00027, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00027 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00026 to 0.00026, storing weights.\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00026 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00025 to 0.00025, storing weights.\n",
      "\n",
      "Epoch 00090: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.00025, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.00025, did not improve\n",
      "Epoch 00092: early stopping\n",
      "Using epoch 00089 with val_loss: 0.00025\n",
      "validate on 30 steps, mse on train / validation data: 0.00131 / 0.00129\n",
      "train fold 3 on 20 steps, validation on 20 steps\n",
      "train considering 20 epochs, evaluate with 20 epochs\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51855, storing weights.\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51855 to 0.09694, storing weights.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss is 14.75946, did not improve\n",
      "\n",
      "Epoch 00004: val_loss is 275.30684, did not improve\n",
      "\n",
      "Epoch 00005: val_loss is 13.29729, did not improve\n",
      "\n",
      "Epoch 00006: val_loss is 8.29154, did not improve\n",
      "\n",
      "Epoch 00007: val_loss is 0.53958, did not improve\n",
      "\n",
      "Epoch 00008: val_loss is 10.31797, did not improve\n",
      "\n",
      "Epoch 00009: val_loss is 1.31900, did not improve\n",
      "\n",
      "Epoch 00010: val_loss is 0.25212, did not improve\n",
      "\n",
      "Epoch 00011: val_loss is 0.24620, did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09694 to 0.05898, storing weights.\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05898 to 0.04390, storing weights.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.04390 to 0.03132, storing weights.\n",
      "\n",
      "Epoch 00015: val_loss is 0.03260, did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03132 to 0.02776, storing weights.\n",
      "\n",
      "Epoch 00017: val_loss is 0.02879, did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02776 to 0.02754, storing weights.\n",
      "\n",
      "Epoch 00019: val_loss is 0.02769, did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02754 to 0.02724, storing weights.\n",
      "\n",
      "Epoch 00021: val_loss is 0.02757, did not improve\n",
      "\n",
      "Epoch 00022: val_loss is 0.02747, did not improve\n",
      "\n",
      "Epoch 00023: val_loss is 0.02750, did not improve\n",
      "\n",
      "Epoch 00024: val_loss is 0.02739, did not improve\n",
      "\n",
      "Epoch 00025: val_loss is 0.02739, did not improve\n",
      "\n",
      "Epoch 00026: val_loss is 0.02734, did not improve\n",
      "\n",
      "Epoch 00027: val_loss is 0.02735, did not improve\n",
      "\n",
      "Epoch 00028: val_loss is 0.02732, did not improve\n",
      "\n",
      "Epoch 00029: val_loss is 0.02730, did not improve\n",
      "\n",
      "Epoch 00030: val_loss is 0.02727, did not improve\n",
      "\n",
      "Epoch 00031: val_loss is 0.02725, did not improve\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.02724 to 0.02722, storing weights.\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.02722 to 0.02720, storing weights.\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.02720 to 0.02718, storing weights.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.02718 to 0.02716, storing weights.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.02716 to 0.02714, storing weights.\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.02714 to 0.02711, storing weights.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.02711 to 0.02709, storing weights.\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.02709 to 0.02707, storing weights.\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02707 to 0.02705, storing weights.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.02705 to 0.02703, storing weights.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.02703 to 0.02701, storing weights.\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.02701 to 0.02699, storing weights.\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.02699 to 0.02697, storing weights.\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.02697 to 0.02696, storing weights.\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.02696 to 0.02694, storing weights.\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.02694 to 0.02692, storing weights.\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.02692 to 0.02690, storing weights.\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.02690 to 0.02689, storing weights.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.02689 to 0.02687, storing weights.\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.02687 to 0.02686, storing weights.\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.02686 to 0.02684, storing weights.\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.02684 to 0.02683, storing weights.\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.02683 to 0.02681, storing weights.\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.02681 to 0.02680, storing weights.\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.02680 to 0.02679, storing weights.\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.02679 to 0.02678, storing weights.\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.02678 to 0.02677, storing weights.\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.02677 to 0.02676, storing weights.\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.02676 to 0.02676, storing weights.\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.02676 to 0.02675, storing weights.\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.02675 to 0.02675, storing weights.\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.02675 to 0.02675, storing weights.\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.02675 to 0.02675, storing weights.\n",
      "\n",
      "Epoch 00065: val_loss is 0.02675, did not improve\n",
      "\n",
      "Epoch 00066: val_loss is 0.02675, did not improve\n",
      "\n",
      "Epoch 00067: val_loss is 0.02676, did not improve\n",
      "\n",
      "Epoch 00068: val_loss is 0.02676, did not improve\n",
      "\n",
      "Epoch 00069: val_loss is 0.02677, did not improve\n",
      "\n",
      "Epoch 00070: val_loss is 0.02678, did not improve\n",
      "\n",
      "Epoch 00071: val_loss is 0.02680, did not improve\n",
      "\n",
      "Epoch 00072: val_loss is 0.02681, did not improve\n",
      "\n",
      "Epoch 00073: val_loss is 0.02683, did not improve\n",
      "\n",
      "Epoch 00074: val_loss is 0.02686, did not improve\n",
      "\n",
      "Epoch 00075: val_loss is 0.02688, did not improve\n",
      "\n",
      "Epoch 00076: val_loss is 0.02691, did not improve\n",
      "\n",
      "Epoch 00077: val_loss is 0.02695, did not improve\n",
      "\n",
      "Epoch 00078: val_loss is 0.02698, did not improve\n",
      "\n",
      "Epoch 00079: val_loss is 0.02703, did not improve\n",
      "\n",
      "Epoch 00080: val_loss is 0.02707, did not improve\n",
      "\n",
      "Epoch 00081: val_loss is 0.02712, did not improve\n",
      "\n",
      "Epoch 00082: val_loss is 0.02718, did not improve\n",
      "\n",
      "Epoch 00083: val_loss is 0.02724, did not improve\n",
      "\n",
      "Epoch 00084: val_loss is 0.02731, did not improve\n",
      "\n",
      "Epoch 00085: val_loss is 0.02739, did not improve\n",
      "\n",
      "Epoch 00086: val_loss is 0.02747, did not improve\n",
      "\n",
      "Epoch 00087: val_loss is 0.02756, did not improve\n",
      "\n",
      "Epoch 00088: val_loss is 0.02765, did not improve\n",
      "\n",
      "Epoch 00089: val_loss is 0.02775, did not improve\n",
      "\n",
      "Epoch 00090: val_loss is 0.02787, did not improve\n",
      "\n",
      "Epoch 00091: val_loss is 0.02799, did not improve\n",
      "\n",
      "Epoch 00092: val_loss is 0.02812, did not improve\n",
      "\n",
      "Epoch 00093: val_loss is 0.02826, did not improve\n",
      "\n",
      "Epoch 00094: val_loss is 0.02841, did not improve\n",
      "\n",
      "Epoch 00095: val_loss is 0.02857, did not improve\n",
      "\n",
      "Epoch 00096: val_loss is 0.02874, did not improve\n",
      "\n",
      "Epoch 00097: val_loss is 0.02892, did not improve\n",
      "\n",
      "Epoch 00098: val_loss is 0.02912, did not improve\n",
      "\n",
      "Epoch 00099: val_loss is 0.02933, did not improve\n",
      "\n",
      "Epoch 00100: val_loss is 0.02955, did not improve\n",
      "\n",
      "Epoch 00101: val_loss is 0.02979, did not improve\n",
      "\n",
      "Epoch 00102: val_loss is 0.03003, did not improve\n",
      "\n",
      "Epoch 00103: val_loss is 0.03030, did not improve\n",
      "\n",
      "Epoch 00104: val_loss is 0.03058, did not improve\n",
      "\n",
      "Epoch 00105: val_loss is 0.03087, did not improve\n",
      "\n",
      "Epoch 00106: val_loss is 0.03118, did not improve\n",
      "\n",
      "Epoch 00107: val_loss is 0.03151, did not improve\n",
      "\n",
      "Epoch 00108: val_loss is 0.03185, did not improve\n",
      "\n",
      "Epoch 00109: val_loss is 0.03220, did not improve\n",
      "\n",
      "Epoch 00110: val_loss is 0.03257, did not improve\n",
      "\n",
      "Epoch 00111: val_loss is 0.03296, did not improve\n",
      "\n",
      "Epoch 00112: val_loss is 0.03336, did not improve\n",
      "\n",
      "Epoch 00113: val_loss is 0.03377, did not improve\n",
      "\n",
      "Epoch 00114: val_loss is 0.03420, did not improve\n",
      "\n",
      "Epoch 00115: val_loss is 0.03463, did not improve\n",
      "\n",
      "Epoch 00116: val_loss is 0.03508, did not improve\n",
      "\n",
      "Epoch 00117: val_loss is 0.03554, did not improve\n",
      "\n",
      "Epoch 00118: val_loss is 0.03601, did not improve\n",
      "\n",
      "Epoch 00119: val_loss is 0.03648, did not improve\n",
      "\n",
      "Epoch 00120: val_loss is 0.03696, did not improve\n",
      "\n",
      "Epoch 00121: val_loss is 0.03744, did not improve\n",
      "\n",
      "Epoch 00122: val_loss is 0.03792, did not improve\n",
      "\n",
      "Epoch 00123: val_loss is 0.03840, did not improve\n",
      "\n",
      "Epoch 00124: val_loss is 0.03888, did not improve\n",
      "\n",
      "Epoch 00125: val_loss is 0.03936, did not improve\n",
      "\n",
      "Epoch 00126: val_loss is 0.03983, did not improve\n",
      "\n",
      "Epoch 00127: val_loss is 0.04029, did not improve\n",
      "\n",
      "Epoch 00128: val_loss is 0.04074, did not improve\n",
      "\n",
      "Epoch 00129: val_loss is 0.04118, did not improve\n",
      "Epoch 00129: early stopping\n",
      "Using epoch 00064 with val_loss: 0.02675\n",
      "validate on 30 steps, mse on train / validation data: 0.02955 / 0.02495\n",
      "MSE on validation data on [5, 10, 20, 30] steps: means over folds: *** [ 0.02429  0.01109  0.0104   0.0094 ] ***\n",
      "Results validation data of all Folds: \n",
      "[[ 0.04105  0.00511  0.00295  0.00196]\n",
      " [ 0.00689  0.00322  0.00331  0.00129]\n",
      " [ 0.02495  0.02495  0.02495  0.02495]]\n",
      "MSE on train data on [5, 10, 20, 30] steps: means over folds: *** [ 0.0211   0.01247  0.01185  0.01096] ***\n",
      "Results training data of all Folds: \n",
      "[[ 0.02463  0.00444  0.00319  0.00203]\n",
      " [ 0.00913  0.00341  0.00281  0.00131]\n",
      " [ 0.02955  0.02955  0.02955  0.02955]]\n",
      "results validation data \n",
      " [[ 0.73713  0.79544  0.92657  0.65975]\n",
      " [ 0.08369  0.04828  0.03323  0.01859]\n",
      " [ 0.02429  0.01109  0.0104   0.0094 ]]\n",
      "results training data\n",
      " [[ 0.54098  0.66638  0.72073  0.52552]\n",
      " [ 0.07582  0.05066  0.03704  0.02011]\n",
      " [ 0.0211   0.01247  0.01185  0.01096]]\n"
     ]
    }
   ],
   "source": [
    "best_cfg = {'batch_size': 21, 'lr': 0.023123758972112808}\n",
    "res_train, res_val = np.zeros((3,4)), np.zeros((3,4))\n",
    "for i, train_steps in enumerate([5,10,20]):\n",
    "    res_train[i], res_val[i] = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                                         steps=(train_steps,[5,10,20,30]), \n",
    "                                         cfg=best_cfg, epochs=1000, earlystop=True, \n",
    "                                         mode='nextstep')\n",
    "print(\"results validation data \\n\", res_val)  \n",
    "print(\"results training data\\n\", res_train)\n",
    "# results were far better with lr = 0.002 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cfg = {'batch_size': 21, 'lr': 0.023123758972112808}\n",
    "res_train, res_val = m.eval_cv('multi_lstm', [configs, lcs], Y, \n",
    "                                     steps=(0,[5,10,20,30]), \n",
    "                                     cfg=cfg, epochs=1000, earlystop=True, \n",
    "                                     mode='nextstep')\n",
    "print(\"results validation data \\n\", res_val)  \n",
    "print(\"results training data\\n\", res_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling configuration data\n",
      "build lstm with input_dim: 6\n",
      "Train on 200 samples, validate on 65 samples\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 0.0743 - mean_squared_error: 0.0743 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "65/65 [==============================] - 0s 843us/step\n",
      "mse:  0.00873059442697\n"
     ]
    }
   ],
   "source": [
    "# experiment with concatenating the config to each data point of learning curve\n",
    "timesteps = 5\n",
    "configs,lcs,Y = t.load_lstm_data_concat_cfg(timesteps=timesteps)\n",
    "model_type = 'lstm'\n",
    "model = m.lstm(lcs[0][0].shape[0])\n",
    "m.train_lstm(model, lcs, Y, split=200, batch_size=20, epochs=5)\n",
    "mse = m.eval_lstm(model, lcs, Y, split=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_curves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-b1ef2fff93a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_curves\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Subset of learning curves\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learning_curves' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_subset=20\n",
    "n_epochs = 40\n",
    "t_idx = np.arange(1, n_epochs+1)\n",
    "\n",
    "[plt.plot(t_idx, lc) for lc in learning_curves[:n_subset]]\n",
    "plt.title(\"Subset of learning curves\")\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram and CDF over the final error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdf648b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7effdf6cbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sorted = np.sort(lcs[:, -1])   # sorted list of final val error\n",
    "print(len(sorted))\n",
    "h = plt.hist(sorted, bins=20)\n",
    "plt.show()\n",
    "\n",
    "yvals = np.arange(len(sorted))/float(len(sorted))   # from 0 to 1 in 265 even steps\n",
    "plt.plot(sorted, yvals)\n",
    "plt.title(\"Empirical CDF\")\n",
    "plt.xlabel(\"y(x, t=40)\")\n",
    "plt.ylabel(\"CDF(y)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram and CDF over all error rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4935a3ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f493581f828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_values = np.sort(learning_curves.flatten())\n",
    "\n",
    "h = plt.hist(all_values, bins=20)\n",
    "plt.show()\n",
    "\n",
    "yvals = np.arange(all_values.shape[0])/all_values.shape[0]\n",
    "plt.plot(all_values, yvals)\n",
    "plt.title(\"Empirical CDF\")\n",
    "plt.xlabel(\"y(x, t=40)\")\n",
    "plt.ylabel(\"CDF(y)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
